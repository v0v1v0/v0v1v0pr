<div class="container">

<table style="width: 100%;"><tr>
<td>plsrda</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>PLSDA models</h2>

<h3>Description</h3>

<p>Discrimination (DA) based on PLS.
</p>
<p>The training variable <code class="reqn">y</code> (univariate class membership) is firstly transformed to a dummy table containing <code class="reqn">nclas</code> columns, where <code class="reqn">nclas</code> is the number of classes present in <code class="reqn">y</code>. Each column is a dummy variable (0/1). Then, a PLS2 is implemented on the <code class="reqn">X-</code>data and the dummy table, returning latent variables (LVs) that are used as dependent variables in a DA model.
</p>
<p>- <code>plsrda</code>: Usual "PLSDA". A linear regression model predicts the Y-dummy table from the PLS2 LVs. This corresponds to the PLSR2 of the X-data and the Y-dummy table. For a given observation, the final prediction is the class corresponding to the dummy variable for which the prediction is the highest.
</p>
<p>- <code>plslda</code> and <code>plsqda</code>: Probabilistic LDA and QDA are run over the PLS2 LVs, respectively.
</p>


<h3>Usage</h3>

<pre><code class="language-R">
plsrda(X, y, weights = NULL, nlv, 
Xscaling = c("none","pareto","sd")[1], Yscaling = c("none","pareto","sd")[1])

plslda(X, y, weights = NULL, nlv, prior = c("unif", "prop"), 
Xscaling = c("none","pareto","sd")[1], Yscaling = c("none","pareto","sd")[1])

plsqda(X, y, weights = NULL, nlv, prior = c("unif", "prop"), 
Xscaling = c("none","pareto","sd")[1], Yscaling = c("none","pareto","sd")[1])

## S3 method for class 'Plsrda'
predict(object, X, ..., nlv = NULL) 

## S3 method for class 'Plsprobda'
predict(object, X, ..., nlv = NULL) 

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>For the main functions: Training X-data (<code class="reqn">n, p</code>). â€” For the auxiliary functions: New X-data (<code class="reqn">m, p</code>) to consider.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Training class membership (<code class="reqn">n</code>). <b>Note:</b> If <code>y</code> is a factor, it is replaced by a character vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>Weights (<code class="reqn">n</code>) to apply to the training observations for the PLS2. Internally, weights are "normalized" to sum to 1. Default to <code>NULL</code> (weights are set to <code class="reqn">1 / n</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlv</code></td>
<td>
<p>The number(s) of LVs to calculate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>
<p>The prior probabilities of the classes. Possible values are "unif" (default; probabilities are set equal for all the classes) or "prop" (probabilities are set equal to the observed proportions of the classes in <code>y</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xscaling</code></td>
<td>
<p>X variable scaling among "none" (mean-centering only), "pareto" (mean-centering and pareto scaling), "sd" (mean-centering and unit variance scaling). If "pareto" or "sd", uncorrected standard deviation is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Yscaling</code></td>
<td>
<p>Y variable scaling, once converted to binary variables, among "none" (mean-centering only), "pareto" (mean-centering and pareto scaling), "sd" (mean-centering and unit variance scaling). If "pareto" or "sd", uncorrected standard deviation is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>For the auxiliary functions: A fitted model, output of a call to the main functions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>For the auxiliary functions: Optional arguments. Not used.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>For <code>plsrda</code>, <code>plslda</code>, <code>plsqda</code>:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>fm</code></td>
<td>
<p>list with the model: (<code>T</code>): X-scores matrix; (<code>P</code>): X-loading matrix;(<code>R</code>): The PLS projection matrix (p,nlv); (<code>W</code>): X-loading weights matrix ;(<code>C</code>): The Y-loading weights matrix; (<code>TT</code>): the X-score normalization factor; (<code>xmeans</code>): the centering vector of X (p,1);  (<code>ymeans</code>): the centering vector of Y (q,1); (<code>xscales</code>): the scaling vector of X (p,1);  (<code>yscales</code>): the scaling vector of Y (q,1); (<code>weights</code>): vector of observation weights; (<code>U</code>): intermediate output.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lev</code></td>
<td>
<p>classes</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ni</code></td>
<td>
<p>number of observations in each class</p>
</td>
</tr>
</table>
<p>For <code>predict.Plsrda</code>, <code>predict.Plsprobda</code>: 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>predicted class for each observation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>posterior</code></td>
<td>
<p>calculated probability of belonging to a class for each observation</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>The first example concerns PLSDA, and the second one concerns PLS LDA.
<code>fm</code> are PLS1 models, and <code>zfm</code> are PLS2 models to predict the disjunctive matrix.
</p>


<h3>See Also</h3>

<p><code>plsr_plsda_allsteps</code> function to help determine the optimal number of latent variables, perform a permutation test, calculate model parameters and predict new observations.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## EXAMPLE OF PLSDA

n &lt;- 50 ; p &lt;- 8
Xtrain &lt;- matrix(rnorm(n * p), ncol = p)
ytrain &lt;- sample(c(1, 4, 10), size = n, replace = TRUE)

Xtest &lt;- Xtrain[1:5, ] ; ytest &lt;- ytrain[1:5]

nlv &lt;- 5
fm &lt;- plsrda(Xtrain, ytrain, Xscaling = "sd", nlv = nlv)
names(fm)

predict(fm, Xtest)
predict(fm, Xtest, nlv = 0:2)$pred

pred &lt;- predict(fm, Xtest)$pred
err(pred, ytest)

zfm &lt;- fm$fm
transform(zfm, Xtest)
transform(zfm, Xtest, nlv = 1)
summary(zfm, Xtrain)
coef(zfm)
coef(zfm, nlv = 0)
coef(zfm, nlv = 2)

## EXAMPLE OF PLS LDA

n &lt;- 50 ; p &lt;- 8
Xtrain &lt;- matrix(rnorm(n * p), ncol = p)
ytrain &lt;- sample(c(1, 4, 10), size = n, replace = TRUE)
Xtest &lt;- Xtrain[1:5, ] ; ytest &lt;- ytrain[1:5]

nlv &lt;- 5
fm &lt;- plslda(Xtrain, ytrain, Xscaling = "sd", nlv = nlv)
predict(fm, Xtest)
predict(fm, Xtest, nlv = 1:2)$pred

zfm &lt;- fm$fm[[1]]
class(zfm)
names(zfm)
summary(zfm, Xtrain)
transform(zfm, Xtest[1:2, ])
coef(zfm)

</code></pre>


</div>