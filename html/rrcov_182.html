<div class="container">

<table style="width: 100%;"><tr>
<td>PcaLocantore</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Spherical Principal Components</h2>

<h3>Description</h3>

<p>The Spherical Principal Components procedure was proposed by 
Locantore et al., (1999) as a functional data analysis method.
The idea is to perform classical PCA on the data,
projected onto a unit sphere. The estimates of the eigenvectors are consistent 
and the procedure is extremely fast. The simulations of Maronna (2005) show
that this method has very good performance. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">PcaLocantore(x, ...)
## Default S3 method:
PcaLocantore(x, k = ncol(x), kmax = ncol(x), delta = 0.001, 
    na.action = na.fail, scale = FALSE, signflip = TRUE, 
    crit.pca.distances = 0.975, trace=FALSE, ...)
## S3 method for class 'formula'
PcaLocantore(formula, data = NULL, subset, na.action, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>a formula with no response variable, referring only to
numeric variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>an optional data frame (or similar: see
<code>model.frame</code>) containing the variables in the
formula <code>formula</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>
<p>an optional vector used to select rows (observations) of the
data matrix <code>x</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.action</code></td>
<td>
<p>a function which indicates what should happen
when the data contain <code>NA</code>s.  The default is set by
the <code>na.action</code> setting of <code>options</code>, and is
<code>na.fail</code> if that is unset. The default is <code>na.omit</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>arguments passed to or from other methods.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a numeric matrix (or data frame) which provides
the data for the principal components analysis.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>number of principal components to compute. If <code>k</code> is missing, 
or <code>k = 0</code>, the algorithm itself will determine the number of 
components by finding such <code>k</code> that <code class="reqn">l_k/l_1 &gt;= 10.E-3</code> and 
<code class="reqn">\Sigma_{j=1}^k l_j/\Sigma_{j=1}^r l_j &gt;= 0.8</code>. 
It is preferable to investigate the scree plot in order to choose the number 
of components and then run again. Default is <code>k=ncol(x)</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kmax</code></td>
<td>
<p>maximal number of principal components to compute.
Default is <code>kmax=10</code>. If <code>k</code> is provided, <code>kmax</code> 
does not need to be specified, unless <code>k</code> is larger than 10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta</code></td>
<td>
<p>an accuracy parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>a value indicating whether and how the variables should be scaled
to have unit variance (only possible if there are no constant 
variables). If <code>scale=FALSE</code> (default) or <code>scale=NULL</code> no scaling is 
performed (a vector of 1s is returned in the scale slot). If <code>scale=TRUE</code>
the data are scaled by <code>mad</code>. Alternatively it can be a function 
like <code>sd</code> or <code>Qn</code> or a vector of length equal the number of columns 
of <code>x</code>. The value is passed to the underlying function and the result 
returned is stored in the scale slot. Default is <code>scale=FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>signflip</code></td>
<td>
<p>a logical value indicating wheather to try to solve 
the sign indeterminancy of the loadings -   ad hoc approach setting 
the maximum element in a singular vector to be positive. Default is 
<code>signflip = TRUE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>crit.pca.distances</code></td>
<td>
<p>criterion to use for computing the cutoff 
values for the orthogonal and score distances. Default is 0.975.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace</code></td>
<td>
<p>whether to print intermediate results. Default is <code>trace = FALSE</code></p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>PcaLocantore</code>, serving as a constructor for objects of class 
<code>PcaLocantore-class</code> is a generic function with "formula" 
and "default" methods. For details see the relevant references.
</p>


<h3>Value</h3>

<p>An S4 object of class <code>PcaLocantore-class</code> which is a subclass of the 
virtual class <code>PcaRobust-class</code>. 
</p>


<h3>Author(s)</h3>

<p> Valentin Todorov <a href="mailto:valentin.todorov@chello.at">valentin.todorov@chello.at</a> 
The SPC algorithm is implemented on the bases of the available from 
the web site of the book Maronna et al. (2006) code  
<a href="https://www.wiley.com/legacy/wileychi/robust_statistics/">https://www.wiley.com/legacy/wileychi/robust_statistics/</a>
</p>


<h3>References</h3>

<p>N. Locantore, J. Marron, D. Simpson, N. Tripoli, J. Zhang and K. Cohen K. (1999), 
Robust principal components for functional data. Test, 8, 1-28.
</p>
<p>R. Maronna, D. Martin and V. Yohai (2006), Robust Statistics: 
Theory and Methods. Wiley, New York.
</p>
<p>R. Maronna (2005). Principal components and orthogonal regression based 
on robust scales. Technometrics, 47, 264-273.    
</p>
<p>Todorov V &amp; Filzmoser P (2009), An Object Oriented Framework for Robust Multivariate Analysis. 
<em>Journal of Statistical Software</em>, <b>32</b>(3), 1â€“47.
<a href="https://doi.org/10.18637/jss.v032.i03">doi:10.18637/jss.v032.i03</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## PCA of the Hawkins Bradu Kass's Artificial Data
##  using all 4 variables
    data(hbk)
    pca &lt;- PcaLocantore(hbk)
    pca

## Compare with the classical PCA
    prcomp(hbk)

## or  
    PcaClassic(hbk)
    
## If you want to print the scores too, use
    print(pca, print.x=TRUE)

## Using the formula interface
    PcaLocantore(~., data=hbk)

## To plot the results:

    plot(pca)                    # distance plot
    pca2 &lt;- PcaLocantore(hbk, k=2)  
    plot(pca2)                   # PCA diagnostic plot (or outlier map)
    
## Use the standard plots available for for prcomp and princomp
    screeplot(pca)    
    biplot(pca)    
</code></pre>


</div>