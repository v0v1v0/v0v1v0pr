<div class="container">

<table style="width: 100%;"><tr>
<td>aicplsr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>AIC and Cp for Univariate PLSR Models</h2>

<h3>Description</h3>

<p>Computation of the AIC and Mallows's <code class="reqn">Cp</code> criteria for univariate PLSR models (Lesnoff et al. 2021). This function may receive modifications in the future (work in progress).
</p>


<h3>Usage</h3>

<pre><code class="language-R">
aicplsr(
    X, y, nlv, algo = NULL,
    meth = c("cg", "div", "cov"),
    correct = TRUE, B = 50, 
    print = FALSE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>A <code class="reqn">n x p</code> matrix or data frame of training observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>A vector of length <code class="reqn">n</code> of training responses. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlv</code></td>
<td>
<p>The maximal number of latent variables (LVs) to consider in the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>algo</code></td>
<td>
<p>a PLS algorithm. Default to  <code>NULL</code> (<code>plskern</code> is used).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>meth</code></td>
<td>
<p>Method used for estimating <code class="reqn">df</code>. Possible values are <code>"cg"</code> (<code>dfplsr_cg</code>), <code>"cov"</code> (<code>dfplsr_cov</code>)or <code>"div"</code> (<code>dfplsr_div</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>correct</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default), the AICc corection is applied to the criteria.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>
<p>For <code>meth = "div"</code>: the number of observations in the data receiving perturbation (maximum is <code class="reqn">n</code>; see <code>dfplsr_cov</code>). For <code>meth = "cov"</code>: the number of bootstrap replications (see <code>dfplsr_cov</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>print</code></td>
<td>
<p>Logical. If <code>TRUE</code>, fitting information are printed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Optionnal arguments to pass in <code>algo</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>For a model with <code class="reqn">a</code> latent variables (LVs), function <code>aicplsr</code> calculates <code class="reqn">AIC</code> and <code class="reqn">Cp</code> by:
</p>
<p><code class="reqn">AIC(a) = n * log(SSR(a)) + 2 * (df(a) + 1)</code>  
</p>
<p><code class="reqn">Cp(a) = SSR(a) / n + 2 * df(a) * s2 / n</code>  
</p>
<p>where <code class="reqn">SSR</code> is the sum of squared residuals for the current evaluated model, <code class="reqn">df(a)</code> the estimated PLSR model complexity (i.e. nb. model's degrees of freedom), <code class="reqn">s2</code> an estimate of the irreductible error variance (computed from a low biased model) and <code class="reqn">n</code> the number of training observations.  
</p>
<p>By default (argument <code>correct</code>), the small sample size correction (so-called AICc) is applied to AIC and Cp for deucing the bias. 
</p>
<p>The functions returns two estimates of Cp (<code class="reqn">cp1</code> and <code class="reqn">cp2</code>), each corresponding to a different estimate of <code class="reqn">s2</code>.
</p>
<p>The model complexity  <code class="reqn">df</code> can be computed from three methods (argument <code>meth</code>).
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>crit</code></td>
<td>
<p>dataframe with <code class="reqn">n</code>, and the etimated criteria (<code class="reqn">df</code>, <code class="reqn">ct</code>, <code class="reqn">ssr</code>, <code class="reqn">aic</code>, <code class="reqn">cp1, cp2</code>) for 0 to <code class="reqn">nlv</code> latent variables in the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta</code></td>
<td>
<p>dataframe with the differences between the estimated values of <code class="reqn">aic</code>, <code class="reqn">cp1</code> and <code class="reqn">cp2</code>, and those of the model with the lowest estimated values of <code class="reqn">aic</code>, <code class="reqn">cp1</code> and <code class="reqn">cp2</code>, for models with 0 to <code class="reqn">nlv</code> latent variables</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>opt</code></td>
<td>
<p>vector with the optimal number of latent variables in the model (i.e. minimizing aic, cp1 and cp2 values)</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Burnham, K.P., Anderson, D.R., 2002. Model selection and multimodel inference: a practical informationtheoretic approach, 2nd ed. Springer, New York, NY, USA.
</p>
<p>Burnham, K.P., Anderson, D.R., 2004. Multimodel Inference: Understanding AIC and BIC in Model
Selection. Sociological Methods &amp; Research 33, 261-304. https://doi.org/10.1177/0049124104268644
</p>
<p>Efron, B., 2004. The Estimation of Prediction Error. Journal of the American Statistical Association 99,
619-632. https://doi.org/10.1198/016214504000000692
</p>
<p>Eubank, R.L., 1999. Nonparametric Regression and Spline Smoothing, 2nd ed, Statistics: Textbooks
and Monographs. Marcel Dekker, Inc., New York, USA.
</p>
<p>Hastie, T., Tibshirani, R.J., 1990. Generalized Additive Models, Monographs on statistics and applied
probablity. Chapman and Hall/CRC, New York, USA.
</p>
<p>Hastie, T., Tibshirani, R., Friedman, J., 2009. The elements of statistical learning: data mining,
inference, and prediction, 2nd ed. Springer, NewYork.
</p>
<p>Hastie, T., Tibshirani, R., Wainwright, M., 2015. Statistical Learning with Sparsity: The Lasso and
Generalizations. CRC Press
</p>
<p>Hurvich, C.M., Tsai, C.-L., 1989. Regression and Time Series Model Selection in Small Samples. Biometrika
76, 297. https://doi.org/10.2307/2336663
</p>
<p>Lesnoff, M., Roger, J.M., Rutledge, D.N., Submitted. Monte Carlo methods for estimating Mallows's Cp and AIC criteria for PLSR models. Illustration on agronomic spectroscopic NIR data. Journal of Chemometrics.
</p>
<p>Mallows, C.L., 1973. Some Comments on Cp. Technometrics 15, 661-675.
https://doi.org/10.1080/00401706.1973.10489103
</p>
<p>Ye, J., 1998. On Measuring and Correcting the Effects of Data Mining and Model Selection. Journal of
the American Statistical Association 93, 120-131. https://doi.org/10.1080/01621459.1998.10474094
</p>
<p>Zuccaro, C., 1992. Mallows'Cp Statistic and Model Selection in Multiple Linear Regression. International Journal of Market Research. 34, 1-10. https://doi.org/10.1177/147078539203400204
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(cassav)

Xtrain &lt;- cassav$Xtrain
ytrain &lt;- cassav$ytrain

nlv &lt;- 25
res &lt;- aicplsr(Xtrain, ytrain, nlv = nlv)
names(res)
headm(res$crit)

z &lt;- res$crit
oldpar &lt;- par(mfrow = c(1, 1))
par(mfrow = c(1, 4))
plot(z$df[-1])
plot(z$aic[-1], type = "b", main = "AIC")
plot(z$cp1[-1], type = "b", main = "Cp1")
plot(z$cp2[-1], type = "b", main = "Cp2")
par(oldpar)

</code></pre>


</div>