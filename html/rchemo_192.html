<div class="container">

<table style="width: 100%;"><tr>
<td>mbplsr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>multi-block PLSR algorithms</h2>

<h3>Description</h3>

<p>Algorithm fitting a multi-block PLS1 or PLS2 model between dependent variables <code class="reqn">Xlist</code> and responses <code class="reqn">Y</code>, based on the "Improved kernel algorithm #1" proposed by Dayal and MacGregor (1997). 
</p>
<p>For weighted versions, see for instance Schaal et al. 2002, Siccard &amp; Sabatier 2006, Kim et al. 2011 and Lesnoff et al. 2020.
</p>
<p><b>Auxiliary functions</b>
</p>
<p><code>transform</code> Calculates the LVs for any new matrix <code class="reqn">X</code> from the model.
</p>
<p><code>summary</code> returns summary information for the model.
</p>
<p><code>coef</code> Calculates b-coefficients from the model, adjuted for raw data.
</p>
<p><code>predict</code> Calculates the predictions for any new matrix <code class="reqn">X</code> from the model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">
mbplsr(Xlist, Y, blockscaling = TRUE, weights = NULL, nlv, 
Xscaling = c("none", "pareto", "sd")[1], Yscaling = c("none", "pareto", "sd")[1])

## S3 method for class 'Mbplsr'
transform(object, X, ..., nlv = NULL)  

## S3 method for class 'Mbplsr'
summary(object, X, ...)  

## S3 method for class 'Mbplsr'
coef(object, ..., nlv = NULL) 

## S3 method for class 'Mbplsr'
predict(object, X, ..., nlv = NULL)  

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Xlist</code></td>
<td>
<p>For the main function: list of training X-data (<code class="reqn">n</code>rows).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>For the auxiliary functions: list of new X-data, with the same variables than the training X-data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>Training Y-data (<code class="reqn">n, q</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>blockscaling</code></td>
<td>
<p>logical. If TRUE, the scaling factor (computed on the training) is the "norm" of the block, i.e. the square root of the sum of the variances of each column of the block.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>Weights (<code class="reqn">n, 1</code>) to apply to the training observations. Internally, weights are "normalized" to sum to 1. Default to <code>NULL</code> (weights are set to <code class="reqn">1 / n</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlv</code></td>
<td>
<p>For the main functions: The number(s) of LVs to calculate. — For the auxiliary functions: The number(s) of LVs to consider.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xscaling</code></td>
<td>
<p>vector (of length Xlist) of variable scaling for each datablock, among "none" (mean-centering only), "pareto" (mean-centering and pareto scaling), "sd" (mean-centering and unit variance scaling). If "pareto" or "sd", uncorrected standard deviation is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Yscaling</code></td>
<td>
<p>character. variable scaling for the Y-block, among "none" (mean-centering only), "pareto" (mean-centering and pareto scaling), "sd" (mean-centering and unit variance scaling). If "pareto" or "sd", uncorrected standard deviation is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>For the auxiliary functions: A fitted model, output of a call to the main functions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>For the auxiliary functions: Optional arguments. Not used.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list of outputs, such as
</p>
<table>
<tr style="vertical-align: top;">
<td><code>T</code></td>
<td>
<p>The X-score matrix (<code class="reqn">n, nlv</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>P</code></td>
<td>
<p>The X-loadings matrix (<code class="reqn">p, nlv</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>W</code></td>
<td>
<p>The X-loading weights matrix (<code class="reqn">p, nlv</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>C</code></td>
<td>
<p>The Y-loading weights matrix (C = t(Beta), where Beta is the scores regression coefficients matrix).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>R</code></td>
<td>
<p>The PLS projection matrix (<code class="reqn">p, nlv</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xmeans</code></td>
<td>
<p>The list of centering vectors of <code class="reqn">Xlist</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ymeans</code></td>
<td>
<p>The centering vector of <code class="reqn">Y</code> (<code class="reqn">q, 1</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xscales</code></td>
<td>
<p>The list of <code class="reqn">Xlist</code> variable standard deviations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>yscales</code></td>
<td>
<p>The vector of <code class="reqn">Y</code> variable standard deviations (<code class="reqn">q, 1</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>Weights applied to the training observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>TT</code></td>
<td>
<p>the X-score normalization factor.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>blockscaling</code></td>
<td>
<p>block scaling.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xnorms</code></td>
<td>
<p>"norm" of each block, i.e. the square root of the sum of the variances of each column of each block, computed on the training, and used as scaling factor</p>
</td>
</tr>
</table>
<p>.
</p>
<table><tr style="vertical-align: top;">
<td><code>U</code></td>
<td>
<p>intermediate output.</p>
</td>
</tr></table>
<p>For <code>transform.Mbplsr</code>: X-scores matrix for new Xlist-data.
</p>
<p>For <code>summary.Mbplsr</code>:
</p>
<table><tr style="vertical-align: top;">
<td><code>explvarx</code></td>
<td>
<p>matrix of explained variances.</p>
</td>
</tr></table>
<p>For <code>coef.Mbplsr</code>: 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>int</code></td>
<td>
<p>matrix (1,nlv) with the intercepts</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>
<p>matrix (n,nlv) with the coefficients</p>
</td>
</tr>
</table>
<p>For <code>predict.Mbplsr</code>: 
</p>
<table><tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>A list of matrices (<code class="reqn">m, q</code>) with the Y predicted values for the new Xlist-data</p>
</td>
</tr></table>
<h3>References</h3>

<p>Andersson, M., 2009. A comparison of nine PLS1 algorithms. Journal of Chemometrics 23, 518-529.
</p>
<p>Dayal, B.S., MacGregor, J.F., 1997. Improved PLS algorithms. Journal of Chemometrics 11, 73-85.
</p>
<p>Hoskuldsson, A., 1988. PLS regression methods. Journal of Chemometrics 2, 211-228. https://doi.org/10.1002/cem.1180020306
</p>
<p>Kim, S., Kano, M., Nakagawa, H., Hasebe, S., 2011. Estimation of active pharmaceutical ingredients content using locally weighted partial least squares and statistical wavelength selection. Int. J. Pharm., 421, 269-274.
</p>
<p>Lesnoff, M., Metz, M., Roger, J.M., 2020. Comparison of locally weighted PLS strategies for regression and discrimination on agronomic NIR Data. Journal of Chemometrics. e3209. https://onlinelibrary.wiley.com/doi/abs/10.1002/cem.3209
</p>
<p>Rannar, S., Lindgren, F., Geladi, P., Wold, S., 1994. A PLS kernel algorithm for data sets with many variables and fewer objects. Part 1: Theory and algorithm. Journal of Chemometrics 8, 111-125. https://doi.org/10.1002/cem.1180080204
</p>
<p>Schaal, S., Atkeson, C., Vijayamakumar, S. 2002. Scalable techniques from nonparametric statistics for the real time robot learning. Applied Intell., 17, 49-60.
</p>
<p>Sicard, E. Sabatier, R., 2006. Theoretical framework for local PLS1 regression and application to a rainfall data set. Comput. Stat. Data Anal., 51, 1393-1410.
</p>
<p>Tenenhaus, M., 1998. La régression PLS: théorie et pratique. Editions Technip, Paris, France.
</p>
<p>Wold, S., Sjostrom, M., Eriksson, l., 2001. PLS-regression: a basic tool for chemometrics. Chem. Int. Lab. Syst., 58, 109-130.
</p>


<h3>See Also</h3>

<p><code>mbplsr_mbplsda_allsteps</code> function to help determine the optimal number of latent variables, perform a permutation test, calculate model parameters and predict new observations.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
n &lt;- 10 ; p &lt;- 10
Xtrain &lt;- matrix(rnorm(n * p), ncol = p)
ytrain &lt;- rnorm(n)

m &lt;- 2
Xtest &lt;- matrix(rnorm(m * p), ncol = p)

colnames(Xtrain) &lt;- colnames(Xtest) &lt;- paste("v", 1:p, sep = "")

Xtrain
Xtest

blocks &lt;- list(1:2, 4, 6:8)
X1 &lt;- mblocks(Xtrain, blocks = blocks)
X2 &lt;- mblocks(Xtest, blocks = blocks)

nlv &lt;- 3
fm &lt;- mbplsr(Xlist = X1, Y = ytrain, Xscaling = c("sd","none","none"), 
blockscaling = TRUE, weights = NULL, nlv = nlv)

summary(fm, X1)
coef(fm)
transform(fm, X2)
predict(fm, X2)

</code></pre>


</div>