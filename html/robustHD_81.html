<div class="container">

<table style="width: 100%;"><tr>
<td>sparseLTS</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Sparse least trimmed squares regression</h2>

<h3>Description</h3>

<p>Compute least trimmed squares regression with an <code class="reqn">L_{1}</code> penalty on
the regression coefficients, which allows for sparse model estimates.
</p>


<h3>Usage</h3>

<pre><code class="language-R">sparseLTS(x, ...)

## S3 method for class 'formula'
sparseLTS(formula, data, ...)

## Default S3 method:
sparseLTS(
  x,
  y,
  lambda,
  mode = c("lambda", "fraction"),
  alpha = 0.75,
  normalize = TRUE,
  intercept = TRUE,
  nsamp = c(500, 10),
  initial = c("sparse", "hyperplane", "random"),
  ncstep = 2,
  use.correction = TRUE,
  tol = .Machine$double.eps^0.5,
  eps = .Machine$double.eps,
  use.Gram,
  crit = c("BIC", "PE"),
  splits = foldControl(),
  cost = rtmspe,
  costArgs = list(),
  selectBest = c("hastie", "min"),
  seFactor = 1,
  ncores = 1,
  cl = NULL,
  seed = NULL,
  model = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a numeric matrix containing the predictor variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments to be passed down.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>a formula describing the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>an optional data frame, list or environment (or object coercible
to a data frame by <code>as.data.frame</code>) containing the variables in
the model.  If not found in data, the variables are taken from
<code>environment(formula)</code>, typically the environment from which
<code>sparseLTS</code> is called.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a numeric vector containing the response variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>a numeric vector of non-negative values to be used as penalty
parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mode</code></td>
<td>
<p>a character string specifying the type of penalty parameter.  If
<code>"lambda"</code>, <code>lambda</code> gives the grid of values for the penalty
parameter directly.  If <code>"fraction"</code>, the smallest value of the penalty
parameter that sets all coefficients to 0 is first estimated based on
bivariate winsorization, then <code>lambda</code> gives the fractions of that
estimate to be used (hence all values of <code>lambda</code> should be in the
interval [0,1] in that case).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>a numeric value giving the percentage of the residuals for
which the <code class="reqn">L_{1}</code> penalized sum of squares should be minimized (the
default is 0.75).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>normalize</code></td>
<td>
<p>a logical indicating whether the predictor variables
should be normalized to have unit <code class="reqn">L_{2}</code> norm (the default is
<code>TRUE</code>).  Note that normalization is performed on the subsamples
rather than the full data set.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>a logical indicating whether a constant term should be
included in the model (the default is <code>TRUE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nsamp</code></td>
<td>
<p>a numeric vector giving the number of subsamples to be used in
the two phases of the algorithm.  The first element gives the number of
initial subsamples to be used.  The second element gives the number of
subsamples to keep after the first phase of <code>ncstep</code> C-steps.  For
those remaining subsets, additional C-steps are performed until
convergence.  The default is to first perform <code>ncstep</code> C-steps on 500
initial subsamples, and then to keep the 10 subsamples with the lowest value
of the objective function for additional C-steps until convergence.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initial</code></td>
<td>
<p>a character string specifying the type of initial subsamples
to be used.  If <code>"sparse"</code>, the lasso fit given by three randomly
selected data points is first computed.  The corresponding initial subsample
is then formed by the fraction <code>alpha</code> of data points with the smallest
squared residuals.  Note that this is optimal from a robustness point of
view, as the probability of including an outlier in the initial lasso fit is
minimized.  If <code>"hyperplane"</code>, a hyperplane through <code class="reqn">p</code> randomly
selected data points is first computed, where <code class="reqn">p</code> denotes the number of
variables.  The corresponding initial subsample is then again formed by the
fraction <code>alpha</code> of data points with the smallest squared residuals.
Note that this cannot be applied if <code class="reqn">p</code> is larger than the number of
observations.  Nevertheless, the probability of including an outlier
increases with increasing dimension <code class="reqn">p</code>.  If <code>"random"</code>, the
initial subsamples are given by a fraction <code>alpha</code> of randomly
selected data points.  Note that this leads to the largest probability of
including an outlier.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncstep</code></td>
<td>
<p>a positive integer giving the number of C-steps to perform on
all subsamples in the first phase of the algorithm (the default is to
perform two C-steps).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use.correction</code></td>
<td>
<p>currently ignored.  Small sample correction factors
may be added in the future.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>a small positive numeric value giving the tolerance for
convergence.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>a small positive numeric value used to determine whether the
variability within a variable is too small (an effective zero).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use.Gram</code></td>
<td>
<p>a logical indicating whether the Gram matrix of the
explanatory variables should be precomputed in the lasso fits on the
subsamples.  If the number of variables is large, computation may be faster
when this is set to <code>FALSE</code>.  The default is to use <code>TRUE</code> if the
number of variables is smaller than the number of observations in the
subsamples and smaller than 100, and <code>FALSE</code> otherwise.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>crit</code></td>
<td>
<p>a character string specifying the optimality criterion to be
used for selecting the final model.  Possible values are <code>"BIC"</code> for
the Bayes information criterion and <code>"PE"</code> for resampling-based
prediction error estimation.  This is ignored if <code>lambda</code> contains
only one value of the penalty parameter, as selecting the optimal value
is trivial in that case.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>splits</code></td>
<td>
<p>an object giving data splits to be used for prediction error
estimation (see <code>perryTuning</code>).  This is only relevant
if selecting the optimal <code>lambda</code> via prediction error estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cost</code></td>
<td>
<p>a cost function measuring prediction loss (see
<code>perryTuning</code> for some requirements).  The
default is to use the root trimmed mean squared prediction error
(see <code>cost</code>).  This is only relevant if selecting
the optimal <code>lambda</code> via prediction error estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>costArgs</code></td>
<td>
<p>a list of additional arguments to be passed to the
prediction loss function <code>cost</code>.  This is only relevant if
selecting the optimal <code>lambda</code> via prediction error estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectBest, seFactor</code></td>
<td>
<p>arguments specifying a criterion for selecting
the best model (see <code>perryTuning</code>).  The default is to
use a one-standard-error rule.  This is only relevant if selecting the
optimal <code>lambda</code> via prediction error estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncores</code></td>
<td>
<p>a positive integer giving the number of processor cores to be
used for parallel computing (the default is 1 for no parallelization).  If
this is set to <code>NA</code>, all available processor cores are used.  For
prediction error estimation, parallel computing is implemented on the <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span>
level using package <span class="pkg">parallel</span>.  Otherwise parallel computing is
implemented on the C++ level  via OpenMP (<a href="https://www.openmp.org/">https://www.openmp.org/</a>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cl</code></td>
<td>
<p>a <span class="pkg">parallel</span> cluster for parallel computing as generated by
<code>makeCluster</code>.  This is preferred over <code>ncores</code>
for prediction error estimation, in which case <code>ncores</code> is only used on
the C++ level for computing the final model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>optional initial seed for the random number generator (see
<code>.Random.seed</code>).  On parallel <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> worker processes for prediction
error estimation, random number streams are used and the seed is set via
<code>clusterSetRNGStream</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>a logical indicating whether the data <code>x</code> and <code>y</code>
should be added to the return object.  If <code>intercept</code> is <code>TRUE</code>,
a column of ones is added to <code>x</code> to account for the intercept.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>If <code>crit</code> is <code>"PE"</code> and <code>lambda</code> contains more than one
value of the penalty parameter, an object of class <code>"perrySparseLTS"</code>
(inheriting from class <code>"perryTuning"</code>, see
<code>perryTuning</code>).  It contains information on the
prediction error criterion, and includes the final model with the optimal
tuning paramter as component <code>finalModel</code>.
</p>
<p>Otherwise an object of class <code>"sparseLTS"</code> with the following
components:
</p>

<dl>
<dt><code>lambda</code></dt>
<dd>
<p>a numeric vector giving the values of the penalty
parameter.</p>
</dd>
<dt><code>best</code></dt>
<dd>
<p>an integer vector or matrix containing the respective
best subsets of <code class="reqn">h</code> observations found and used for computing the raw
estimates.</p>
</dd>
<dt><code>objective</code></dt>
<dd>
<p>a numeric vector giving the respective values of
the sparse LTS objective function, i.e., the <code class="reqn">L_{1}</code> penalized
sums of the <code class="reqn">h</code> smallest squared residuals from the raw fits.</p>
</dd>
<dt><code>coefficients</code></dt>
<dd>
<p>a numeric vector or matrix containing the
respective coefficient estimates from the reweighted fits.</p>
</dd>
<dt><code>fitted.values</code></dt>
<dd>
<p>a numeric vector or matrix containing the
respective fitted values of the response from the reweighted fits.</p>
</dd>
<dt><code>residuals</code></dt>
<dd>
<p>a numeric vector or matrix containing the
respective residuals from the reweighted fits.</p>
</dd>
<dt><code>center</code></dt>
<dd>
<p>a numeric vector giving the robust center estimates
of the corresponding reweighted residuals.</p>
</dd>
<dt><code>scale</code></dt>
<dd>
<p>a numeric vector giving the robust scale estimates of
the corresponding reweighted residuals.</p>
</dd>
<dt><code>cnp2</code></dt>
<dd>
<p>a numeric vector giving the respective consistency
factors applied to the scale estimates of the reweighted residuals.</p>
</dd>
<dt><code>wt</code></dt>
<dd>
<p>an integer vector or matrix containing binary weights
that indicate outliers from the respective reweighted fits, i.e., the
weights are <code class="reqn">1</code> for observations with reasonably small reweighted
residuals and <code class="reqn">0</code> for observations with large reweighted residuals.</p>
</dd>
<dt><code>df</code></dt>
<dd>
<p>an integer vector giving the respective degrees of
freedom of the obtained reweighted model fits, i.e., the number of
nonzero coefficient estimates.</p>
</dd>
<dt><code>intercept</code></dt>
<dd>
<p>a logical indicating whether the model includes a
constant term.</p>
</dd>
<dt><code>alpha</code></dt>
<dd>
<p>a numeric value giving the percentage of the residuals
for which the <code class="reqn">L_{1}</code> penalized sum of squares was minimized.</p>
</dd>
<dt><code>quan</code></dt>
<dd>
<p>the number <code class="reqn">h</code> of observations used to compute the
raw estimates.</p>
</dd>
<dt><code>raw.coefficients</code></dt>
<dd>
<p>a numeric vector or matrix containing the
respective coefficient estimates from the raw fits.</p>
</dd>
<dt><code>raw.fitted.values</code></dt>
<dd>
<p>a numeric vector or matrix containing the
respective fitted values of the response from the raw fits.</p>
</dd>
<dt><code>raw.residuals</code></dt>
<dd>
<p>a numeric vector or matrix containing the
respective residuals from the raw fits.</p>
</dd>
<dt><code>raw.center</code></dt>
<dd>
<p>a numeric vector giving the robust center
estimates of the corresponding raw residuals.</p>
</dd>
<dt><code>raw.scale</code></dt>
<dd>
<p>a numeric vector giving the robust scale estimates
of the corresponding raw residuals.</p>
</dd>
<dt><code>raw.cnp2</code></dt>
<dd>
<p>a numeric value giving the consistency factor
applied to the scale estimate of the raw residuals.</p>
</dd>
<dt><code>raw.wt</code></dt>
<dd>
<p>an integer vector or matrix containing binary weights
that indicate outliers from the respective raw fits, i.e., the weights
used for the reweighted fits.</p>
</dd>
<dt><code>crit</code></dt>
<dd>
<p>an object of class <code>"bicSelect"</code> containing the
BIC values and indicating the final model (only returned if argument
<code>crit</code> is <code>"BIC"</code> and argument <code>lambda</code> contains more
than one value for the penalty parameter).</p>
</dd>
<dt><code>x</code></dt>
<dd>
<p>the predictor matrix (if <code>model</code> is <code>TRUE</code>).</p>
</dd>
<dt><code>y</code></dt>
<dd>
<p>the response variable (if <code>model</code> is <code>TRUE</code>).</p>
</dd>
<dt><code>call</code></dt>
<dd>
<p>the matched function call.</p>
</dd>
</dl>
<h3>Note</h3>

<p>The underlying C++ code uses the C++ library Armadillo.  From package
version 0.6.0, the back end for sparse least trimmed squares from package
<span class="pkg">sparseLTSEigen</span>, which uses the C++ library Eigen, is no longer
supported and can no longer be used.
</p>
<p>Parallel computing is implemented via OpenMP (<a href="https://www.openmp.org/">https://www.openmp.org/</a>).
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>References</h3>

<p>Alfons, A., Croux, C. and Gelper, S. (2013) Sparse least trimmed squares
regression for analyzing high-dimensional large data sets. <em>The Annals
of Applied Statistics</em>, <b>7</b>(1), 226–248. <a href="https://doi.org/10.1214/12-AOAS575">doi:10.1214/12-AOAS575</a>
</p>


<h3>See Also</h3>

<p><code>coef</code>,
<code>fitted</code>,
<code>plot</code>,
<code>predict</code>,
<code>residuals</code>,
<code>rstandard</code>,
<code>weights</code>,
<code>ltsReg</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## generate data
# example is not high-dimensional to keep computation time low
library("mvtnorm")
set.seed(1234)  # for reproducibility
n &lt;- 100  # number of observations
p &lt;- 25   # number of variables
beta &lt;- rep.int(c(1, 0), c(5, p-5))  # coefficients
sigma &lt;- 0.5      # controls signal-to-noise ratio
epsilon &lt;- 0.1    # contamination level
Sigma &lt;- 0.5^t(sapply(1:p, function(i, j) abs(i-j), 1:p))
x &lt;- rmvnorm(n, sigma=Sigma)    # predictor matrix
e &lt;- rnorm(n)                   # error terms
i &lt;- 1:ceiling(epsilon*n)       # observations to be contaminated
e[i] &lt;- e[i] + 5                # vertical outliers
y &lt;- c(x %*% beta + sigma * e)  # response
x[i,] &lt;- x[i,] + 5              # bad leverage points

## fit sparse LTS model for one value of lambda
sparseLTS(x, y, lambda = 0.05, mode = "fraction")

## fit sparse LTS models over a grid of values for lambda
frac &lt;- seq(0.2, 0.05, by = -0.05)
sparseLTS(x, y, lambda = frac, mode = "fraction")
</code></pre>


</div>