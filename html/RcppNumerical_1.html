<div class="container">

<table style="width: 100%;"><tr>
<td>fastLR</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fast Logistic Regression Fitting Using L-BFGS Algorithm</h2>

<h3>Description</h3>

<p><code>fastLR()</code> uses the L-BFGS algorithm to efficiently fit logistic
regression. It is in fact an application of the C++ function
<code>optim_lbfgs()</code> provided by <span class="pkg">RcppNumerical</span> to perform L-BFGS
optimization.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fastLR(
  x,
  y,
  start = rep(0, ncol(x)),
  eps_f = 1e-08,
  eps_g = 1e-05,
  maxit = 300
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>The model matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>The response vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start</code></td>
<td>
<p>The initial guess of the coefficient vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps_f</code></td>
<td>
<p>Iteration stops if <code class="reqn">|f-f'|/|f|&lt;\epsilon_f</code>,
where <code class="reqn">f</code> and <code class="reqn">f'</code> are the current and previous value
of the objective function (negative log likelihood) respectively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps_g</code></td>
<td>
<p>Iteration stops if
<code class="reqn">||g|| &lt; \epsilon_g * \max(1, ||\beta||)</code>,
where <code class="reqn">\beta</code> is the current coefficient vector and
<code class="reqn">g</code> is the gradient.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxit</code></td>
<td>
<p>Maximum number of iterations.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p><code>fastLR()</code> returns a list with the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>coefficients</code></td>
<td>
<p>Coefficient vector</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitted.values</code></td>
<td>
<p>The fitted probability values</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>linear.predictors</code></td>
<td>
<p>The fitted values of the linear part, i.e.,
<code class="reqn">X\hat{\beta}</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loglikelihood</code></td>
<td>
<p>The maximized log likelihood</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>converged</code></td>
<td>
<p>Whether the optimization algorithm has converged</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Yixuan Qiu <a href="https://statr.me">https://statr.me</a>
</p>


<h3>See Also</h3>

<p><code>glm.fit()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(123)
n = 1000
p = 100
x = matrix(rnorm(n * p), n)
beta = runif(p)
xb = c(x %*% beta)
p = 1 / (1 + exp(-xb))
y = rbinom(n, 1, p)

system.time(res1 &lt;- glm.fit(x, y, family = binomial()))
system.time(res2 &lt;- fastLR(x, y))
max(abs(res1$coefficients - res2$coefficients))
</code></pre>


</div>