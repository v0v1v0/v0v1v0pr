<div class="container">

<table style="width: 100%;"><tr>
<td>getValidation</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Extract validation results from superClass objects</h2>

<h3>Description</h3>

<p>Extract validation results from superClass objects
</p>


<h3>Usage</h3>

<pre><code class="language-R">getValidation(x, from = "testset", metrics = "overall")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>superClass object or caret::confusionMatrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>from</code></td>
<td>
<p>Character. 'testset' extracts the results from independent validation with testset. 'cv' extracts cross-validation results.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metrics</code></td>
<td>
<p>Character. Only relevant in classification mode (ignored for regression models). 
Select 'overall' for overall accuracy metrics, 'classwise' for classwise metrics, 
'confmat' for the confusion matrix itself and 'caret' to return the whole caret::confusionMatrix object.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Returns a data.frame with validation results. 
If metrics = 'confmat' or 'caret' will return a table or the full caret::confusionMatrix object, respectively.
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(pls)
## Fit classifier (splitting training into 70\% training data, 30\% validation data)
train &lt;- readRDS(system.file("external/trainingPoints_rlogo.rds", package="RStoolbox"))
SC   &lt;- superClass(rlogo, trainData = train, responseCol = "class",
                    model="pls", trainPartition = 0.7)
## Independent testset-validation
getValidation(SC)
getValidation(SC, metrics = "classwise")
## Cross-validation based 
getValidation(SC, from = "cv")
</code></pre>


</div>