<div class="container">

<table style="width: 100%;"><tr>
<td>revealPrefModel</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Model Falsification with Random Limited Attention</h2>

<h3>Description</h3>

<p>Given a collection of choice problems and corresponding
choice probabilities, <code>revealPrefModel</code> determines if they are compatible with
the Random Attention Model (RAM) of
<a href="https://arxiv.org/abs/1712.03448">Cattaneo, Ma, Masatlioglu, and Suleymanov (2020)</a>
and/or the Attention Overload Model (AOM) of
<a href="https://arxiv.org/abs/2110.10650">Cattaneo, Cheung, Ma, and Masatlioglu (2024)</a>.
</p>
<p>See <code>revealPref</code> for revealed preference analysis with empirical choice data.
</p>


<h3>Usage</h3>

<pre><code class="language-R">revealPrefModel(
  menu,
  prob,
  pref_list = NULL,
  RAM = TRUE,
  AOM = TRUE,
  limDataCorr = TRUE,
  attBinary = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>menu</code></td>
<td>
<p>Numeric matrix of 0s and 1s, the collection of choice problems.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prob</code></td>
<td>
<p>Numeric matrix, the collection of choice probabilities</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pref_list</code></td>
<td>
<p>Numeric matrix, each row corresponds to one preference. For example, <code>c(2, 3, 1)</code> means
2 is preferred to 3 and to 1. When set to <code>NULL</code>, the default, <code>c(1, 2, 3, ...)</code>,
will be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>RAM</code></td>
<td>
<p>Boolean, whether the restrictions implied by the RAM of
<a href="https://arxiv.org/abs/1712.03448">Cattaneo et al. (2020)</a> should be incorporated, that is, their monotonic attention assumption (default is <code>TRUE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>AOM</code></td>
<td>
<p>Boolean, whether the restrictions implied by the AOM of
<a href="https://arxiv.org/abs/2110.10650">Cattaneo et al. (2024)</a> should be incorporated, that is, their attention overload assumption (default is <code>TRUE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>limDataCorr</code></td>
<td>
<p>Boolean, whether assuming limited data (default is <code>TRUE</code>). When set to
<code>FALSE</code>, will assume all choice problems are observed. This option only applies when <code>RAM</code> is set to <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>attBinary</code></td>
<td>
<p>Numeric, between 1/2 and 1 (default is <code>1</code>), whether additional restrictions (on the attention rule)
should be imposed for binary choice problems (i.e., attentive at binaries).</p>
</td>
</tr>
</table>
<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>constraints</code></td>
<td>
<p>Matrices of constraints, generated by <code>genMat</code>. <code>R</code>: a matrix containing all constraints. <code>ConstN</code>: number of constraints for each preference.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>inequalities</code></td>
<td>
<p>The moment inequalities. Positive numbers indicate that the RAM/AOM restrictions are rejected by the given choice probabilities. <code>R</code>: a vector containing all moment inequalities. <code>ConstN</code>: number of constraints for each preference.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Matias D. Cattaneo, Princeton University. <a href="mailto:cattaneo@princeton.edu">cattaneo@princeton.edu</a>.
</p>
<p>Paul Cheung, University of Maryland. <a href="mailto:hycheung@umd.edu">hycheung@umd.edu</a>
</p>
<p>Xinwei Ma (maintainer), University of California San Diego. <a href="mailto:x1ma@ucsd.edu">x1ma@ucsd.edu</a>
</p>
<p>Yusufcan Masatlioglu, University of Maryland. <a href="mailto:yusufcan@umd.edu">yusufcan@umd.edu</a>
</p>
<p>Elchin Suleymanov, Purdue University. <a href="mailto:esuleyma@purdue.edu">esuleyma@purdue.edu</a>
</p>


<h3>References</h3>

<p>M. D. Cattaneo, X. Ma, Y. Masatlioglu, and E. Suleymanov (2020). <a href="https://arxiv.org/abs/1712.03448">A Random Attention Model</a>. <em>Journal of Political Economy</em> 128(7): 2796-2836. <a href="https://doi.org/10.1086/706861">doi:10.1086/706861</a>
</p>
<p>M. D. Cattaneo, P. Cheung, X. Ma, and Y. Masatlioglu (2024). <a href="https://arxiv.org/abs/2110.10650">Attention Overload</a>. Working paper.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Logit attention with parameter 2
# True preference: 1 2 3 4 5 6
menu &lt;- prob &lt;- matrix(c(1, 1, 1, 1, 1, 1,
                         0, 1, 1, 1, 1, 1,
                         1, 0, 1, 1, 1, 1,
                         1, 1, 0, 1, 1, 1,
                         1, 1, 1, 0, 1, 1,
                         1, 1, 1, 1, 0, 1,
                         1, 1, 1, 1, 1, 0), ncol=6, byrow=TRUE)
for (i in 1:nrow(prob)) prob[i, menu[i, ]==1] &lt;- logitAtte(sum(menu[i, ]), 2)$choiceProb

# List of preferences to be tested
pref_list &lt;- matrix(c(1, 2, 3, 4, 5, 6,
                      2, 3, 4, 5, 6, 1), ncol=6, byrow=TRUE)
# RAM only
result1 &lt;- revealPrefModel(menu = menu, prob = prob, pref_list = pref_list, RAM = TRUE, AOM = FALSE)
summary(result1)

# AOM only
result2 &lt;- revealPrefModel(menu = menu, prob = prob, pref_list = pref_list, RAM = FALSE, AOM = TRUE)
summary(result2)

# Both RAM and AOM
result3 &lt;- revealPrefModel(menu = menu, prob = prob, pref_list = pref_list, RAM = TRUE, AOM = TRUE)
summary(result3)

</code></pre>


</div>