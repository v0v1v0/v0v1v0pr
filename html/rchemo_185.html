<div class="container">

<table style="width: 100%;"><tr>
<td>svmr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>SVM Regression and Discrimination</h2>

<h3>Description</h3>

<p>SVM models with Gaussian (RBF) kernel.
</p>
<p><code>svmr</code>: SVM regression (SVMR).
</p>
<p><code>svmda</code>: SVM discrimination (SVMC).
</p>
<p>The SVM models are fitted with parameterization <code class="reqn">'C'</code>, not the <code class="reqn">'nu'</code> parameterization. 
</p>
<p>The RBF kernel is defined by: exp(-gamma * |x - y|^2).
</p>
<p>For tuning the model, usual preliminary ranges are for instance:
</p>
<p>- cost = 10^(-5:15)
</p>
<p>- epsilon = seq(.1, .3, by = .1)
</p>
<p>- gamma = 10^(-6:3)
</p>
<p>The functions uses function <code>svm</code> of package <code>e1071</code> (Meyer et al. 2021) available on CRAN (e1071 uses the tool box LIVSIM; Chang &amp; Lin, http://www.csie.ntu.edu.tw/~cjlin/libsvm). 
</p>


<h3>Usage</h3>

<pre><code class="language-R">
svmr(X, y, cost = 1, epsilon = .1, gamma = 1, scale = FALSE)

svmda(X, y, cost = 1, epsilon = .1, gamma = 1, scale = FALSE)

## S3 method for class 'Svm'
predict(object, X, ...)  

## S3 method for class 'Svm'
summary(object, ...)  

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>For the main functions: Training X-data (<code class="reqn">n, p</code>). â€” For the auxiliary functions: New X-data (<code class="reqn">m, p</code>) to consider.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Training Y-data (<code class="reqn">n</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cost</code></td>
<td>
<p>The cost of constraints violation <code class="reqn">cost</code> parameter. See <code>svm</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epsilon</code></td>
<td>
<p>The <code class="reqn">epsilon</code> parameter in the insensitive-loss function. See <code>svm</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma</code></td>
<td>
<p>The <code class="reqn">gamma</code> parameter in the RBF kernel.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>Logical. If <code>TRUE</code>, <code>X</code> and <code>Y</code> are scaled internally.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>For the auxiliary functions: A fitted model, output of a call to the main function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>For the auxiliary functions: Optional arguments.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>For <code>svmr</code> and <code>svmda</code>:
</p>
<table><tr style="vertical-align: top;">
<td><code>fm</code></td>
<td>
<p>list of outputs such as:
<code>call</code>; <code>type</code>; <code>kernel</code>; <code>cost</code>; <code>degree</code>; <code>gamma</code>; <code>coef0</code>; <code>nu</code>; <code>epsilon</code>; <code>sparse</code>; <code>scaled</code>; <code>x.scale</code>; <code>y.scale</code>; <code>nclasses</code>; <code>levels</code>; <code>tot.nSV</code>; <code>nSV</code>; <code>labels</code>; <code>SV</code>: The resulting support vectors (possibly scaled); <code>index</code>: The index of the resulting support vectors in the data matrix. Note that this index refers to the preprocessed data (after the possible effect of na.omit and subset); <code>rho</code>: The negative intercept; <code>compprob</code>; <code>probA, probB</code>: numeric vectors of length k(k-1)/2, k number of classes, containing the parameters of the logistic distributions fitted to the decision values of the binary classifiers (1 / (1 + exp(a x + b))); <code>sigma</code>: In case of a probabilistic regression model, the scale parameter of the hypothesized (zero-mean) laplace distribution estimated by maximum likelihood; <code>coefs</code>: The corresponding coefficients times the training labels; <code>na.action</code>; <code>fitted</code>; <code>decision.values</code>; <code>residuals</code>; <code>isnum</code>.</p>
</td>
</tr></table>
<p>For <code>predict.Svm</code>:
</p>
<table><tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>predictions for each observation.</p>
</td>
</tr></table>
<p>For <code>summary.Svm</code>:display of call, parameters, and number of support vectors.
</p>


<h3>Note</h3>

<p>The first example illustrates SVMR.
The second one is the example of fitting the function sinc(x) described in Rosipal &amp; Trejo 2001 p. 105-106.
The third one illustrates SVMC.
</p>


<h3>References</h3>

<p>Meyer, M. 2021 Support Vector Machines - The Interface to libsvm in package e1071. FH Technikum Wien, Austria, David.Meyer@R-Project.org. https://cran.r-project.org/web/packages/e1071/vignettes/svmdoc.pdf
</p>
<p>Chang, cost.-cost. &amp; Lin, cost.-J. (2001). LIBSVM: a library for support vector machines. Software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm. Detailed documentation (algorithms, formulae, . . . ) can be found in http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.ps.gz
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## EXAMPLE 1 (SVMR)

n &lt;- 50 ; p &lt;- 4
Xtrain &lt;- matrix(rnorm(n * p), ncol = p)
ytrain &lt;- rnorm(n)
m &lt;- 3
Xtest &lt;- Xtrain[1:m, , drop = FALSE] 
ytest &lt;- ytrain[1:m]

fm &lt;- svmr(Xtrain, ytrain)
predict(fm, Xtest)

pred &lt;- predict(fm, Xtest)$pred
msep(pred, ytest)

summary(fm)

## EXAMPLE 2 

x &lt;- seq(-10, 10, by = .2)
x[x == 0] &lt;- 1e-5
n &lt;- length(x)
zy &lt;- sin(abs(x)) / abs(x)
y &lt;- zy + rnorm(n, 0, .2)
plot(x, y, type = "p")
lines(x, zy, lty = 2)
X &lt;- matrix(x, ncol = 1)

fm &lt;- svmr(X, y, gamma = .5)
pred &lt;- predict(fm, X)$pred
plot(X, y, type = "p")
lines(X, zy, lty = 2)
lines(X, pred, col = "red")

## EXAMPLE 3 (SVMC)

n &lt;- 50 ; p &lt;- 8
Xtrain &lt;- matrix(rnorm(n * p), ncol = p)
ytrain &lt;- sample(c("a", "10", "d"), size = n, replace = TRUE)
m &lt;- 5
Xtest &lt;- Xtrain[1:m, ] ; ytest &lt;- ytrain[1:m]

cost &lt;- 100 ; epsilon &lt;- .1 ; gamma &lt;- 1 
fm &lt;- svmda(Xtrain, ytrain,
    cost = cost, epsilon = epsilon, gamma = gamma)
predict(fm, Xtest)

pred &lt;- predict(fm, Xtest)$pred
err(pred, ytest)

summary(fm)

</code></pre>


</div>