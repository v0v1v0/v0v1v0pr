<div class="container">

<table style="width: 100%;"><tr>
<td>Many simple linear regressions coefficients</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Simple linear regressions coefficients
</h2>

<h3>Description</h3>

<p>Simple linear regressions coefficients.
</p>


<h3>Usage</h3>

<pre><code class="language-R">allbetas(y, x, pvalue = FALSE, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>A numerical vector with the response variable. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>A matrix with the data, where rows denotes the observations and the columns contain the independent variables.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pvalue</code></td>
<td>

<p>If you want a hypothesis test that each slope (beta coefficient) is equal to zero set this equal to TRUE. It will also produce all the correlations between y and x.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logged</code></td>
<td>

<p>A boolean variable; it will return the logarithm of the pvalue if set to TRUE.
</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A matrix with the constant (alpha) and the slope (beta) for each simple linear regression. 
If the p-value is set to TRUE, the correlation of each y with the x is calculated along with the relevant test statistic and its associated p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> mvbetas, correls, univglms, colsums, colVars
</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">x &lt;- matrix( rnorm(100 * 50), ncol = 50 )
y &lt;- rnorm(100)
r &lt;- cor(y, x)  ## correlation of y with each of the xs
a &lt;- allbetas(y, x)  ## the coefficients of each simple linear regression of y with x
x &lt;- NULL
</code></pre>


</div>