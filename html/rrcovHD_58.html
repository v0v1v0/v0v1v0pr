<div class="container">

<table style="width: 100%;"><tr>
<td>RSimca</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Robust classification in high dimensions based on the SIMCA method
</h2>

<h3>Description</h3>

<p>RSimca performs a robust version of the SIMCA method. This method classifies
a data matrix x with a known group structure. To reduce the dimension on 
each group a robust PCA analysis is performed. Afterwards a classification
rule is developped to determine the assignment of new observations. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">RSimca(x, ...)
## Default S3 method:
RSimca(x, grouping, prior=proportions, k, kmax = ncol(x), 
    control="hubert", alpha, tol = 1.0e-4, trace=FALSE, ...)
## S3 method for class 'formula'
RSimca(formula, data = NULL, ..., subset, na.action)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>a formula of the form <code>y~x</code>, it describes the response
and the predictors. The formula can be more complicated, such as
<code>y~log(x)+z</code> etc (see <code>formula</code> for more details).
The response should
be a factor representing the response variable, or any vector
that can be coerced to such (such as a logical variable).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>an optional data frame (or similar: see
<code>model.frame</code>) containing the variables in the
formula <code>formula</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>
<p>an optional vector used to select rows (observations) of the
data matrix <code>x</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.action</code></td>
<td>
<p>a function which indicates what should happen
when the data contain <code>NA</code>s.  The default is set by
the <code>na.action</code> setting of <code>options</code>, and is
<code>na.fail</code> if that is unset. The default is <code>na.omit</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a matrix or data frame containing the explanatory variables (training set). </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>grouping</code></td>
<td>
<p>grouping variable:  a factor specifying the class for each observation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>
<p>prior probabilities, default to the class proportions for the training set.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>tolerance</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p> a control object (S4) for specifying one of the 
available PCA estimation methods and containing estimation options. 
The class of this object defines which estimator will be used. 
Alternatively a character string can be specified
which names the estimator - one of auto, hubert, locantore, grid, proj. 
If 'auto' is specified or the argument is missing, the
function will select the estimator (see below for details)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>this parameter measures the fraction of outliers the algorithm should
resist. In MCD alpha controls the size of the subsets over which the
determinant is minimized, i.e. alpha*n observations are used for
computing the determinant. Allowed values are between 0.5 and 1
and the default is 0.5.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>number of principal components to compute. If <code>k</code> is missing, 
or <code>k = 0</code>, the algorithm itself will determine the number of 
components by finding such <code>k</code> that <code class="reqn">l_k/l_1 &gt;= 10.E-3</code> and 
<code class="reqn">\Sigma_{j=1}^k l_j/\Sigma_{j=1}^r l_j &gt;= 0.8</code>. 
It is preferable to investigate the scree plot in order to choose the number 
of components and then run again. Default is <code>k=0</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kmax</code></td>
<td>
<p>maximal number of principal components to compute.
Default is <code>kmax=10</code>. If <code>k</code> is provided, <code>kmax</code> 
does not need to be specified, unless <code>k</code> is larger than 10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace</code></td>
<td>
<p>whether to print intermediate results. Default is <code>trace = FALSE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>arguments passed to or from other methods.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>RSimca</code>, serving as a constructor for objects of class <code>RSimca-class</code> 
is a generic function with "formula" and "default" methods.
</p>
<p>SIMCA is a two phase procedure consisting of PCA performed on each group 
separately for dimension reduction followed by classification rules built 
in the lower dimensional space (note that the dimension in 
each group can be different). Instead of classical PCA robust alternatives will be used.
Any of the robust PCA methods available in package <code>Pca-class</code> 
can be used through the argument <code>control</code>.
In original SIMCA new observations are 
classified by means of their deviations from the different PCA models.
Here the classification rules will be obtained using two popular distances arising from PCA - 
orthogonal distances (OD) and score distances (SD). For the definition of these distances,
the definition of the cutoff values and the standartization of the distances see 
Vanden Branden K, Hubert M (2005) and Todorov and Filzmoser (2009).
</p>


<h3>Value</h3>

<p>An S4 object of class <code>RSimca-class</code> which is a subclass of of the 
virtual class <code>Simca-class</code>. 
</p>


<h3>Author(s)</h3>

<p> Valentin Todorov <a href="mailto:valentin.todorov@chello.at">valentin.todorov@chello.at</a> 
</p>


<h3>References</h3>

<p>Vanden Branden K, Hubert M (2005) Robust classification in high 
dimensions based on the SIMCA method. Chemometrics and 
Intellegent Laboratory Systems 79:10–21
</p>
<p>Todorov V &amp; Filzmoser P (2014),
Software Tools for Robust Analysis of High-Dimensional Data.
<em>Austrian Journal of Statistics</em>, <b>43</b>(4),  255–266,
<a href="https://doi.org/10.17713/ajs.v43i4.44">doi:10.17713/ajs.v43i4.44</a>.   
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(pottery)
dim(pottery)        # 27 observations in 2 classes, 6 variables
head(pottery)

## Build the SIMCA model. Use RSimca for a robust version
rs &lt;- RSimca(origin~., data=pottery)
rs
summary(rs)


## generate a sample from the pottery data set -
##  this will be the "new" data to be predicted
smpl &lt;- sample(1:nrow(pottery), 5)
test &lt;- pottery[smpl, -7]          # extract the test sample. Remove the last (grouping) variable
print(test)


## predict new data
pr &lt;- predict(rs, newdata=test)

pr@classification 
</code></pre>


</div>