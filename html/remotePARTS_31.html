<div class="container">

<table style="width: 100%;"><tr>
<td>MC_GLSpart</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>fit a parallel partitioned GLS</h2>

<h3>Description</h3>

<p>fit a GLS model to a large data set by partitioning the data
into smaller pieces (partitions) and processing these pieces individually and
summarizing output across partitions to conduct hypothesis tests.
</p>


<h3>Usage</h3>

<pre><code class="language-R">MC_GLSpart(
  formula,
  partmat,
  formula0 = NULL,
  part_FUN = "part_data",
  distm_FUN = "distm_scaled",
  covar_FUN = "covar_exp",
  covar.pars = c(range = 0.1),
  nugget = NA,
  ncross = 6,
  save.GLS = FALSE,
  ncores = parallel::detectCores(logical = FALSE) - 1,
  debug = FALSE,
  ...
)

MCGLS_partsummary(
  MCpartGLS,
  covar.pars = c(range = 0.1),
  save.GLS = FALSE,
  partsize
)

multicore_fitGLS_partition(
  formula,
  partmat,
  formula0 = NULL,
  part_FUN = "part_data",
  distm_FUN = "distm_scaled",
  covar_FUN = "covar_exp",
  covar.pars = c(range = 0.1),
  nugget = NA,
  ncross = 6,
  save.GLS = FALSE,
  ncores = parallel::detectCores(logical = FALSE) - 1,
  do.t.test = TRUE,
  do.chisqr.test = TRUE,
  debug = FALSE,
  ...
)

fitGLS_partition(
  formula,
  partmat,
  formula0 = NULL,
  part_FUN = "part_data",
  distm_FUN = "distm_scaled",
  covar_FUN = "covar_exp",
  covar.pars = c(range = 0.1),
  nugget = NA,
  ncross = 6,
  save.GLS = FALSE,
  do.t.test = TRUE,
  do.chisqr.test = TRUE,
  progressbar = TRUE,
  debug = FALSE,
  ncores = NA,
  parallel = TRUE,
  ...
)

part_data(index, formula, data, formula0 = NULL, coord.names = c("lng", "lat"))

part_csv(index, formula, file, formula0 = NULL, coord.names = c("lng", "lat"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>a formula for the GLS model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>partmat</code></td>
<td>
<p>a numeric partition matrix, with values containing indices of locations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula0</code></td>
<td>
<p>an optional formula for the null GLS model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>part_FUN</code></td>
<td>
<p>a function to partition individual data. See details for more
information about requirements for this function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>distm_FUN</code></td>
<td>
<p>a function to calculate distances from a coordinate matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>covar_FUN</code></td>
<td>
<p>a function to calculate covariances from a distance matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>covar.pars</code></td>
<td>
<p>a named list of parameters passed to <code>covar_FUN</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nugget</code></td>
<td>
<p>a numeric fixed nugget component: if NA, the nugget is estimated for
each partition</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncross</code></td>
<td>
<p>an integer indicating the number of partitions used to calculate
cross-partition statistics</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>save.GLS</code></td>
<td>
<p>logical: should full GLS output be saved for each partition?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncores</code></td>
<td>
<p>an optional integer indicating how many CPU threads to use for calculations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>debug</code></td>
<td>
<p>logical debug mode</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>arguments passed to <code>part_FUN</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MCpartGLS</code></td>
<td>
<p>object resulting from MC_partGLS()</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>partsize</code></td>
<td>
<p>number of locations per partition</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>do.t.test</code></td>
<td>
<p>logical: should a t-test of the GLS coefficients be conducted?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>do.chisqr.test</code></td>
<td>
<p>logical: should a correlated chi-squared test of the model
fit be conducted?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>progressbar</code></td>
<td>
<p>logical: should progress be tracked with a progress bar?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel</code></td>
<td>
<p>logical: should all calculations be done in parallel? See details for
more information</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>index</code></td>
<td>
<p>a vector of pixels with which to subset the data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>a data frame</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coord.names</code></td>
<td>
<p>a vector containing names of spatial coordinate variables
(x and y, respectively)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>file</code></td>
<td>
<p>a text string indicating the csv file from which to read data</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function specified by <code>part_FUN</code> is called internally to obtain
properly formatted subsets of the full data (i.e., partitions). Two functions
are provided in the <code>remotePARTs</code> package for this purpose: <code>part_data</code>
and <code>part_csv</code>. Both of these functions have required arguments that
must be specified through the call to <code>fitGLS_partition</code> (via <code>...</code>).
Check each function's argument list and see "<code>part_FUN</code> details" below
for more information.
</p>
<p><code>partmat</code> is used to partition the data. <code>partmat</code> must be a complete
matrix, without any missing or non-finite values. Columns of <code>partmat</code> are
passed as the first argument <code>part_FUN</code> to obtain data, which is then
passed to <code>fitGLS</code>. Users are encouraged to use <code>sample_partitions()</code>
to obtain a valid <code>partmat</code>.
</p>
<p>The specific dimensions of <code>partmat</code> can have a substantial effect on the
efficiency of <code>fitGLS_partition</code>. For most systems, we do not recommend
fitting with partitions exceeding 3000 locations or pixels
(i.e., <code>partmat(partsize = 3000, ...)</code>). Any larger, and the covariance
matrix inversions may become quite slow (or impossible for some machines).
It may help performance to use smaller even partitions of around 1000-2000
locations.
</p>
<p><code>ncross</code> determines how many partitions are used to estimate cross-partition
statistics. All partitions, up to <code>ncross</code> are compared with all others
in a pairwise fashion. There is no hard rule for setting <code>mincross</code>. More
crosses will ensure convergence, but we believe that the default of 6
(10 total comparisons) should be sufficient for most moderate-sized maps
if 1500-3000 pixel partitions are used. This may require testing with each
individual dataset to determine at what point convergence occurs.
</p>
<p>Covariance matrices for each partition are calculated with <code>covar_FUN</code>
from distances among points within the partition. Parameter values for
<code>covar_FUN</code> are given by <code>covar.pars</code>.
</p>
<p>The distances among points are calculated with <code>distm_FUN</code>.
<code>distm_FUN</code> can be any function, modeled after <code>geosphere::distm()</code>,
that satisfies both: 1) returns a distance matrix among points when a single
coordinate matrix is given as first argument; and 2) returns a matrix
containing distances between two coordinate matrices if given as the first and
second arguments.
</p>
<p>If <code>nugget = NA</code>, a ML nugget is obtained for each partition. Otherwise,
a fixed nugget is used for all partitions.
</p>
<p>It is not required to use all partitions for cross-partition calculations, nor
is it recommended to do so for most large data sets.
</p>
<p>If <code>progressbar = TRUE</code> a text progress bar shows the current status
of the calculations in the console.
</p>


<h3>Value</h3>

<p>a "MC_partGLS", which is a precursor to a "partGLS" object
</p>
<p>a "partGLS" object
</p>
<p>"partGLS" object
</p>
<p><code>fitGLS_partition</code> returns a list object of class "partGLS" which
contains at least the following elements:
</p>

<dl>
<dt>call</dt>
<dd>
<p>the function call</p>
</dd>
<dt>GLS</dt>
<dd>
<p>an optional list of "remoteGLS" objects, one for each partition</p>
</dd>
<dt>part</dt>
<dd>
<p>statistics calculated from each partition: see below for further
details</p>
</dd>
<dt>cross</dt>
<dd>
<p>statistics calculated from each pair of crossed partitions,
determined by <code>ncross</code>: see below for further details</p>
</dd>
<dt>overall</dt>
<dd>
<p>summary statistics of the overall model: see below for further
details</p>
</dd>
</dl>
<p><code>part</code> is a sub-list containing the following elements
</p>

<dl>
<dt>coefficients</dt>
<dd>
<p>a numeric matrix of GLS coefficients for each partition</p>
</dd>
<dt>SEs</dt>
<dd>
<p>a numeric matrix of coefficient standard errors</p>
</dd>
<dt>tstats</dt>
<dd>
<p>a numeric matrix of coefficient t-statstitics</p>
</dd>
<dt>pvals_t</dt>
<dd>
<p>a numeric matrix of t-test pvalues</p>
</dd>
<dt>nuggets</dt>
<dd>
<p>a numeric vector of nuggets for each partition</p>
</dd>
<dt>covar.pars</dt>
<dd>
<p><code>covar.pars</code> input vector</p>
</dd>
<dt>modstats</dt>
<dd>
<p>a numeric matrix with rows corresponding to partitions and
columns corresponding to log-likelihoods (<code>logLik</code>),
sum of square error (<code>SSE</code>), mean-squared error (<code>MSE</code>),
regression mean-square (<code>MSR</code>), F-statistics (<code>Fstat</code>),
and p-values from F-tests (<code>pval_F</code>)</p>
</dd>
</dl>
<p><code>cross</code> is a sub-list containing the following elements, which are use
to calculate the combined (across partitions) standard errors of the coefficient
estimates and statistical tests. See Ives et al. (2022).
</p>

<dl>
<dt>rcoefs</dt>
<dd>
<p>a numeric matrix of cross-partition correlations in the
estimates of the coefficients</p>
</dd>
<dt>rSSRs</dt>
<dd>
<p>a numeric vector of cross-partition correlations in the
regression sum of squares</p>
</dd>
<dt>rSSEs</dt>
<dd>
<p>a numeric vector of cross-partition correlations in the
sum of squared errors</p>
</dd>
</dl>
<p>and <code>overall</code> is a sub-list containing the elements
</p>

<dl>
<dt>coefficients</dt>
<dd>
<p>a numeric vector of the average coefficient estimates
across all partitions</p>
</dd>
<dt>rcoefficients</dt>
<dd>
<p>a numeric vector of the average cross-partition
coefficient from across all crosses</p>
</dd>
<dt>rSSR</dt>
<dd>
<p>the average cross-partition correlation in the regression
sum of squares</p>
</dd>
<dt>rSSE</dt>
<dd>
<p>the average cross-partition correlation in the sum of
squared errors</p>
</dd>
<dt>Fstat</dt>
<dd>
<p>the average f-statistic across partitions</p>
</dd>
<dt>dfs</dt>
<dd>
<p>degrees of freedom to be used with partitioned GLS f-test</p>
</dd>
<dt>partdims</dt>
<dd>
<p>dimensions of <code>partmat</code></p>
</dd>
<dt>pval.chisqr</dt>
<dd>
<p>if <code>chisqr.test = TRUE</code>, a p-value for the correlated
chi-squared test</p>
</dd>
<dt>t.test</dt>
<dd>
<p>if <code>do.t.test = TRUE</code>, a table with t-test results, including
the coefficient estimates, standard errors, t-statistics, and p-values</p>
</dd>
</dl>
<p><code>part_data</code> and <code>part_csv</code> both return a list with two elements:
</p>

<dl>
<dt>data</dt>
<dd>
<p>a dataframe, containing the data subset</p>
</dd>
<dt>coords</dt>
<dd>
<p>a coordinate matrix for the subset</p>
</dd>
</dl>
<h3>parallel implementation</h3>

<p>In order to be efficient and account for different user situations, parallel
processing is available natively in <code>fitGLS_partition</code>. There are a few
different specifications that will result in different behavior:
</p>
<p>When <code>parallel = TRUE</code> and <code>ncores &gt; 1</code>, all calculations are done
completely in parallel (via <code>multicore_fitGLS_partition()</code>).
In this case, parallelization is implemented with the
<code>parallel</code>, <code>doParallel</code>, and <code>foreach</code> packages. In this version,
all matrix operations are serialized on each worker but multiple operations
can occur simultaneously..
</p>
<p>When <code>parallel = FALSE</code> and <code>ncores &gt; 1</code>, then most calculations
are done on a single core but matrix opperations use multiple cores. In this
case, <code>ncores</code> is passed to fitGLS. In this option, it is suggested
to not exceed the number of physical cores (not threads).
</p>
<p>When <code>ncores &lt;= 1</code>, then the calculations are completely serialized
</p>
<p>When <code>ncores = NA</code> (the default), only one core is used.
</p>
<p>In the parallel implementation of this function, a progress bar is not possible,
so <code>progressbar</code> is ignored.
</p>


<h3>
<code>part_FUN</code> details</h3>

<p><code>part_FUN</code> can be any function that satisfies the following criteria
</p>
<p>1. the first argument of <code>part_FUN</code> must accept an index of pixels by which
to subset the data;
</p>
<p>2. <code>part_FUN</code> must also accept <code>formula</code> and <code>formula0</code> from
<code>fitGLS_partition</code>; and
</p>
<p>3. the output of <code>part_FUN</code> must be a list with at least the
following elements, which are passed to <code>fitGLS</code>;
</p>

<dl>
<dt>data</dt>
<dd>
<p>a data frame containing all variables given by <code>formula</code>.
Rows should correspond to pixels specified by the first argument</p>
</dd>
<dt>coords</dt>
<dd>
<p>a coordinate matrix or data frame. Rows should correspond to
pixels specified by the first argument</p>
</dd>
</dl>
<p>Two functions that satisfy these criteria are provided by <code>remotePARTS</code>:
<code>part_data</code> and <code>part_csv</code>.
</p>
<p><code>part_data</code> uses an in-memory data frame (<code>data</code>)
as a data source. <code>part_csv</code>, instead reads data from a
csv file (<code>file</code>), one partition at a time, for efficient memory usage.
<code>part_csv</code> internally calls <code>sqldf::read.csv.sql()</code> for fast and
efficient row extraction.
</p>
<p>Both functions use <code>index</code> to subset rows of data and <code>formula</code> and
<code>formula0</code> (optional) to determine which variables to select.
</p>
<p>Both functions also use <code>coord.names</code> to indicate which variables contain
spatial coordinates. The name of the x-coordinate column should always preceed
the y-coordinate column: <code>c("x", "y")</code>.
</p>
<p>Users are encouraged to write their own <code>part_FUN</code> functions to meet their
needs. For example, one might be interested in using data stored in a raster
stack or any other file type. In this case, a user-defined <code>part_FUN</code>
function allows access to <code>fitGLS_partition</code> without saving reformatted
copies of data.
</p>


<h3>References</h3>

<p>Ives, A. R., L. Zhu, F. Wang, J. Zhu, C. J. Morrow, and V. C. Radeloff. in review.
Statistical tests for non-independent partitions of large autocorrelated datasets.
MethodsX.
</p>


<h3>See Also</h3>

<p>Other partitionedGLS: 
<code>crosspart_GLS()</code>,
<code>sample_partitions()</code>
</p>
<p>Other partitionedGLS: 
<code>crosspart_GLS()</code>,
<code>sample_partitions()</code>
</p>
<p>Other partitionedGLS: 
<code>crosspart_GLS()</code>,
<code>sample_partitions()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## read data
data(ndvi_AK10000)
df = ndvi_AK10000[seq_len(1000), ] # first 1000 rows

## create partition matrix
pm = sample_partitions(nrow(df), npart = 3)

## fit GLS with fixed nugget
partGLS = fitGLS_partition(formula = CLS_coef ~ 0 + land, partmat = pm,
                           data = df, nugget = 0, do.t.test = TRUE)

## hypothesis tests
chisqr(partGLS) # explanatory power of model
t.test(partGLS) # significance of predictors

## now with a numeric predictor
fitGLS_partition(formula = CLS_coef ~ lat, partmat = pm, data = df, nugget = 0)


## fit ML nugget for each partition (slow)
(partGLS.opt = fitGLS_partition(formula = CLS_coef ~ 0 + land, partmat = pm,
                                data = df, nugget = NA))
partGLS.opt$part$nuggets # ML nuggets

# Certain model structures may not be useful:
## 0 intercept with numeric predictor (produces NAs) and gives a warning in statistical tests
fitGLS_partition(formula = CLS_coef ~ 0 + lat, partmat = pm, data = df, nugget = 0)

## intercept-only, gives warning
fitGLS_partition(formula = CLS_coef ~ 1, partmat = pm, data = df, nugget = 0,
                 do.chisqr.test = FALSE)

## part_data examples
part_data(1:20, CLS_coef ~ 0 + land, data = ndvi_AK10000)


## part_csv examples - ## CAUTION: examples for part_csv() include manipulation side-effects:
# first, create a .csv file from ndviAK
data(ndvi_AK10000)
file.path = file.path(tempdir(), "ndviAK10000-remotePARTS.csv")
write.csv(ndvi_AK10000, file = file.path)

# build a partition from the first 30 pixels in the file
part_csv(1:20, formula = CLS_coef ~ 0 + land, file = file.path)

# now with a random 20 pixels
part_csv(sample(3000, 20), formula = CLS_coef ~ 0 + land, file = file.path)

# remove the example csv file from disk
file.remove(file.path)


</code></pre>


</div>