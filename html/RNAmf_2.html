<div class="container">

<table style="width: 100%;"><tr>
<td>ALD_RNAmf</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>find the next point by ALD criterion</h2>

<h3>Description</h3>

<p>The function acquires the new point by the Active learning Decomposition (ALD) criterion.
It calculates the ALD criterion <code class="reqn">\frac{V_l(\bm{x})}{\sum^l_{j=1}C_j}</code>,
where <code class="reqn">V_l(\bm{x})</code> is the contribution of GP emulator
at each fidelity level <code class="reqn">l</code> and <code class="reqn">C_j</code> is the simulation cost at level <code class="reqn">j</code>.
For details, see Heo and Sung (2024, &lt;<a href="https://doi.org/10.1080/00401706.2024.2376173">doi:10.1080/00401706.2024.2376173</a>&gt;).
</p>
<p>A new point is acquired on <code>Xcand</code>. If <code>Xcand=NULL</code>, a new point is acquired on unit hypercube <code class="reqn">[0,1]^d</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ALD_RNAmf(Xcand = NULL, fit, mc.sample = 1000, cost = NULL,
optim = TRUE, parallel = FALSE, ncore = 1, trace=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Xcand</code></td>
<td>
<p>vector or matrix of candidate set which could be added into the current design only used when <code>optim=FALSE</code>. <code>Xcand</code> is the set of the points where ALD criterion is evaluated. If <code>Xcand=NULL</code>, <code class="reqn">100 \times d</code> number of points from 0 to 1 are generated by Latin hypercube design. Default is <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fit</code></td>
<td>
<p>object of class <code>RNAmf</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mc.sample</code></td>
<td>
<p>a number of mc samples generated for the MC approximation. Default is <code>1000</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cost</code></td>
<td>
<p>vector of the costs for each level of fidelity. If <code>cost=NULL</code>, total costs at all levels would be 1. <code>cost</code> is encouraged to have a ascending order of positive value. Default is <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optim</code></td>
<td>
<p>logical indicating whether to optimize AL criterion by <code>optim</code>'s gradient-based <code>L-BFGS-B</code> method. If <code>optim=TRUE</code>, <code class="reqn">5 \times d</code> starting points are generated by Latin hypercube design for optimization. If <code>optim=FALSE</code>, AL criterion is optimized on the <code>Xcand</code>. Default is <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel</code></td>
<td>
<p>logical indicating whether to compute the AL criterion in parallel or not. If <code>parallel=TRUE</code>, parallel computation is utilized. Default is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncore</code></td>
<td>
<p>a number of core for parallel. It is only used if <code>parallel=TRUE</code>. Default is 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace</code></td>
<td>
<p>logical indicating whether to print the computational time for each step. If <code>trace=TRUE</code>, the computation time for each step is printed. Default is <code>FALSE</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>


<ul>
<li> <p><code>ALD</code>: list of ALD criterion computed at each point of <code>Xcand</code> at each level if <code>optim=FALSE</code>. If <code>optim=TRUE</code>, <code>ALD</code> returns <code>NULL</code>.
</p>
</li>
<li> <p><code>cost</code>: a copy of <code>cost</code>.
</p>
</li>
<li> <p><code>Xcand</code>: a copy of <code>Xcand</code>.
</p>
</li>
<li> <p><code>chosen</code>: list of chosen level and point.
</p>
</li>
<li> <p><code>time</code>: a scalar of the time for the computation.
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">
library(lhs)
library(doParallel)
library(foreach)

### simulation costs ###
cost &lt;- c(1, 3)

### 1-d Perdikaris function in Perdikaris, et al. (2017) ###
# low-fidelity function
f1 &lt;- function(x) {
  sin(8 * pi * x)
}

# high-fidelity function
f2 &lt;- function(x) {
  (x - sqrt(2)) * (sin(8 * pi * x))^2
}

### training data ###
n1 &lt;- 13
n2 &lt;- 8

### fix seed to reproduce the result ###
set.seed(1)

### generate initial nested design ###
X &lt;- NestedX(c(n1, n2), 1)
X1 &lt;- X[[1]]
X2 &lt;- X[[2]]

### n1 and n2 might be changed from NestedX ###
### assign n1 and n2 again ###
n1 &lt;- nrow(X1)
n2 &lt;- nrow(X2)

y1 &lt;- f1(X1)
y2 &lt;- f2(X2)

### n=100 uniform test data ###
x &lt;- seq(0, 1, length.out = 100)

### fit an RNAmf ###
fit.RNAmf &lt;- RNAmf_two_level(X1, y1, X2, y2, kernel = "sqex")

### predict ###
predy &lt;- predict(fit.RNAmf, x)$mu
predsig2 &lt;- predict(fit.RNAmf, x)$sig2

### active learning with optim=TRUE ###
ald.RNAmf.optim &lt;- ALD_RNAmf(
  Xcand = x, fit.RNAmf, cost = cost,
  optim = TRUE, parallel = TRUE, ncore = 2
)
print(ald.RNAmf.optim$time) # computation time of optim=TRUE

### active learning with optim=FALSE ###
ald.RNAmf &lt;- ALD_RNAmf(
  Xcand = x, fit.RNAmf, cost = cost,
  optim = FALSE, parallel = TRUE, ncore = 2
)
print(ald.RNAmf$time) # computation time of optim=FALSE

### visualize ALD ###
oldpar &lt;- par(mfrow = c(1, 2))
plot(x, ald.RNAmf$ALD$ALD1,
  type = "l", lty = 2,
  xlab = "x", ylab = "ALD criterion at the low-fidelity level",
  ylim = c(min(c(ald.RNAmf$ALD$ALD1, ald.RNAmf$ALD$ALD2)),
           max(c(ald.RNAmf$ALD$ALD1, ald.RNAmf$ALD$ALD2)))
)
points(ald.RNAmf$chosen$Xnext,
  ald.RNAmf$ALD$ALD1[which(x == drop(ald.RNAmf$chosen$Xnext))],
  pch = 16, cex = 1, col = "red"
)
plot(x, ald.RNAmf$ALD$ALD2,
  type = "l", lty = 2,
  xlab = "x", ylab = "ALD criterion at the high-fidelity level",
  ylim = c(min(c(ald.RNAmf$ALD$ALD1, ald.RNAmf$ALD$ALD2)),
           max(c(ald.RNAmf$ALD$ALD1, ald.RNAmf$ALD$ALD2)))
)
par(oldpar)

</code></pre>


</div>