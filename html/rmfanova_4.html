<div class="container">

<table style="width: 100%;"><tr>
<td>rmfanova</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Repeated measures functional analysis of variance</h2>

<h3>Description</h3>

<p>The function <code>rmfanova()</code> calculates the tests based on three test statistics
<code class="reqn">\mathcal{C}_n</code>, <code class="reqn">\mathcal{D}_n</code>, and <code class="reqn">\mathcal{E}_n</code> for the problem of
comparing <code class="reqn">\ell</code>-samples of repeated measures for functional data. The tests are based on
five resampling methods, i.e., two permutation and three bootstrap ones. The overall and local
hypotheses are considered.
</p>


<h3>Usage</h3>

<pre><code class="language-R">rmfanova(
  x,
  method = "bonferroni",
  n_perm = 1000,
  n_boot = 1000,
  parallel = FALSE,
  n_cores = NULL,
  multi_gen = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a list of length <code class="reqn">\ell</code> with elements being <code class="reqn">n\times p</code> matrices of data
corresponding to <code class="reqn">n</code> functional observations measured in <code class="reqn">p</code> design time points under given
experimental conditions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>the correction method to be used for pairwise comparisons. Options are <code>"bonferroni"</code>
(default) and those given in the vector <code>p.adjust.methods</code> (as for the <code>p.adjust()</code> function).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_perm</code></td>
<td>
<p>a number of permutation replicates. The default is 1000.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_boot</code></td>
<td>
<p>a number of bootstrap replicates. The default is 1000.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel</code></td>
<td>
<p>a logical indicating of whether to use parallel computing. The default is <code>FALSE.</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_cores</code></td>
<td>
<p>if <code>parallel = TRUE</code>, a number of processes used in parallel computation.
Its default value (<code>NULL</code>) means that it will be equal to a number of cores of a computer used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>multi_gen</code></td>
<td>
<p>a logical indicating of whether to use separate multiple generations of Gaussian processes
for the parametric bootstrap tests. The default is FALSE, which means that the processes will be
generated once in a big matrix. This method is much faster, but for larger <code class="reqn">n</code> and <code class="reqn">p</code>
the generated data can be too large for RAM. In such a case, we suggest using separate generation
(<code>multi_gen = TRUE</code>), which is slower, but possible to calculate.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function <code>rmfanova()</code> concerns the tests for the functional repeated measures analysis problem.
The details are presented in Kurylo and Smaga (2023), where in particular, some recommendations for using tests are given.
Here we present only some summary of the problem and its solutions implemented in the package.
</p>
<p>We have <code class="reqn">n</code> subjects subjected to <code class="reqn">\ell\geq 2</code> (possibly) different conditions.
The results of the experiments are functional observations. Let the subjects be represented
by a functional sample consisting of independent stochastic processes <code class="reqn">Y_1,\dots,Y_n</code> defined on the
interval <code class="reqn">[0,\ell]</code>, which satisfy the following model proposed by Martinez-Camblor and Corral (2011):
</p>
<p style="text-align: center;"><code class="reqn">Y_j(t)=\mu(t)+e_j(t),\ j=1,\dots,n,\ t\in[0,\ell],</code>
</p>

<p>where <code class="reqn">\mu</code> is a fixed mean function, and <code class="reqn">e_j</code> is a random process with zero mean function.
In this notation, <code class="reqn">t\in[0,1]</code> corresponds to the first experimental condition, <code class="reqn">t\in[1,2]</code>
to the second, and so on. Thus, in this model, we ignore the possible time periods between repetitions
of the experiment, but this does not mean that they do not exist. We are interested in testing the equality
of <code class="reqn">\ell</code> mean functions corresponding to experimental conditions; namely, the global null hypothesis is as follows:
</p>
<p style="text-align: center;"><code class="reqn">\mathcal{H}_0:\mu(t)=\mu(t+1)=\dots=\mu(t+(\ell-1))\ \ \forall t\in[0,1].</code>
</p>

<p>For the global null hypothesis <code class="reqn">\mathcal{H}_0</code>, the tests given by Martinez-Camblor and Corral (2011)
used the pointwise sum of squares due to the hypothesis:
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{SSA}_{point}(t)=n\sum_{i=1}^\ell(\bar{Y}_{i\cdot}(t)-\bar{Y}(t))^2,\ t\in[0,1],</code>
</p>

<p>where </p>
<p style="text-align: center;"><code class="reqn">\bar{Y}_{i\cdot}(t)=n^{-1}\sum_{j=1}^nY_j(t+(i-1)),\ \bar{Y}(t)=N^{-1}\sum_{i=1}^\ell\sum_{j=1}^nY_j(t+(i-1)),</code>
</p>

<p><code class="reqn">i=1,\dots,\ell</code>. In the package, it is calculated and drawn by the <code>pointwise_ssa_test_statistic()</code> function.
The other option is the following pointwise F-type test statistic proposed in Kurylo and Smaga (2023):
</p>
<p style="text-align: center;"><code class="reqn">F_{point}(t)=\frac{\mathrm{SSA}_{point}(t)/(\ell-1)}{\mathrm{SSR}_{point}(t)/((\ell-1)(n-1))},\ t\in[0,1],</code>
</p>

<p>where </p>
<p style="text-align: center;"><code class="reqn">\mathrm{SSR}_{point}(t)=\sum_{i=1}^\ell\sum_{j=1}^n(Y_j(t+(i-1))-\bar{Y}_{i\cdot}(t)-\bar{Y}_{\cdot j}(t)+\bar{Y}(t))^2</code>
</p>

<p>is the pointwise sum of squares due to residuals, and </p>
<p style="text-align: center;"><code class="reqn">\bar{Y}_{\cdot j}(t)=\ell^{-1}\sum_{i=1}^\ell Y_j(t+(i-1)),\ j=1,\dots,n.</code>
</p>

<p><code class="reqn">F_{point}</code> is calculated and drawn by the <code>pointwise_f_test_statistic()</code> function.
</p>
<p>To obtain global test statistics for <code class="reqn">\mathcal{H}_0</code>, Martinez-Camblor and Corral (2011) proposed the
following test statistic: </p>
<p style="text-align: center;"><code class="reqn">\mathcal{C}_n(\ell)=\int_0^1\mathrm{SSA}_{point}(t)dt.</code>
</p>
<p> On the other hand,
Kurylo and Smaga (2023) proposed the following two test statistics:
</p>
<p style="text-align: center;"><code class="reqn">\mathcal{D}_n(\ell)=\int_0^1F_{point}(t)dt,\quad\mathcal{E}_n(\ell)=\sup\limits_{t\in[0,1]}F_{point}(t).</code>
</p>

<p>To construct the tests, five resampling strategies are proposed by Kurylo and Smaga (2023). For details, we refer
to this paper. Here we just note the two permutation tests and three bootstrap tests are denoted by P1, P2, B1, B2,
and B3 in the output of the <code>summary.rmfanova()</code> function.
</p>
<p>When <code class="reqn">\ell&gt;2</code>, by rejecting the global null hypothesis <code class="reqn">\mathcal{H}_0</code>, we determine the presence of significant differences
in the mean functions corresponding to the experimental conditions. However, we do not know which conditions are
significantly different and which are not. To solve this problem, one needs to perform a post hoc analysis.
More precisely, we would like to test the family of hypotheses:
</p>
<p style="text-align: center;"><code class="reqn">\left\{\begin{array}{l}
\mathcal{H}_0^{rs}:\mu(t+(r-1))=\mu(t+(s-1))\ \forall t\in[0,1],\\
\mathcal{H}_1^{rs}:\mu(t+(r-1))\neq\mu(t+(s-1))\ \text{for some}\ t\in[0,1],\\
\end{array}\right.</code>
</p>

<p>for <code class="reqn">r,s=1,\dots,\ell</code>, <code class="reqn">r\neq s</code>. These hypotheses are also named pairwise comparisons.
To test this family of local hypotheses, we propose the following procedure:
</p>
<p>1. Test each of the hypotheses <code class="reqn">\mathcal{H}_0^{rs}</code>  using the data for the <code class="reqn">r</code>-th and <code class="reqn">s</code>-th objects,
i.e., <code class="reqn">Y_1(t),\dots,Y_n(t)</code> for <code class="reqn">t\in[r-1,r]</code> and <code class="reqn">t\in[s-1,s]</code> respectively, and the chosen test
from those presented above. Let <code class="reqn">p_{rs}</code> denote the <code class="reqn">p</code>-values obtained.
</p>
<p>2. Make a final decision using the Bonferroni method, i.e., reject <code class="reqn">\mathcal{H}_0^{rs}</code> if
<code class="reqn">p_{rs}^{Bonf}\leq \alpha</code>, where <code class="reqn">p_{rs}^{Bonf}=m\cdot p_{rs}</code> are the corrected <code class="reqn">p</code>-values,
<code class="reqn">\alpha</code> is the significance level and <code class="reqn">m</code> is the number of null hypotheses considered.
</p>
<p>In the paper Kurylo and Smaga (2023), the Bonferroni method was used only. However, in the package,
there is a possibility to use other correction methods, which are available in the vector <code>p.adjust.methods</code>.
</p>
<p>The results of testing the global and local hypotheses are given separately in the output of the
<code>summary.rmfanova()</code> function for the convenience of the user.
</p>


<h3>Value</h3>

<p>A list of class <code>rmfanova</code> containing the following 7 components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>a number <code class="reqn">n</code> of functional observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>a number <code class="reqn">p</code> of design time points.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>l</code></td>
<td>
<p>a number <code class="reqn">\ell</code> of repeated samples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>an argument <code>method</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test_stat</code></td>
<td>
<p>values of the test statistics <code class="reqn">\mathcal{C}_n</code>, <code class="reqn">\mathcal{D}_n</code>, and <code class="reqn">\mathcal{E}_n</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p_values</code></td>
<td>
<p>p-values for the global null hypothesis.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p_values_pc</code></td>
<td>
<p>p-values of the pairwise comparisons.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Martinez-Camblor P., Corral N. (2011) Repeated Measures Analysis for Functional Data.
Computational Statistics &amp; Data Analysis 55, 3244–3256.
</p>
<p>Kurylo K., Smaga L. (2023) Functional repeated measures analysis of variance and its application. Preprint https://arxiv.org/abs/2306.03883
</p>
<p>Ramsay J.O., Silverman B.W. (2005) Functional Data Analysis, 2nd Edition. New York: Springer.
</p>
<p>Zhang J.T. (2013) Analysis of Variance for Functional Data. London: Chapman &amp; Hall.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Some of the examples may run some time.
# preparation of the DTI data set, for details see Kurylo and Smaga (2023)
library(refund)
data(DTI)
# MS patients
DTI_ms &lt;- DTI[DTI$case == 1, ]
miss_data &lt;- c()
for (i in 1:340) if (any(is.na(DTI_ms$cca[i, ]))) miss_data &lt;- c(miss_data, i)
DTI_ms &lt;- DTI_ms[-miss_data, ]
DTI_ms_2 &lt;- DTI_ms[DTI_ms$Nscans == 4, ]
xx &lt;- vector("list", 4)
for (i in 1:4) {
  xx[[i]] &lt;- DTI_ms_2$cca[DTI_ms_2$visit == i, ]
}
xx[[1]] &lt;- xx[[1]][-14, ]
xx[[3]] &lt;- xx[[3]][-14, ]
yy &lt;- xx
for (i in seq_len(4)) yy[[i]] &lt;- yy[[i]][1:17, ]
# data trajectories for four visits
oldpar &lt;- par(mfrow = c(1, 4), mar = c(4, 4, 4, 0.1))
matplot(t(yy[[1]]), type = "l", col = 1, lty = 1, xlab = "t", ylab = "FA",
        main = "Visit 1", xaxt = "n", ylim = c(0.29, 0.73))
axis(1, c(1, 15, 30, 45, 60, 75, 93), labels = c(1, 15, 30, 45, 60, 75, 93))
matplot(t(yy[[2]]), type = "l", col = 1, lty = 1, xlab = "t", ylab = "FA",
        main = "Visit 2", xaxt = "n", ylim = c(0.29, 0.73))
axis(1, c(1, 15, 30, 45, 60, 75, 93), labels = c(1, 15, 30, 45, 60, 75, 93))
matplot(t(yy[[3]]), type = "l", col = 1, lty = 1, xlab = "t", ylab = "FA",
        main = "Visit 3", xaxt = "n", ylim = c(0.29, 0.73))
axis(1, c(1, 15, 30, 45, 60, 75, 93), labels = c(1, 15, 30, 45, 60, 75, 93))
matplot(t(yy[[4]]), type = "l", col = 1, lty = 1, xlab = "t", ylab = "FA",
        main = "Visit 4", xaxt = "n", ylim = c(0.29, 0.73))
axis(1, c(1, 15, 30, 45, 60, 75, 93), labels = c(1, 15, 30, 45, 60, 75, 93))
par(oldpar)
# sample mean functions
oldpar &lt;- par(mfrow = c(1, 1), mar = c(4, 4, 2, 0.1))
pointwise_sample_mean_fun(yy, values = FALSE,
                          col = 1:4, xlab = "t", ylab = "FA", xaxt = "n")
axis(1, c(1, 15, 30, 45, 60, 75, 93), labels = c(1, 15, 30, 45, 60, 75, 93))
legend(x = 36, y = 0.64, legend = 1:4, lty = 1, col = 1:4, title = "Visit")
par(oldpar)
# pointwise SSA and F-type test statistics
oldpar &lt;- par(mfrow = c(1, 2), mar = c(4, 2, 2, 0.1))
pointwise_ssa_test_statistic(yy, xlab = "t", xaxt = "n")
axis(1, c(1, 15, 30, 45, 60, 75, 93), labels = c(1, 15, 30, 45, 60, 75, 93))
pointwise_f_test_statistic(yy, xlab = "t", xaxt = "n")
axis(1, c(1, 15, 30, 45, 60, 75, 93), labels = c(1, 15, 30, 45, 60, 75, 93))
par(oldpar)

# testing without parallel computing and multiple generation of Gaussian processes
res &lt;- rmfanova(yy)
summary(res, digits = 3)
# testing without parallel computing and with multiple generation of Gaussian processes
res &lt;- rmfanova(yy, multi_gen = TRUE)
summary(res, digits = 3)
# testing with parallel computing and without multiple generation of Gaussian processes
res &lt;- rmfanova(yy, parallel = TRUE, n_cores = 2)
summary(res, digits = 3)
# testing with parallel computing and with multiple generation of Gaussian processes
res &lt;- rmfanova(yy, parallel = TRUE, multi_gen = TRUE, n_cores = 2)
summary(res, digits = 3)


</code></pre>


</div>