<div class="container">

<table style="width: 100%;"><tr>
<td>MCPLDA</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Maximum Contrastive Pessimistic Likelihood Estimation for Linear Discriminant Analysis</h2>

<h3>Description</h3>

<p>Maximum Contrastive Pessimistic Likelihood (MCPL) estimation (Loog 2016) attempts to find a semi-supervised solution that has a higher likelihood compared to the supervised solution on the labeled and unlabeled data even for the worst possible labeling of the data. This is done by attempting to find a saddle point of the maximin problem, where the max is over the parameters of the semi-supervised solution and the min is over the labeling, while the objective is the difference in likelihood between the semi-supervised and the supervised solution measured on the labeled and unlabeled data. The implementation is a translation of the Matlab code of Loog (2016).
</p>


<h3>Usage</h3>

<pre><code class="language-R">MCPLDA(X, y, X_u, x_center = FALSE, scale = FALSE, max_iter = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>matrix; Design matrix for labeled data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>factor or integer vector; Label vector</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X_u</code></td>
<td>
<p>matrix; Design matrix for unlabeled data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x_center</code></td>
<td>
<p>logical;  Should the features be centered?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>logical; Should the features be normalized? (default: FALSE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iter</code></td>
<td>
<p>integer; Maximum number of iterations</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Loog, M., 2016. Contrastive Pessimistic Likelihood Estimation for Semi-Supervised Classification. IEEE Transactions on Pattern Analysis and Machine Intelligence, 38(3), pp.462-475.
</p>


<h3>See Also</h3>

<p>Other RSSL classifiers: 
<code>EMLeastSquaresClassifier</code>,
<code>EMLinearDiscriminantClassifier</code>,
<code>GRFClassifier</code>,
<code>ICLeastSquaresClassifier</code>,
<code>ICLinearDiscriminantClassifier</code>,
<code>KernelLeastSquaresClassifier</code>,
<code>LaplacianKernelLeastSquaresClassifier()</code>,
<code>LaplacianSVM</code>,
<code>LeastSquaresClassifier</code>,
<code>LinearDiscriminantClassifier</code>,
<code>LinearSVM</code>,
<code>LinearTSVM()</code>,
<code>LogisticLossClassifier</code>,
<code>LogisticRegression</code>,
<code>MCLinearDiscriminantClassifier</code>,
<code>MCNearestMeanClassifier</code>,
<code>MajorityClassClassifier</code>,
<code>NearestMeanClassifier</code>,
<code>QuadraticDiscriminantClassifier</code>,
<code>S4VM</code>,
<code>SVM</code>,
<code>SelfLearning</code>,
<code>TSVM</code>,
<code>USMLeastSquaresClassifier</code>,
<code>WellSVM</code>,
<code>svmlin()</code>
</p>


</div>