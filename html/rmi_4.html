<div class="container">

<table style="width: 100%;"><tr>
<td>lnn_entropy</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Local Nearest Neighbor (LNN) Entropy Estimator</h2>

<h3>Description</h3>

<p>Local Nearest Neighbor entropy estimator using Gaussian kernel and kNN selected bandwidth. Entropy is estimated by taking a Monte Carlo estimate using local kernel density estimate of the negative-log density.
</p>


<h3>Usage</h3>

<pre><code class="language-R">lnn_entropy(data, k = 5, tr = 30, bw = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>Matrix of sample observations, each row is an observation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>Order of the local kNN bandwidth selection.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tr</code></td>
<td>
<p>Order of truncation (number of neighbors to include in entropy).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bw</code></td>
<td>
<p>Bandwidth (optional) manually fix bandwidth instead of using local kNN bandwidth selection.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Loader, C. (1999). Local regression and likelihood. Springer Science &amp; Business Media.
</p>
<p>Gao, W., Oh, S., &amp; Viswanath, P. (2017). Density functional estimators with k-nearest neighbor bandwidths. IEEE International Symposium on Information Theory - Proceedings, 1, 1351â€“1355.
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(123)
x &lt;- rnorm(1000)
print(lnn_entropy(x))
#analytic entropy
print(0.5*log(2*pi*exp(1)))

</code></pre>


</div>