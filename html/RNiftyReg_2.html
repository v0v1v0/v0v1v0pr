<div class="container">

<table style="width: 100%;"><tr>
<td>applyTransform</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Apply a precomputed transformation</h2>

<h3>Description</h3>

<p>This function allows a precomputed transformation to be applied to a new
image or set of points.
</p>


<h3>Usage</h3>

<pre><code class="language-R">applyTransform(transform, x, interpolation = 3L, nearest = FALSE,
  internal = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>transform</code></td>
<td>
<p>A transform, possibly obtained from <code>forward</code>
or <code>reverse</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A numeric vector, representing a pixel/voxel location in source
space, or a matrix with rows representing such points, or an image with
the same dimensions as the original source image.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>interpolation</code></td>
<td>
<p>A single integer specifying the type of interpolation
to be applied to the final resampled image. May be 0 (nearest neighbour),
1 (trilinear) or 3 (cubic spline). No other values are valid.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nearest</code></td>
<td>
<p>Logical value: if <code>TRUE</code> and <code>x</code> contains points,
the nearest voxel centre location in target space will be returned.
Otherwise a more precise subvoxel location will be given.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>internal</code></td>
<td>
<p>If <code>FALSE</code>, the default, the returned image will be
returned as a standard R array. If <code>TRUE</code>, it will instead be an
object of class <code>"internalImage"</code>, containing only basic metadata and
a C-level pointer to the full image. (See also <code>readNifti</code>.)
This can occasionally be useful to save memory.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Points may be transformed from source to target space exactly under an
affine transformation, but nonlinear transformation is inexact. Its accuracy
will depend to some extent on the density of the control point grid and the
geometry of the deformation in the vicinity of the points of interest.
Nevertheless, it should be quite sufficient for most purposes.
</p>
<p>The method is to first convert the control points to a deformation field
(cf. <code>deformationField</code>), which encodes the location of each
target space voxel in the source space. The target voxel closest to the
requested location is found by searching through this deformation field, and
returned if <code>nearest</code> is <code>TRUE</code> or it coincides exactly with the
requested location. Otherwise, a block of four voxels in each dimension
around the point of interest is extracted from the deformation field, and
the final location is estimated by local cubic spline regression.
</p>


<h3>Value</h3>

<p>A resampled image or matrix of transformed points.
</p>


<h3>Author(s)</h3>

<p>Jon Clayden &lt;code@clayden.org&gt;
</p>


<h3>See Also</h3>

<p><code>niftyreg.linear</code>, <code>niftyreg.nonlinear</code>
</p>


</div>