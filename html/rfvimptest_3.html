<div class="container">

<table style="width: 100%;"><tr>
<td>rfvimptest</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Testing the statistical significance of predictors in random forests using sequential permutation testing</h2>

<h3>Description</h3>

<p>Implements several strategies for testing the statistical significance of predictors in random forests using sequential permutation testing procedures based on the permutation variable importance measure.
See Hapfelmeier et al. (2022) for details.
</p>


<h3>Usage</h3>

<pre><code class="language-R">rfvimptest(
  data,
  yname,
  Mmax = 500,
  varnames = NULL,
  p0 = 0.06,
  p1 = 0.04,
  alpha = 0.05,
  beta = 0.2,
  A = 0.1,
  B = 10,
  h = 8,
  nperm = 1,
  ntree = 500,
  progressbar = TRUE,
  test = c("general", "twosample")[1],
  type = c("SPRT", "SAPT", "pval", "certain", "complete")[1],
  condinf = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A <code>data.frame</code> containing the variables in the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>yname</code></td>
<td>
<p>Name of outcome variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Mmax</code></td>
<td>
<p>Maximum number of permutations used in each permutation test. Default is 500.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>varnames</code></td>
<td>
<p>Optional. Names of the variables for which testing should be performed. By default all variables in <code>data</code> with the exception of the outcome variable are used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p0</code></td>
<td>
<p>The value of the p-value in the null hypothesis (H0: p = p0) of SPRT and SAPT. Default is 0.06.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p1</code></td>
<td>
<p>The value of the p-value in the alternative hypothesis (H1: p = p1) of SPRT and SAPT. Default is 0.04.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>The significance level of SPRT when p = p0. Also known as type I error. Default is 0.05.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>One minus the power of SPRT when p = p1. Also known as type II error. Default is 0.2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>A</code></td>
<td>
<p>The quantity A in the formula of SAPT. Default is 0.1 for a type I error of 0.05. Usually not changed by the user.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>
<p>The quantity B in the formula of SAPT. Default is 10 (1/A) for a type I error of 0.05. Usually not changed by the user.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>h</code></td>
<td>
<p>The quantity h in the formula for the sequential Monte Carlo p-value. The default value for h is 8. Larger values lead to more precise p-value estimates,
but are computationally more expensive.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nperm</code></td>
<td>
<p>The numbers of permutations of the out-of-bag observations over which the results are averaged, when calculating the variable importance measure values. Default is 1. Larger values than 1 can only be considered when <code>condinf=TRUE</code>, that is, when using random forests
with conditional inference trees (Hothorn et al., 2006) as base learners.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ntree</code></td>
<td>
<p>Number of trees per forest. Default is 500.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>progressbar</code></td>
<td>
<p>Output the current progress of the calculations for each variable to the console? Default is TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test</code></td>
<td>
<p>Type of the permutation test to perform. This can be either "general" or "twosample", where "general" refers to the usual (sequential) permutation
test and "twosample" refers to the two-sample (sequential) permutation test. For the latter, see also Coleman et al. (2019).
Note, however, that "twosample" is experimental and should not be used for formal testing. See the details section below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>Type of the sequential method to use in the permutation tests. The choices are: "SPRT", "SAPT", "pval", "certain", and "complete". See the 'Details' section below for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>condinf</code></td>
<td>
<p>Set this value to <code>TRUE</code> if random forests using conditional inference trees (Hothorn et al., 2006) should
be used and to <code>FALSE</code> if classical random forests using CART trees should be used. Default is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further arguments passed to <code>ranger::ranger</code> (if <code>condinf=FALSE</code>) or <br><code>party::cforest_unbiased()</code> (if <code>condinf=TRUE</code>).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Only the general permutation test (<code>test="general"</code>) controls the type I error. In contrast, the two-sample permutation test (<code>test="twosample"</code>)
is associated with inflated type I error, which can lead to false positive findings. An advantage of the two-sample permutation test is that it is
very fast. Therefore, this experimental approach may be used as an informal screening tool for finding informative variables.
It is, however, not a valid testing procedure. Note also that
the paper of Coleman et al. (2019) on which the two-sample test is based has not yet been published in a peer-reviewed journal and that
the theory underlying this procedure might thus still need further review.
</p>
<p>SRPT (<code>type="SRPT"</code>) and SAPT (<code>type="SAPT"</code>) are similar sequential procedures, where SRPT is faster with respect to accepting H0, that is, detecting non-informative variables,
whereas SAPT is faster with respect to accepting H1, that is, detecting informative variables. Therefore, SRPT may be preferred for
datasets with only few informative variables, whereas SAPT is preferable for datasets with many informative variables.
The Monte Carlo p-value based testing procedure (<code>type="pval"</code>) should be used, when p-values are required.
The choice <code>type="complete"</code> offers a conventional permutation test (that is, without sequential testing) (Hapfelmeier and Ulm, 2013). This choice
is computationally the most intensive. Lastly, the choice <code>type="certain"</code> is similar to <code>type="complete"</code>, but performs
early stopping by ending the permutation iterations as soon as it is certain which outcome the conventional permutation test would
take. That is, <code>type="certain"</code> can be considered as a computationally more effective version of <code>type="complete"</code>.
</p>


<h3>Value</h3>

<p>Object of class <code>rfvimptest</code> with elements
</p>
<table>
<tr style="vertical-align: top;">
<td><code>testtype</code></td>
<td>
<p>Type of the permutation test performed and sequential method used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>varimp</code></td>
<td>
<p>Variable importance for each considered independent variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>testres</code></td>
<td>
<p>The results ("keep H0" vs. "accept H1") of the tests for each considered independent variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pvalues</code></td>
<td>
<p>The p-values of the tests for each considered independent variable. Note that p-values are only obtained for the
method types "pval" and "complete".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stoppedearly</code></td>
<td>
<p>For each independent variable, whether the calculations stopped early ("yes") or the maximum of <code>Mmax</code> permutations was reached ("no").</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>perms</code></td>
<td>
<p>The number of permutations performed for each independent variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Mmax</code></td>
<td>
<p>Maximum number of permutations used in each permutation test.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ntree</code></td>
<td>
<p>Number of trees per forest.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>comptime</code></td>
<td>
<p>The time the computations needed.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Alexander Hapfelmeier, Roman Hornung
</p>


<h3>References</h3>


<ul>
<li>
<p> Breiman, L. (2001). Random forests. Mach Learn, 45:5-32, &lt;doi: <a href="https://doi.org/10.1023/A:1010933404324">10.1023/A:1010933404324</a>&gt;.
</p>
</li>
<li>
<p> Coleman, T., Peng, W., Mentch, L. (2019). Scalable and efficient hypothesis testing with random forests. arXiv preprint arXiv:1904.07830, &lt;doi: <a href="https://doi.org/10.48550/arXiv.1904.07830">10.48550/arXiv.1904.07830</a>&gt;.
</p>
</li>
<li>
<p> Hapfelmeier, A., Hornung, R., Haller, B. (2022). Sequential Permutation Testing of Random Forest Variable Importance Measures. arXiv preprint arXiv:2206.01284, &lt;doi: <a href="https://doi.org/10.48550/arXiv.2206.01284">10.48550/arXiv.2206.01284</a>&gt;.
</p>
</li>
<li>
<p> Hapfelmeier, A., Ulm, K. (2013). A new variable selection approach using Random Forests. CSDA 60:50–69, &lt;doi: <a href="https://doi.org/10.1016/j.csda.2012.09.020">10.1016/j.csda.2012.09.020</a>&gt;.
</p>
</li>
<li>
<p> Hapfelmeier, A., Hothorn, T., Ulm, K., Strobl, C. (2014). A new variable importance measure for random forests with missing data. Stat Comput 24:21–34, &lt;doi: <a href="https://doi.org/10.1007/s11222-012-9349-1">10.1007/s11222-012-9349-1</a>&gt;.
</p>
</li>
<li>
<p> Hothorn, T., Hornik, K., Zeileis, A. (2006). Unbiased Recursive Partitioning: A Conditional Inference Framework. J Comput Graph Stat 15(3):651–674, &lt;doi: <a href="https://doi.org/10.1198/106186006X133933">10.1198/106186006X133933</a>&gt;.
</p>
</li>
<li>
<p> Wright, M. N., Ziegler, A. (2017). ranger: A fast implementation of random forests for high dimensional data in C++ and R. J Stat Softw 77:1-17, &lt;doi: <a href="https://doi.org/10.18637/jss.v077.i01">10.18637/jss.v077.i01</a>&gt;.
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">

## Load package:
library("rfvimptest")

## Set seed to obtain reproducible results:
set.seed(1234)

# Load example data:
data(hearth2)

# NOTE: For illustration purposes a very small number (Mmax=20) of maximum
# permutations is considered. This number would be much too small for actual
# applications. The default number is Max=500.

# By default, SPRT is performed:
(ptest_sprt &lt;- rfvimptest(data=hearth2, yname="Class", Mmax=20))
ptest_sprt$varimp
ptest_sprt$testres

# Calculation of p-values using the Monte Carlo p-value based testing procedure:
(ptest_pval &lt;- rfvimptest(data=hearth2, yname="Class", type="pval", Mmax=20))
ptest_pval$pvalues

# If the frequency of informative variables is expected to be high SAPT can be used:
(ptest_sapt &lt;- rfvimptest(data=hearth2, yname="Class", type="SAPT", Mmax=20))
ptest_sapt$testres


# If it is only of interest to test specific variables in the dataset these variables
# should be passed to rfvimptest() vias the argument 'varnames' because this
# reduces the computational burden considerably:

(ptest_twovar &lt;- rfvimptest(data=hearth2, yname="Class", varnames=c("age", "sex"), Mmax=20))
ptest_twovar$varimp
ptest_twovar$testres


# Two-sample permutation test procedures:

# NOTE: These should be used only for informal screening for informative variables.
# They are not valid statistical tests.

# Here, the maximum number of permutations can be much higher because it is necessary
# here to construct a new forest for each permutation:
rfvimptest(data=hearth2, yname="Class", test="twosample", condinf=TRUE, Mmax=1000)

rfvimptest(data=hearth2, yname="Class", test="twosample", type="pval", condinf=TRUE, Mmax=1000)

rfvimptest(data=hearth2, yname="Class", test="twosample", type="SAPT", condinf=TRUE, Mmax=1000)



</code></pre>


</div>