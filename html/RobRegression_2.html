<div class="container">

<table style="width: 100%;"><tr>
<td>Robust_Mahalanobis_regression</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Robust_Mahalanobis_regression</h2>

<h3>Description</h3>

<p>We propose here a function which enables to provide a robust estimation of the parameters of Multivariate Gaussian Linear Models of the form <code class="reqn">Y = X \beta + \epsilon</code> where <code class="reqn">\epsilon</code> is a 0-mean Gaussian vector of variance <code class="reqn">\Sigma</code>. In addition, one can aslo consider a low-rank variance of the form <code class="reqn">\Sigma = C + \sigma I</code> where <code class="reqn">\sigma</code> is a positive scalar and <code class="reqn">C</code> is a matrix of rank <code class="reqn">d</code>. More precisely, the aim is to minimize the functional
</p>
<p><code class="reqn">G_\lambda(\hat{\beta}) = \mathbb{E}\left(\| Y-X\hat{\beta} \|_{\Sigma^{-1}}\right) + \lambda \|\hat{\beta}\|^{\text{Ridge}}</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">Robust_Mahalanobis_regression(X, Y, alphaRM=0.66, alphareg=0.66, w=2, lambda=0,
                              creg='default', K=2:30, par=TRUE, epsilon=10^(-8),
                              method_regression='Offline', niter_regression=50,
                              cRM='default', mc_sample_size='default',
                              method_MCM='Weiszfeld', methodMC='Robbins',
                              niterMC=50, ridge=1, eps_vp=10^(-4), nlambda=50,
                              scale='none', tol=10^(-3))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>A <code class="reqn">(n,p)</code>-matrix whose rows are the explaining data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>A <code class="reqn">(n,q)</code>-matrix whose rows are the variables to be explained.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method_regression</code></td>
<td>
<p>The method used for estimating the parameter. Should be <code>method_regression='Offline'</code> if the fix point algorithm is used, and <code>method_regression='Online'</code> if the (weighted) averaged stochastic gradient algorithm is used. Default is <code>'Offline'</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>niter_regression</code></td>
<td>
<p>The maximum number of regression iterations if the fix point algorithm is used, i.e. if <code>method_regression='Offline'</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epsilon</code></td>
<td>
<p>Stoping condition for the fix point algorithm if <code>method_regression='Offline'</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>If a scaling is used. <code>scale='robust'</code> should be used if a robust scaling of <code>Y</code> is desired.  Default is <code>'none'</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ridge</code></td>
<td>
<p>The power of the penalty: i.e. should be <code>2</code> if the squared norm is considered or <code>1</code> if the norm is considered.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>A vector giving the different studied penalizations. If <code>lambda='default'</code>, would be a vector of preselected penalizations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>par</code></td>
<td>
<p>Is equal to <code>T</code> if the parallelization of the algorithm for estimating robustly the variance of the noise is allowed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlambda</code></td>
<td>
<p>The number of tested penalizations if <code>lambda='default'</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alphaRM</code></td>
<td>
<p>A scalar between 1/2 and 1 used in the stepsequence if the Robbins-Monro algorithm is used, i.e. if <code>methodMC='Robbins'</code>. Default is <code>0.66</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alphareg</code></td>
<td>
<p>A scalar between 1/2 and 1 used in the stepsequence for stochastic gradient algorithm if <code>method_regression='Online'</code>. Default is <code>0.66</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w</code></td>
<td>
<p>The power for the weighted averaged algorithms if <code>method_regression='Online'</code> or if <code>methodMC='Robbins'</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>creg</code></td>
<td>
<p>The constant in the stepsequence if the averaged stochastic gradient algorithm is used, i.e. if <code>method='Online'</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>A vector containing the possible values of <code class="reqn">d</code>. The good <code class="reqn">d</code> is chosen with the help of a penatly criterion if the length of <code>K</code> is larger than 10. Default is <code>ncol(X)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mc_sample_size</code></td>
<td>
<p>The number of data generated for the Monte-Carlo method for estimating robustly the eigenvalues of the variance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method_MCM</code></td>
<td>
<p>The method chosen to estimate Median Covariation Matrix. Can be <code>'Weiszfeld'</code> if the Weiszfeld algorithm is used, or <code>'ASGD'</code> if one chooses the Averaged Stochastic Gradient Descent algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>methodMC</code></td>
<td>
<p>The method chosen to estimate robustly the variance. Can be <code>'Robbins'</code>, <code>'Grad'</code> or <code>'Fix'</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>niterMC</code></td>
<td>
<p>The number of iterations for estimating robustly the variance of each class if <code>methodMC='Fix'</code> or <code>methodMC='Grad'</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps_vp</code></td>
<td>
<p>The minimum values for the estimates of the eigenvalues of the Variance can take. Default is <code>10^-4</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cRM</code></td>
<td>
<p>The constant in the stepsequence if the Robbins-Monro algorithm is used to robustly estimate the variance, i.e. if <code>methodMC='Robbins'</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>A scalar that avoid numerical problems if method='Offline'. Default is <code>10^(-3)</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list with:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>A <code class="reqn">(p,q)</code>-matrix giving the estimation of the parameters of the MultivariateGaussian Linear Regression.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Residual_Variance</code></td>
<td>
<p>A <code class="reqn">(q,q)</code>-matrix giving the estimation of the variance of the residuals.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>criterion</code></td>
<td>
<p>A vector giving the loss for the different chosen <code>lambda</code>. If <code>scale='robust'</code>, it is calculated on the scaled data. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>all_beta</code></td>
<td>
<p>A list containing the different estimation of the parameters (with respect to the different choices of <code>lambda</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda_opt</code></td>
<td>
<p>A scalar giving the selected <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>variance_results</code></td>
<td>
<p>A list giving the results on the variance of the noise obtained with the help of the function <code>Robust_Variance</code>. If <code>scale='robust'</code>, it is calculated on the scaled data. The details are given above.</p>
</td>
</tr>
</table>
<p>Details of the list <code>variance_results</code>:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Sigma</code></td>
<td>
<p>The robust estimation of the variance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>invSigma</code></td>
<td>
<p>The robuste estimation of the inverse of the variance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MCM</code></td>
<td>
<p>The Median Covariation Matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eigenvalues</code></td>
<td>
<p>A vector containing the estimation of the <code class="reqn">d+1</code> main eigenvalues of the variance, where <code class="reqn">d+1</code> is the optimal choice belonging to <code>K</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MCM_eigenvalues</code></td>
<td>
<p>A vector containing the estimation of the <code class="reqn">d+1</code> main eigenvalues of the Median Covariation Matrix, where <code class="reqn">d+1</code> is the optimal choice belonging to <code>K</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cap</code></td>
<td>
<p>The result given for capushe for selecting <code class="reqn">d</code> if the length of <code>K</code> is larger than 10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reduction_results</code></td>
<td>
<p>A list containing the results for all possible <code>K</code>.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Cardot, H., Cenac, P. and Zitt, P-A. (2013). Efficient and fast estimation of the geometric median in Hilbert spaces with an averaged stochastic gradient algorithm. <em>Bernoulli</em>, 19, 18-43.
</p>
<p>Cardot, H. and Godichon-Baggioni, A. (2017). Fast Estimation of the Median Covariation Matrix with Application to Online Robust Principal Components Analysis. <em>Test</em>, 26(3), 461-480
</p>
<p>Vardi, Y. and Zhang, C.-H. (2000). The multivariate L1-median and associated data depth. <em>Proc. Natl. Acad. Sci. USA</em>, 97(4):1423-1426.
</p>


<h3>See Also</h3>

<p>See also <code>Robust_Variance</code>, <code>Robust_regression</code> and <code>RobRegression-package</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
p=5
q=10
n=2000
mu=rep(0,q)
Sigma=diag(c(q,rep(0.1,q-1)))
epsilon=mvtnorm::rmvnorm(n = n,mean = mu,sigma = Sigma)
X=mvtnorm::rmvnorm(n=n,mean=rep(0,p))
beta=matrix(rnorm(p*q),ncol=q)
Y=X %*% beta+epsilon
Res_reg=Robust_Mahalanobis_regression(X,Y,par=FALSE)
sum((Res_reg$beta-beta)^2)

</code></pre>


</div>