<div class="container">

<table style="width: 100%;"><tr>
<td>trainSupv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Train a Classifier</h2>

<h3>Description</h3>

<p>Trains a classifier for supervised classification of record pairs.
</p>


<h3>Usage</h3>

<pre><code class="language-R">trainSupv(rpairs, method, use.pred = FALSE, omit.possible = TRUE, 
  convert.na = TRUE, include.data = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>rpairs</code></td>
<td>
<p>Object of class <code>RecLinkData</code>. Training data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>A character vector. The classification method to use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use.pred</code></td>
<td>
<p>Logical. Whether to use results of an unsupervised classification 
instead of true matching status.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>omit.possible</code></td>
<td>
<p>Logical. Whether to remove pairs labeled as possible
links or with unknown status.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>convert.na</code></td>
<td>
<p>Logical. Whether to convert <code>NA</code>s to 0 in the
comparison patterns.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>include.data</code></td>
<td>
<p>Logical. Whether to include training data in the result object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further arguments to the training method.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The given dataset is used as training data for a supervised classification.
Either the true matching status has to be known for a sufficient number of
data pairs or the data must have been classified previously, e.g. by using
<code>emClassify</code> or <code>classifyUnsup</code>. In the latter case,
argument <code>use.pred</code> has to be set to <code>TRUE</code>.
</p>
<p>A classifying method has to be provided as a character string (factors are
converted to character) through argument <code>method</code>.
The supported classifiers are:
</p>

<dl>
<dt><code>"svm"</code></dt>
<dd>
<p>Support vector machine, see <code>svm</code>.</p>
</dd>
<dt><code>"rpart"</code></dt>
<dd>
<p>Recursive partitioning tree, see <code>rpart</code>.</p>
</dd>
<dt><code>"ada"</code></dt>
<dd>
<p>Stochastic boosting model, see <code>ada</code>.</p>
</dd>
<dt><code>"bagging"</code></dt>
<dd>
<p>Bagging with classification trees, see <code>bagging</code>.</p>
</dd>
<dt><code>"nnet"</code></dt>
<dd>
<p>Single-hidden-layer neural network, see <code>nnet</code>.</p>
</dd>
<dt><code>"bumping"</code></dt>
<dd>
<p>A bootstrap based method using classification trees, see details.</p>
</dd>
</dl>
<p>Arguments in <code>...</code> are passed to the corresponding function.
</p>
<p>Most classifiers cannot handle <code>NA</code>s in the data, so by default these
are converted to 0 before training.
</p>
<p>By <code>omit.possible = TRUE</code>, possible links or pairs with unknown status
are excluded from the training set. Setting this argument to <code>FALSE</code>
allows three-class-classification (links, non-links and possible links), but
the results tend to be poor.
</p>
<p>Leaving <code>include.data=FALSE</code> saves memory, setting it to <code>TRUE</code> can be useful for saving the classificator while keeping track of the underlying training data.
</p>
<p><abbr><span class="acronym">Bumping</span></abbr>, (acronym for “Bootstrap umbrella of model
parameters”), is an ensemble method described by <cite>Tibshirani and Knight,
1999</cite>. Such as in bagging, multiple classifiers are trained on bootstrap
samples of the training set. The key difference is that not the aggregated
decision of all classifiers (e.g. by majority vote) is used to classify new
data, but only the single model that performs best on the whole training set.
In combination with classification trees as underlying classifiers this
approach allows good interpretability of the trained model while being more
stable against outliers than traditionally induced decision trees. The number
of bootstrap samples to use can be controlled by supplying the argument
<code>n.bootstrap</code>, which defaults to 25.
</p>


<h3>Value</h3>

<p>An object of class <code>RecLinkClassif</code> with the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>train</code></td>
<td>
<p>If <code>include.data</code> is <code>TRUE</code>, a copy of <code>rpairs</code>,
otherwise an empty data frame with the same column names.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>The model returned by the underlying training function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>A copy of the argument <code>method</code>.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>References</h3>

<p>Tibshirani R, Knight K: Model search by bootstrap “bumping”.
Journal of Computational and Graphical Statistics 8(1999):671–686.
</p>


<h3>See Also</h3>

<p><code>classifySupv</code> for classifying with the trained model, 
<code>classifyUnsup</code> for unsupervised classification</p>


<h3>Examples</h3>

<pre><code class="language-R"># Train a rpart decision tree with additional parameter minsplit
data(RLdata500)
pairs=compare.dedup(RLdata500, identity=identity.RLdata500,
                    blockfld=list(1,3,5,6,7))
model=trainSupv(pairs, method="rpart", minsplit=5)
summary(model)
</code></pre>


</div>