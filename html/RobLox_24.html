<div class="container">

<table style="width: 100%;"><tr>
<td>roblox</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Optimally robust estimator for location and/or scale</h2>

<h3>Description</h3>

<p>The function <code>roblox</code> computes the optimally robust estimator
and corresponding IC for normal location und/or scale and 
(convex) contamination neighborhoods. The definition of 
these estimators can be found in Rieder (1994) or Kohl (2005),
respectively.
</p>


<h3>Usage</h3>

<pre><code class="language-R">roblox(x, mean, sd, eps, eps.lower, eps.upper, initial.est, k = 1L, 
       fsCor = TRUE, returnIC = FALSE, mad0 = 1e-4, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p> vector <code>x</code> of data values, may also be a matrix or data.frame
with one row, respectively one column/(numeric) variable. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mean</code></td>
<td>
<p> specified mean. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sd</code></td>
<td>
<p> specified standard deviation which has to be positive. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p> positive real (0 &lt; <code>eps</code> &lt;= 0.5): amount of gross errors. 
See details below. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps.lower</code></td>
<td>
<p> positive real (0 &lt;= <code>eps.lower</code> &lt;= <code>eps.upper</code>): 
lower bound for the amount of gross errors. See details below. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps.upper</code></td>
<td>
<p> positive real (<code>eps.lower</code> &lt;= <code>eps.upper</code> &lt;= 0.5): 
upper bound for the amount of gross errors. See details below. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initial.est</code></td>
<td>
<p> initial estimate for <code>mean</code> and/or <code>sd</code>. If missing 
median and/or MAD are used. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p> positive integer. k-step is used to compute the optimally robust estimator. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fsCor</code></td>
<td>
<p> logical: perform finite-sample correction. See function <code>finiteSampleCorrection</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>returnIC</code></td>
<td>
<p> logical: should IC be returned. See details below. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mad0</code></td>
<td>
<p> scale estimate used if computed MAD is equal to zero</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>logical: if  <code>TRUE</code>, the estimator is evaluated at <code>complete.cases(x)</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Computes the optimally robust estimator for location with scale specified,
scale with location specified, or both if neither is specified. The computation
uses a k-step construction with an appropriate initial estimate for location
or scale or location and scale, respectively. Valid candidates are e.g. 
median and/or MAD (default) as well as Kolmogorov(-Smirnov) or von Mises minimum 
distance estimators; cf. Rieder (1994) and Kohl (2005).
</p>
<p>If the amount of gross errors (contamination) is known, it can be 
specified by <code>eps</code>. The radius of the corresponding infinitesimal 
contamination neighborhood is obtained by multiplying <code>eps</code> 
by the square root of the sample size. 
</p>
<p>If the amount of gross errors (contamination) is unknown, try to find a 
rough estimate for the amount of gross errors, such that it lies 
between <code>eps.lower</code> and <code>eps.upper</code>.
</p>
<p>In case <code>eps.lower</code> is specified and <code>eps.upper</code> is missing, 
<code>eps.upper</code> is set to 0.5. In case <code>eps.upper</code> is specified and
<code>eps.lower</code> is missing, <code>eps.lower</code> is set to 0.
</p>
<p>If neither <code>eps</code> nor <code>eps.lower</code> and/or <code>eps.upper</code> is 
specified, <code>eps.lower</code> and <code>eps.upper</code> are set to 0 and 0.5, 
respectively.
</p>
<p>If <code>eps</code> is missing, the radius-minimax estimator in sense of 
Rieder et al. (2008), respectively Section 2.2 of Kohl (2005) is returned.
</p>
<p>In case of location, respectively scale one additionally has to specify
<code>sd</code>, respectively <code>mean</code> where <code>sd</code> and <code>mean</code> have
to be a single number.
</p>
<p>For sample size &lt;= 2, median and/or MAD are used for estimation.
</p>
<p>If <code>eps = 0</code>, mean and/or sd are computed. In this situation it's better
to use function <code>MLEstimator</code>.
</p>


<h3>Value</h3>

<p>Object of class <code>"kStepEstimate"</code>. </p>


<h3>Author(s)</h3>

<p>Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>M. Kohl (2005). Numerical Contributions to the Asymptotic Theory of Robustness.
Dissertation. University of Bayreuth. <a href="https://epub.uni-bayreuth.de/id/eprint/839/2/DissMKohl.pdf">https://epub.uni-bayreuth.de/id/eprint/839/2/DissMKohl.pdf</a>.
</p>
<p>H. Rieder (1994): Robust Asymptotic Statistics. Springer. <a href="https://doi.org/10.1007/978-1-4684-0624-5">doi:10.1007/978-1-4684-0624-5</a>
</p>
<p>H. Rieder, M. Kohl, and P. Ruckdeschel (2008). The Costs of Not Knowing the Radius.
Statistical Methods and Applications  <em>17</em>(1): 13-40. <a href="https://doi.org/10.1007/s10260-007-0047-7">doi:10.1007/s10260-007-0047-7</a>
</p>
<p>M. Kohl, P. Ruckdeschel, and H. Rieder (2010). Infinitesimally Robust Estimation in 
General Smoothly Parametrized Models. Statistical Methods and Applications <em>19</em>(3): 333-354.
<a href="https://doi.org/10.1007/s10260-010-0133-0">doi:10.1007/s10260-010-0133-0</a>.
</p>
<p>M. Kohl and H.P. Deigner (2010). Preprocessing of gene expression data by 
optimally robust estimators. BMC Bioinformatics <em>11</em>, 583.
<a href="https://doi.org/10.1186/1471-2105-11-583">doi:10.1186/1471-2105-11-583</a>.
</p>


<h3>See Also</h3>

<p><code>ContIC-class</code>, <code>rlOptIC</code>, 
<code>rsOptIC</code>, <code>rlsOptIC.AL</code>,
<code>kStepEstimate-class</code>,
<code>roptest</code> </p>


<h3>Examples</h3>

<pre><code class="language-R">ind &lt;- rbinom(100, size=1, prob=0.05) 
x &lt;- rnorm(100, mean=ind*3, sd=(1-ind) + ind*9)

## amount of gross errors known
res1 &lt;- roblox(x, eps = 0.05, returnIC = TRUE)
estimate(res1)
## don't run to reduce check time on CRAN
## Not run: 
confint(res1)
confint(res1, method = symmetricBias())
pIC(res1)
checkIC(pIC(res1))
Risks(pIC(res1))
Infos(pIC(res1))
plot(pIC(res1))
infoPlot(pIC(res1))

## End(Not run)

## amount of gross errors unknown
res2 &lt;- roblox(x, eps.lower = 0.01, eps.upper = 0.1, returnIC = TRUE)
estimate(res2)
## don't run to reduce check time on CRAN
## Not run: 
confint(res2)
confint(res2, method = symmetricBias())
pIC(res2)
checkIC(pIC(res2))
Risks(pIC(res2))
Infos(pIC(res2))
plot(pIC(res2))
infoPlot(pIC(res2))

## End(Not run)

## estimator comparison
# classical optimal (non-robust)
c(mean(x), sd(x))

# most robust
c(median(x), mad(x))

# optimally robust (amount of gross errors known)
estimate(res1)

# optimally robust (amount of gross errors unknown)
estimate(res2)

# Kolmogorov(-Smirnov) minimum distance estimator (robust)
(ks.est &lt;- MDEstimator(x, ParamFamily = NormLocationScaleFamily()))

# optimally robust (amount of gross errors known)
roblox(x, eps = 0.05, initial.est = estimate(ks.est))

# Cramer von Mises minimum distance estimator (robust)
(CvM.est &lt;- MDEstimator(x, ParamFamily = NormLocationScaleFamily(), distance = CvMDist))

# optimally robust (amount of gross errors known)
roblox(x, eps = 0.05, initial.est = estimate(CvM.est))
</code></pre>


</div>