<div class="container">

<table style="width: 100%;"><tr>
<td>comp_accu_prob</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compute exact accuracy metrics based on probabilities.</h2>

<h3>Description</h3>

<p><code>comp_accu_prob</code> computes a list of exact accuracy metrics
from a sufficient and valid set of 3 essential probabilities
(<code>prev</code>, and
<code>sens</code> or its complement <code>mirt</code>, and
<code>spec</code> or its complement <code>fart</code>).
</p>


<h3>Usage</h3>

<pre><code class="language-R">comp_accu_prob(
  prev = prob$prev,
  sens = prob$sens,
  mirt = NA,
  spec = prob$spec,
  fart = NA,
  tol = 0.01,
  w = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>prev</code></td>
<td>
<p>The condition's prevalence <code>prev</code>
(i.e., the probability of condition being <code>TRUE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sens</code></td>
<td>
<p>The decision's sensitivity <code>sens</code>
(i.e., the conditional probability of a positive decision
provided that the condition is <code>TRUE</code>).
<code>sens</code> is optional when its complement <code>mirt</code> is provided.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mirt</code></td>
<td>
<p>The decision's miss rate <code>mirt</code>
(i.e., the conditional probability of a negative decision
provided that the condition is <code>TRUE</code>).
<code>mirt</code> is optional when its complement <code>sens</code> is provided.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>spec</code></td>
<td>
<p>The decision's specificity value <code>spec</code>
(i.e., the conditional probability
of a negative decision provided that the condition is <code>FALSE</code>).
<code>spec</code> is optional when its complement <code>fart</code> is provided.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fart</code></td>
<td>
<p>The decision's false alarm rate <code>fart</code>
(i.e., the conditional probability
of a positive decision provided that the condition is <code>FALSE</code>).
<code>fart</code> is optional when its complement <code>spec</code> is provided.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>A numeric tolerance value for <code>is_complement</code>.
Default: <code>tol = .01</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w</code></td>
<td>
<p>The weighting parameter <code>w</code> (from 0 to 1)
for computing weighted accuracy <code>wacc</code>.
Default: <code>w = .50</code> (i.e., yielding balanced accuracy <code>bacc</code>).
</p>
<p>Notes:
</p>

<ul>
<li>
<p> Accuracy metrics describe the <em>correspondence</em> of decisions (or predictions) to actual conditions (or truth).
</p>
<p>There are several possible interpretations of accuracy:
</p>

<ol>
<li>
<p> as <em>probabilities</em> (i.e., <code>acc</code> being the proportion of correct classifications,
or the ratio <code>dec_cor</code>/<code>N</code>),
</p>
</li>
<li>
<p> as <em>frequencies</em> (e.g., as classifying a population of <code>N</code>
individuals into cases of <code>dec_cor</code> vs. <code>dec_err</code>),
</p>
</li>
<li>
<p> as <em>correlations</em> (e.g., see <code>mcc</code> in <code>accu</code>).
</p>
</li>
</ol>
</li>
<li>
<p> Computing exact accuracy values based on probabilities (by <code>comp_accu_prob</code>) may differ from
accuracy values computed from (possibly rounded) frequencies (by <code>comp_accu_freq</code>).
</p>
<p>When frequencies are rounded to integers (see the default of <code>round = TRUE</code>
in <code>comp_freq</code> and <code>comp_freq_prob</code>) the accuracy metrics computed by
<code>comp_accu_freq</code> correspond to these rounded values.
Use <code>comp_accu_prob</code> to obtain exact accuracy metrics from probabilities.
</p>
</li>
</ul>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Currently computed accuracy metrics include:
</p>

<ol>
<li> <p><code>acc</code>: Overall accuracy as the proportion (or probability)
of correctly classifying cases or of <code>dec_cor</code> cases:
</p>
<p>(a) from <code>prob</code>: <code>acc = (prev x sens) + [(1 - prev) x spec]</code>
</p>
<p>(b) from <code>freq</code>: <code>acc = dec_cor/N = (hi + cr)/(hi + mi + fa + cr)</code>
</p>
<p>When frequencies in <code>freq</code> are not rounded, (b) coincides with (a).
</p>
<p>Values range from 0 (no correct prediction) to 1 (perfect prediction).
</p>
</li>
<li> <p><code>wacc</code>: Weighted accuracy, as a weighted average of the
sensitivity <code>sens</code> (aka. hit rate <code>HR</code>, <code>TPR</code>,
<code>power</code> or <code>recall</code>)
and the the specificity <code>spec</code> (aka. <code>TNR</code>)
in which <code>sens</code> is multiplied by a weighting parameter <code>w</code>
(ranging from 0 to 1) and <code>spec</code> is multiplied by
<code>w</code>'s complement <code>(1 - w)</code>:
</p>
<p><code>wacc = (w * sens) + ((1 - w) * spec)</code>
</p>
<p>If <code>w = .50</code>, <code>wacc</code> becomes <em>balanced</em> accuracy <code>bacc</code>.
</p>
</li>
<li> <p><code>mcc</code>: The Matthews correlation coefficient (with values ranging from -1 to +1):
</p>
<p><code>mcc = ((hi * cr) - (fa * mi)) / sqrt((hi + fa) * (hi + mi) * (cr + fa) * (cr + mi))</code>
</p>
<p>A value of <code>mcc = 0</code> implies random performance; <code>mcc = 1</code> implies perfect performance.
</p>
<p>See <a href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient">Wikipedia: Matthews correlation coefficient</a>
for additional information.
</p>
</li>
<li> <p><code>f1s</code>: The harmonic mean of the positive predictive value <code>PPV</code>
(aka. <code>precision</code>)
and the sensitivity <code>sens</code> (aka. hit rate <code>HR</code>,
<code>TPR</code>, <code>power</code> or <code>recall</code>):
</p>
<p><code>f1s =  2 * (PPV * sens) / (PPV + sens)</code>
</p>
<p>See <a href="https://en.wikipedia.org/wiki/F1_score">Wikipedia: F1 score</a> for additional information.
</p>
</li>
</ol>
<p>Note that some accuracy metrics can be interpreted
as probabilities (e.g., <code>acc</code>) and some as correlations (e.g., <code>mcc</code>).
</p>
<p>Also, accuracy can be viewed as a probability (e.g., the ratio of or link between
<code>dec_cor</code> and <code>N</code>) or as a frequency type
(containing <code>dec_cor</code> and <code>dec_err</code>).
</p>
<p><code>comp_accu_prob</code> computes exact accuracy metrics from probabilities.
When input frequencies were rounded (see the default of <code>round = TRUE</code>
in <code>comp_freq</code> and <code>comp_freq_prob</code>) the accuracy
metrics computed by <code>comp_accu</code> correspond these rounded values.
</p>


<h3>Value</h3>

<p>A list <code>accu</code> containing current accuracy metrics.
</p>


<h3>References</h3>

<p>Consult <a href="https://en.wikipedia.org/wiki/Confusion_matrix">Wikipedia: Confusion matrix</a>
for additional information.
</p>


<h3>See Also</h3>

<p><code>accu</code> for all accuracy metrics;
<code>comp_accu_freq</code> computes accuracy metrics from frequencies;
<code>num</code> for basic numeric parameters;
<code>freq</code> for current frequency information;
<code>txt</code> for current text settings;
<code>pal</code> for current color settings;
<code>popu</code> for a table of the current population.
</p>
<p>Other metrics: 
<code>accu</code>,
<code>acc</code>,
<code>comp_accu_freq()</code>,
<code>comp_acc()</code>,
<code>comp_err()</code>,
<code>err</code>
</p>
<p>Other functions computing probabilities: 
<code>comp_FDR()</code>,
<code>comp_FOR()</code>,
<code>comp_NPV()</code>,
<code>comp_PPV()</code>,
<code>comp_accu_freq()</code>,
<code>comp_acc()</code>,
<code>comp_comp_pair()</code>,
<code>comp_complement()</code>,
<code>comp_complete_prob_set()</code>,
<code>comp_err()</code>,
<code>comp_fart()</code>,
<code>comp_mirt()</code>,
<code>comp_ppod()</code>,
<code>comp_prob_freq()</code>,
<code>comp_prob()</code>,
<code>comp_sens()</code>,
<code>comp_spec()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">comp_accu_prob()  # =&gt; accuracy metrics for prob of current scenario
comp_accu_prob(prev = .2, sens = .5, spec = .5)  # medium accuracy, but cr &gt; hi.

# Extreme cases:
comp_accu_prob(prev = NaN, sens = NaN, spec = NaN)  # returns list of NA values
comp_accu_prob(prev = 0, sens = NaN, spec = 1)      # returns list of NA values
comp_accu_prob(prev = 0, sens = 0, spec = 1)     # perfect acc = 1, but f1s is NaN
comp_accu_prob(prev = .5, sens = .5, spec = .5)  # random performance
comp_accu_prob(prev = .5, sens = 1,  spec = 1)   # perfect accuracy
comp_accu_prob(prev = .5, sens = 0,  spec = 0)   # zero accuracy, but f1s is NaN
comp_accu_prob(prev = 1,  sens = 1,  spec = 0)   # perfect, but see wacc (0.5) and mcc (0)

# Effects of w:
comp_accu_prob(prev = .5, sens = .6, spec = .4, w = 1/2)  # equal weights to sens and spec
comp_accu_prob(prev = .5, sens = .6, spec = .4, w = 2/3)  # more weight on sens: wacc up
comp_accu_prob(prev = .5, sens = .6, spec = .4, w = 1/3)  # more weight on spec: wacc down

# Contrasting comp_accu_freq and comp_accu_prob:
# (a) comp_accu_freq (based on rounded frequencies):
freq1 &lt;- comp_freq(N = 10, prev = 1/3, sens = 2/3, spec = 3/4)   # =&gt; rounded frequencies!
accu1 &lt;- comp_accu_freq(freq1$hi, freq1$mi, freq1$fa, freq1$cr)  # =&gt; accu1 (based on rounded freq).
# accu1

# (b) comp_accu_prob (based on probabilities):
accu2 &lt;- comp_accu_prob(prev = 1/3, sens = 2/3, spec = 3/4)      # =&gt; exact accu (based on prob).
# accu2
all.equal(accu1, accu2)  # =&gt; 4 differences!
#
# (c) comp_accu_freq (exact values, i.e., without rounding):
freq3 &lt;- comp_freq(N = 10, prev = 1/3, sens = 2/3, spec = 3/4, round = FALSE)
accu3 &lt;- comp_accu_freq(freq3$hi, freq3$mi, freq3$fa, freq3$cr)  # =&gt; accu3 (based on EXACT freq).
# accu3
all.equal(accu2, accu3)  # =&gt; TRUE (qed).


</code></pre>


</div>