<div class="container">

<table style="width: 100%;"><tr>
<td>rwnn</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Random weight neural networks</h2>

<h3>Description</h3>

<p>Set-up and estimate weights of a random weight neural network.
</p>


<h3>Usage</h3>

<pre><code class="language-R">rwnn(
  formula,
  data = NULL,
  n_hidden = c(),
  lambda = 0,
  type = NULL,
  control = list()
)

## S3 method for class 'formula'
rwnn(
  formula,
  data = NULL,
  n_hidden = c(),
  lambda = 0,
  type = NULL,
  control = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>A formula specifying features and targets used to estimate the parameters of the output layer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A data-set (either a data.frame or a tibble) used to estimate the parameters of the output layer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_hidden</code></td>
<td>
<p>A vector of integers designating the number of neurons in each of the hidden layers (the length of the list is taken as the number of hidden layers).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>The penalisation constant used when training the output layer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>A string indicating whether this is a regression or classification problem.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>A list of additional arguments passed to the control_rwnn function.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>A deep RWNN is constructed by increasing the number of elements in the vector <code>n_hidden</code>. Furthermore, if <code>type</code> is null, then the function tries to deduce it from class of target.
</p>


<h3>Value</h3>

<p>An RWNN-object.
</p>


<h3>References</h3>

<p>Schmidt W., Kraaijveld M., Duin R. (1992) "Feedforward neural networks with random weights." <em>In Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems</em>, 1–4.
</p>
<p>Pao Y., Park G., Sobajic D. (1992) "Learning and generalization characteristics of random vector Functional-link net." <em>Neurocomputing</em>, 6, 163–180.
</p>
<p>Huang G.B., Zhu Q.Y., Siew C.K. (2006) "Extreme learning machine: Theory and applications." <em>Neurocomputing</em>, 70(1), 489–501.
</p>
<p>Henríquez P.A., Ruz G.A. (2018) "Twitter Sentiment Classification Based on Deep Random Vector Functional Link." <em>In 2018 International Joint Conference on Neural Networks (IJCNN)</em>, 1–6.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Models with a single hidden layer
n_hidden &lt;- 50
lambda &lt;- 0.01

# Regression
m &lt;- rwnn(y ~ ., data = example_data, n_hidden = n_hidden, lambda = lambda)

# Classification
m &lt;- rwnn(I(y &gt; median(y)) ~ ., data = example_data, n_hidden = n_hidden, lambda = lambda)

## Model with multiple hidden layers
n_hidden &lt;- c(20, 15, 10, 5)
lambda &lt;- 0.01

# Combining outputs from all hidden layers (default)
m &lt;- rwnn(y ~ ., data = example_data, n_hidden = n_hidden, lambda = lambda)

# Using only the output of the last hidden layer
m &lt;- rwnn(y ~ ., data = example_data, n_hidden = n_hidden,
          lambda = lambda, control = list(combine_hidden = FALSE))

</code></pre>


</div>