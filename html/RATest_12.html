<div class="container">

<table style="width: 100%;"><tr>
<td>RPT</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Robust Permutation Test</h2>

<h3>Description</h3>

<p>This function considers the k-sample problem of comparing general parameters, such as means, medians, or parameters that depend on the joint distribution using permutation tests. Under weak assumptions for comparing estimator, the permutation tests implemented here provide a general test procedure whereby the asymptotic validity of the permutation test holds while retaining the exact rejection probability <code class="reqn">\alpha</code> in finite samples when the underlying distributions are identical.
Here we will consider three test for the 2 sample case, but the function works for k-samples. 
</p>
<p>Difference of means: Here, the null hypothesis is of the form <code class="reqn">H_0: \mu(P)-\mu(Q)=0</code>, and the corresponding test statistic is given by 
</p>
<p style="text-align: center;"><code class="reqn">T_{m,n}=\frac{N^{1/2}(\bar{X}_m-\bar{Y}_n)}{\sqrt{\frac{N}{m}\sigma^2_m(X_1,\dots,X_m)+ \frac{N}{n}\sigma^2_n(Y_1,\dots,Y_n)}}</code>
</p>
  
<p>where <code class="reqn">\bar{X}_m</code> and <code class="reqn">\bar{Y}_n</code> are the sample means from population <code class="reqn">P</code> and population <code class="reqn">Q</code>, respectively, and <code class="reqn">\sigma^2_m(X_1,\dots,X_m)</code> is a consistent estimator of <code class="reqn">\sigma^2(P)</code> when <code class="reqn">X_1,\dots,X_m</code> are i.i.d. from <code class="reqn">P</code>. Assume consistency also under <code class="reqn">Q</code>.
</p>
<p>Difference of medians: Let <code class="reqn">F</code> and <code class="reqn">G</code> be the CDFs corresponding to <code class="reqn">P</code> and <code class="reqn">Q</code>, and denote <code class="reqn">\theta(F)</code> the median of <code class="reqn">F</code> i.e. <code class="reqn">\theta(F)=\inf\{x:F(x)\ge1/2\}</code>. Assume that <code class="reqn">F</code> is continuously differentiable at <code class="reqn">\theta(P)</code> with derivative <code class="reqn">F'</code> (and the same with <code class="reqn">F</code> replaced by <code class="reqn">G</code>). Here, the null hypothesis is of the form  <code class="reqn">H_0: \theta(P)-\theta(Q)=0</code>, and the corresponding test statistic is given by
</p>
<p style="text-align: center;"><code class="reqn">T_{m,n}=\frac{N^{1/2}\left(\theta(\hat{P}_m)-\theta(\hat{Q})\right)}{\hat{\upsilon}_{m,n}}</code>
</p>

<p>where <code class="reqn">\hat{\upsilon}_{m,n}</code> is a consistent estimator of <code class="reqn">\upsilon(P,Q)</code>:
</p>
<p style="text-align: center;"><code class="reqn">\upsilon(P,Q)=\frac{1}{\lambda}\frac{1}{4(F'(\theta))^2}+\frac{1}{1-\lambda}\frac{1}{4(G'(\theta))^2}</code>
</p>

<p>Choices of <code class="reqn">\hat{\upsilon}_{m,n}</code> may include the kernel estimator of Devroye and Wagner (1980), the bootstrap estimator of Efron (1992), or the smoothed bootstrap  Hall et al. (1989) to list a few. For further details, see Chung and Romano (2013). Current implementation uses the bootstrap estimator of Efron (1992)
</p>
<p>Difference of variances: Here, the null hypothesis is of the form <code class="reqn">H_0: \sigma^2(P)-\sigma^2(Q)=0</code>, and the corresponding test statistic is given by 
</p>
<p style="text-align: center;"><code class="reqn">T_{m,n}=\frac{N^{1/2}(\hat{\sigma}_m^2(X_1,\dots,X_,)-\hat{\sigma}_n^2(Y_1,\dots,Y_n))}{\sqrt{\frac{N}{m}(\hat{\mu}_{4,x}-\frac{(m-3)}{(m-1)}(\hat{\sigma}_m^2)^2)+\frac{N}{n}(\hat{\mu}_{4,y}-\frac{(n-3)}{(n-1)}(\hat{\sigma}_y^2)^2)}}</code>
</p>
 
<p>where <code class="reqn">\hat{\mu}_{4,m}</code> the sample analog of <code class="reqn">E(X-\mu)^4</code> based on an i.i.d. sample <code class="reqn">X_1,\dots,X_m</code> from <code class="reqn">P</code>. Similarly for <code class="reqn">\hat{\mu}_{4,n}</code>.
</p>
<p>We could also have the case when the parameter of interest is a function of the joint distribution. The examples considered here are
</p>
<p>Lehmann (1951) two-sample U statistics: Consider testing <code class="reqn">H_0: P=Q</code>, or the more general hypothesis that <code class="reqn">P</code> and <code class="reqn">Q</code> only differ in location against the alternative that the <code class="reqn">Y</code>'s are more spread out than the <code class="reqn">X</code>'s. The null hypothesis is of the form </p>
<p style="text-align: center;"><code class="reqn">H_0: P(\vert Y-Y'\vert&gt;\vert X-X'\vert)=1/2</code>
</p>
<p>.
</p>
<p>Two-sample Wilcoxon statistic, where the null hypothesis is of the form </p>
<p style="text-align: center;"><code class="reqn">H_0: P(X\le Y)=1/2</code>
</p>
<p>.
</p>
<p>Two-sample Wilcoxon statistic without continuity assumption. In this case, the null hypothesis is of the form </p>
<p style="text-align: center;"><code class="reqn">H_0: P(X\le Y)=P(Y\le X)</code>
</p>
<p>.
</p>
<p>Hollander (1967) two-sample U statistics. The null hypothesis is of the form </p>
<p style="text-align: center;"><code class="reqn">H_0: P(X+X'&lt;Y+Y')=1/2</code>
</p>
<p>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">RPT(
  formula,
  data,
  test = "means",
  n.perm = 499,
  na.action,
  wilcoxon.option = "continuity"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>a formula object, with the response on the left of a ~ operator, and the groups on the right.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>a data.frame in which to interpret the variables named in the formula. If this is missing, then the variables in the formula should be on the search list.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test</code></td>
<td>
<p>test to be perfomed. Multiple options are available, depending on the nature of the testing problem. In general, we have two types of problem. First, when the researcher is interested in comparing parameters. In this case, "means" will perform a Difference of Means, "medians" a Difference of Medians, "variances" a Difference of Variances. This case allows for 2 or more population comparisons. For the test of difference of medians the Efron (1992) bootstrap estimator is used to estimate the variances (for further details, see Chung and Romano (2013)). Second, when the parameter of interest is a function of the joint distribution. In this case, "lehmann.2S.test" will perform Lehmann (1951) two-sample U statistics, "wilcoxon.2s.test" the two-sample Wilcoxon test (with or without continuity assumption), and "hollander.2S.test" Hollander (1967) two sample U statistics. In this case, only 2 sample comparisons are permitted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.perm</code></td>
<td>
<p>Numeric. Number of permutations needed for the stochastic approximation of the p-values. See remark 3.2 in Canay and Kamat (2017). The default is n.perm=499.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.action</code></td>
<td>
<p>a function to filter missing data. This is applied to the model.frame . The default is na.omit, which deletes observations that contain one or more missing values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wilcoxon.option</code></td>
<td>
<p>Continuity assumption for Wilcoxon test" with continuity ("continuity") or without ("discontinuity"). The default is "continuity"</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>An object of class "RPT" is a list containing at least the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>description</code></td>
<td>
<p>Type of test, can be Difference of Means, Medians, or Variances.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_populations</code></td>
<td>
<p>Number of grups.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>N</code></td>
<td>
<p>Sample Size.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>T.obs</code></td>
<td>
<p>Observed test statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pvalue</code></td>
<td>
<p>P-value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>T.perm</code></td>
<td>
<p>Vector. Test statistics from the permutations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_perm</code></td>
<td>
<p>Number of permutations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parameters</code></td>
<td>
<p>Estimated parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sample_sizes</code></td>
<td>
<p>Groups lengths.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Maurcio Olivares
</p>
<p>Ignacio Sarmiento Barbieri
</p>


<h3>References</h3>

<p>Chung, E. and Romano, J. P. (2013). Exact and asymptotically robust permutation tests. The Annals of Statistics, 41(2):484–507.
Chung, E. and Romano, J. P. (2016). Asymptotically valid and exact permutation tests based on two-sample u-statistics. Journal of Statistical Planning and Inference, 168:97–105.
Devroye, L. P. and Wagner, T. J. (1980). The strong uniform consistency of kernel density estimates. In Multivariate Analysis V: Proceedings of the fifth International Symposium on Multivariate Analysis, volume 5, pages 59–77.
Efron, B. (1992). Bootstrap methods: another look at the jackknife. In Breakthroughs in statistics, pages 569–593. Springer.
Hall, P., DiCiccio, T. J., and Romano, J. P. (1989). On smoothing and the bootstrap. The Annals of Statistics, pages 692–704.
Hollander, M. (1967). Asymptotic efficiency of two nonparametric competitors of wilcoxon’s two sample test. Journal of the American Statistical Association, 62(319):939–949.
Lehmann, E. L. (1951). Consistency and unbiasedness of certain nonparametric tests. The Annals of Mathematical Statistics, pages 165–179.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
male&lt;-rnorm(50,1,1)
female&lt;-rnorm(50,1,2)
dta&lt;-data.frame(group=c(rep(1,50),rep(2,50)),outcome=c(male,female))
rpt.var&lt;-RPT(dta$outcome~dta$group,test="variances")
summary(rpt.var)


## End(Not run)
</code></pre>


</div>