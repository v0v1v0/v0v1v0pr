<div class="container">

<table style="width: 100%;"><tr>
<td>rl_dnn_config</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>DNN Configuration for Reinforcement Learning</h2>

<h3>Description</h3>

<p>DNN (deep neural network) configuration for reinforcement learning.
For detail, see Section 3.2.6 of the original paper.
</p>


<h3>Usage</h3>

<pre><code class="language-R">rl_dnn_config(
  fcnet_hiddens = c(256L, 256L),
  fcnet_activation = c("relu", "tanh", "swish", "silu", "linear"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>fcnet_hiddens</code></td>
<td>
<p>A positive integer vector. Numbers of units of the
intermediate layers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fcnet_activation</code></td>
<td>
<p>A character value specifying the activation function.
Possible values are "ReLU" (default), "tanh", "Swish" (or "SiLU"), or
"linear".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Other configurations. See source code of RLlib.
https://github.com/ray-project/ray/blob/master/rllib/models/catalog.py</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list of DNN configuration parameters
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
allocation_rule &lt;- learn_allocation_rule(
  models, 
  N_total = 150, N_ini = rep(10, 5), N_block = 10, Delta = 1.3,
  outcome_type = "continuous", sd_normal = sqrt(4.5), 
  seed = 123, 
  # We change iter to 200 and cores to 8
  rl_config = rl_config_set(
    iter = 1000, 
    # We change the DNN model
    model = rl_dnn_config(fcnet_hiddens = c(512L, 512L), fcnet_activation = "tanh")
  ), 
  alpha = 0.025
)
## End(Not run) 

</code></pre>


</div>