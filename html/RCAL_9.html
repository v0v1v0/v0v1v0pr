<div class="container">

<table style="width: 100%;"><tr>
<td>glm.regu.cv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Regularied M-estimation for fitting generalized linear models based on cross validation</h2>

<h3>Description</h3>

<p>This function implements regularized M-estimation for fitting generalized linear models with binary or contiunous responses 
based on cross validation.
</p>


<h3>Usage</h3>

<pre><code class="language-R">glm.regu.cv(fold, nrho = NULL, rho.seq = NULL, y, x, iw = NULL,
  loss = "cal", n.iter = 100, eps = 1e-06, tune.fac = 0.5,
  tune.cut = TRUE, ann.init = TRUE, nz.lab = NULL, permut = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>fold</code></td>
<td>
<p>A fold number used for cross validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nrho</code></td>
<td>
<p>The number of tuning parameters searched in cross validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rho.seq</code></td>
<td>
<p>A vector of tuning parameters searched in cross validation. If both <code>nrho</code> and <code>rho.seq</code> are specified, then <code>rho.seq</code> overrides <code>nrho</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>An <code class="reqn">n</code> x <code class="reqn">1</code> response vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>An <code class="reqn">n</code> x <code class="reqn">p</code> matix of covariates, excluding a constant.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iw</code></td>
<td>
<p>An <code class="reqn">n</code> x <code class="reqn">1</code> weight vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loss</code></td>
<td>
<p>A loss function, which can be specified as "gaus" for continuous responses, or "ml" or "cal" for binary respones.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.iter</code></td>
<td>
<p>The maximum number of iterations allowed as in <code>glm.regu</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>The tolerance used to declare convergence as in <code>glm.regu</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tune.fac</code></td>
<td>
<p>The multiplier (factor) used to define <code>rho.seq</code> if only <code>nrho</code> is specified.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tune.cut</code></td>
<td>
<p>Logical; if <code>TRUE</code>, all smaller tuning parameters are skipped once non-convergence is found with a tuning parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ann.init</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the estimates from the previous tuning parameter are used as the inital values when fitting with the current tuning parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nz.lab</code></td>
<td>
<p>A <code class="reqn">p</code> x <code class="reqn">1</code> logical vector (useful for simulations), indicating which covariates are included when calculating the number of nonzero coefficients.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>permut</code></td>
<td>
<p>An <code class="reqn">n</code> x <code class="reqn">1</code> vector, giving a random permutation of the integers from 1 to <code class="reqn">n</code>, which is used in cross validation.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Cross validation is performed as described in Tan (2020a, 2020b). If not specified by users, the sequence of tuning parameters searched is defined as 
a geometric series of length <code>nrho</code>, starting from the value which yields a zero solution, and then decreasing by a factor <code>tune.fac</code> successively. 
</p>
<p>After cross validation, two tuning parameters are selected. The first and default choice is the value yielding the smallest average test loss.
The second choice is the largest value giving the average test loss within one standard error of the first choice (Hastie, Tibshirani, and Friedman 2016).
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>permut</code></td>
<td>
<p>An <code class="reqn">n</code> x <code class="reqn">1</code> vector, giving the random permutation used in cross validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rho</code></td>
<td>
<p>The vector of tuning parameters, searched in cross validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>non.conv</code></td>
<td>
<p>A vector indicating the non-convergene status found or imputed if <code>tune.cut=TRUE</code>, for the tuning parmaters in cross validation.
For each tuning parameter, 0 indicates convergence, 1 non-convergence if exceeding <code>n.iter</code>, 2 non-convergence if exceeding <code>bt.lim</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>err.ave</code></td>
<td>
<p>A vector giving the averages of the test losses in cross validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>err.sd</code></td>
<td>
<p>A vector giving the standard deviations of the test losses in cross validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sel.rho</code></td>
<td>
<p>A vector of two selected tuning parameters by cross validation; see <strong>Details</strong>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sel.nz</code></td>
<td>
<p>A vector of numbers of nonzero coefficients estimated for the selected tuning parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sel.bet</code></td>
<td>
<p>The <code class="reqn">(p+1)</code> x <code class="reqn">2</code> vector of estimated intercept and coefficients.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sel.fit</code></td>
<td>
<p>The <code class="reqn">n</code> x <code class="reqn">2</code> vector of fitted values.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Hastie, T., Tibshirani, R., and Friedman. J. (2016) <em>The Elements of Statistical Learning</em> (second edition), Springer: New York.
</p>
<p>Tan, Z. (2020a) Regularized calibrated estimation of propensity scores with model misspecification and high-dimensional data, <em>Biometrika</em>, 107, 137–158.
</p>
<p>Tan, Z. (2020b) Model-assisted inference for treatment effects using regularized calibrated estimation with high-dimensional data, <em>Annals of Statistics</em>, 48, 811–837.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(simu.data)
n &lt;- dim(simu.data)[1]
p &lt;- dim(simu.data)[2]-2

y &lt;- simu.data[,1]
tr &lt;- simu.data[,2]
x &lt;- simu.data[,2+1:p]
x &lt;- scale(x)

### Example 1: Regularized maximum likelihood estimation of propensity scores
ps.cv.rml &lt;- glm.regu.cv(fold=5, nrho=1+10, y=tr, x=x, loss="ml")
ps.cv.rml$rho
ps.cv.rml$err.ave
ps.cv.rml$err.sd
ps.cv.rml$sel.rho
ps.cv.rml$sel.nz

fp.cv.rml &lt;- ps.cv.rml $sel.fit[,1]
check.cv.rml &lt;- mn.ipw(x, tr, fp.cv.rml)
check.cv.rml$est

### Example 2: Regularized calibrated estimation of propensity scores
ps.cv.rcal &lt;- glm.regu.cv(fold=5, nrho=1+10, y=tr, x=x, loss="cal")
ps.cv.rcal$rho
ps.cv.rcal$err.ave
ps.cv.rcal$err.sd
ps.cv.rcal$sel.rho
ps.cv.rcal$sel.nz

fp.cv.rcal &lt;- ps.cv.rcal $sel.fit[,1]

check.cv.rcal &lt;- mn.ipw(x, tr, fp.cv.rcal)
check.cv.rcal$est


</code></pre>


</div>