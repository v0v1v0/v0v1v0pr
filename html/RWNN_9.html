<div class="container">

<table style="width: 100%;"><tr>
<td>control_rwnn</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>rwnn control function</h2>

<h3>Description</h3>

<p>A function used to create a control-object for the rwnn function.
</p>


<h3>Usage</h3>

<pre><code class="language-R">control_rwnn(
  n_hidden = NULL,
  n_features = NULL,
  lnorm = NULL,
  bias_hidden = TRUE,
  bias_output = TRUE,
  activation = NULL,
  combine_input = FALSE,
  combine_hidden = TRUE,
  include_data = TRUE,
  include_estimate = TRUE,
  rng = runif,
  rng_pars = list(min = -1, max = 1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>n_hidden</code></td>
<td>
<p>A vector of integers designating the number of neurons in each of the hidden layers (the length of the list is taken as the number of hidden layers).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_features</code></td>
<td>
<p>The number of randomly chosen features in the RWNN model. Note: This is meant for use in bag_rwnn, and it is not recommended outside of that function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lnorm</code></td>
<td>
<p>A string indicating the type of regularisation used when estimating the weights in the output layer, <code>"l1"</code> or <code>"l2"</code> (default).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bias_hidden</code></td>
<td>
<p>A vector of TRUE/FALSE values. The vector should have length 1, or be equal to the number of hidden layers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bias_output</code></td>
<td>
<p>TRUE/FALSE: Should a bias be added to the output layer?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>activation</code></td>
<td>
<p>A vector of strings corresponding to activation functions (see details). The vector should have length 1, or be equal to the number of hidden layers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>combine_input</code></td>
<td>
<p>TRUE/FALSE: Should the input be included to predict the output?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>combine_hidden</code></td>
<td>
<p>TRUE/FALSE: Should all hidden layers be combined to predict the output?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>include_data</code></td>
<td>
<p>TRUE/FALSE: Should the original data be included in the returned object? Note: this should almost always be set to '<code>TRUE</code>', but using '<code>FALSE</code>' is more memory efficient in ERWNN-object's.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>include_estimate</code></td>
<td>
<p>TRUE/FALSE: Should the <code>rwnn</code>-function estimate the output parameters? Note: this should almost always be set to '<code>TRUE</code>', but using '<code>FALSE</code>'is more memory efficient in ERWNN-object's.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rng</code></td>
<td>
<p>A string indicating the sampling distribution used for generating the weights of the hidden layer (defaults to <code>runif</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rng_pars</code></td>
<td>
<p>A list of parameters passed to the <code>rng</code> function (defaults to <code>list(min = -1, max = 1)</code>).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The possible activation functions supplied to '<code>activation</code>' are:
</p>

<dl>
<dt><code>"identity"</code></dt>
<dd>
<p style="text-align: center;"><code class="reqn">f(x) = x</code>
</p>
</dd>
<dt><code>"bentidentity"</code></dt>
<dd>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{\sqrt{x^2 + 1} - 1}{2} + x</code>
</p>
</dd>
<dt><code>"sigmoid"</code></dt>
<dd>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{1}{1 + \exp(-x)}</code>
</p>
</dd>
<dt><code>"tanh"</code></dt>
<dd>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{\exp(x) - \exp(-x)}{\exp(x) + \exp(-x)}</code>
</p>
</dd>
<dt><code>"relu"</code></dt>
<dd>
<p style="text-align: center;"><code class="reqn">f(x) = \max\{0, x\}</code>
</p>
</dd>
<dt>
<code>"silu"</code> (default)</dt>
<dd>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{x}{1 + \exp(-x)}</code>
</p>
</dd>
<dt><code>"softplus"</code></dt>
<dd>
<p style="text-align: center;"><code class="reqn">f(x) = \ln(1 + \exp(x))</code>
</p>
</dd>
<dt><code>"softsign"</code></dt>
<dd>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{x}{1 + |x|}</code>
</p>
</dd>
<dt><code>"sqnl"</code></dt>
<dd>
<p style="text-align: center;"><code class="reqn">f(x) = -1\text{, if }x &lt; -2\text{, }f(x) = x + \frac{x^2}{4}\text{, if }-2 \le x &lt; 0\text{, }f(x) = x - \frac{x^2}{4}\text{, if }0 \le x \le 2\text{, and } f(x) = 2\text{, if }x &gt; 2</code>
</p>
</dd>
<dt><code>"gaussian"</code></dt>
<dd>
<p style="text-align: center;"><code class="reqn">f(x) = \exp(-x^2)</code>
</p>
</dd>
<dt><code>"sqrbf"</code></dt>
<dd>
<p style="text-align: center;"><code class="reqn">f(x) = 1 - \frac{x^2}{2}\text{, if }|x| \le 1\text{, }f(x) = \frac{(2 - |x|)^2}{2}\text{, if }1 &lt; |x| &lt; 2\text{, and }f(x) = 0\text{, if }|x| \ge 2</code>
</p>
</dd>
</dl>
<p>The '<code>rng</code>' argument can also be set to <code>"orthogonal"</code>, <code>"torus"</code>, <code>"halton"</code>, or <code>"sobol"</code> for added stability. The <code>"torus"</code>, <code>"halton"</code>, and <code>"sobol"</code> methods relay on the torus, halton, and sobol functions. NB: this is not recommended when creating ensembles.
</p>


<h3>Value</h3>

<p>A list of control variables.
</p>


<h3>References</h3>

<p>Wang W., Liu X. (2017) "The selection of input weights of extreme learning machine: A sample structure preserving point of view." <em>Neurocomputing</em>, 261, 28-36.
</p>


</div>