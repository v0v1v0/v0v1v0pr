<div class="container">

<table style="width: 100%;"><tr>
<td>RMixtComp-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>RMixtComp</h2>

<h3>Description</h3>

<p>MixtComp (Mixture Composer, <a href="https://github.com/modal-inria/MixtComp">https://github.com/modal-inria/MixtComp</a>) is a model-based clustering package
for mixed data. It used mixture models (McLachlan and Peel, 2010) fitted using a SEM algorithm (Celeux et al., 1995) to cluster the data.
</p>
<p>It has been engineered around the idea of easy and quick integration of all new univariate models, under the conditional
independence assumption.
</p>
<p>Five basic models (Gaussian, Multinomial, Poisson, Weibull, NegativeBinomial) are implemented, as well as two
advanced models: Func_CS for functional data (Same et al., 2011) and Rank_ISR for ranking data (Jacques and Biernacki, 2014).
</p>
<p>MixtComp has the ability to natively manage missing data (completely or by interval).
</p>


<h3>Details</h3>

<p>Main functions are mixtCompLearn for clustering, mixtCompPredict for predicting the cluster of new samples
with a model learnt with mixtCompLearn.
createAlgo gives you default values for required parameters.
</p>
<p>Read the help page of mixtCompLearn for available models and data format. A summary of these information can be
accessed with the function availableModels.
</p>
<p>All utility functions (getters, graphical) are in the <code>RMixtCompUtilities-package</code> package.
</p>
<p>In order to have an overview of the output, you can use print.MixtCompLearn, summary.MixtCompLearn and
plot.MixtCompLearn functions,
</p>
<p>Getters are available to easily access some results (see. mixtCompLearn for output format): getBIC,
getICL, getCompletedData, getParam, getProportion, getTik, getEmpiricTik,
getPartition, getType, getModel, getVarNames.
</p>
<p>You can compute discriminative powers and similarities with functions: computeDiscrimPowerClass,
computeDiscrimPowerVar, computeSimilarityClass, computeSimilarityVar.
</p>
<p>Graphics functions are plot.MixtComp, plot.MixtCompLearn, heatmapClass, heatmapTikSorted,
heatmapVar, histMisclassif, plotConvergence, plotDataBoxplot, plotDataCI,
plotDiscrimClass, plotDiscrimVar, plotProportion, plotCrit.
</p>
<p>Datasets with running examples are provided: titanic, CanadianWeather, prostate, simData.
</p>
<p>Documentation about input and output format is available: <code>vignette("dataFormat")</code> and
<code>vignette("mixtCompObject")</code>.
</p>
<p>MixtComp examples: <code>vignette("MixtComp")</code> or online <a href="https://github.com/vandaele/mixtcomp-notebook">https://github.com/vandaele/mixtcomp-notebook</a>.
</p>
<p>Using ClusVis with RMixtComp: <code>vignette("dataFormat")</code>.
</p>


<h3>References</h3>

<p>C. Biernacki. MixtComp software: Model-based clustering/imputation with mixed data, missing data and uncertain data. MISSDATA 2015, Jun 2015, Rennes, France. hal-01253393
</p>
<p>G. McLachlan, D. Peel (2000). Finite Mixture Models. Wiley Series in Probability and Statistics, 1st edition. John Wiley &amp; Sons. doi:10.1002/0471721182.
</p>
<p>G. Celeux, D. Chauveau, J. Diebolt. On Stochastic Versions of the EM Algorithm. [Research Report] RR-2514, INRIA. 1995. inria-00074164
</p>
<p>A. Same, F. Chamroukhi, G. Govaert, P. Aknin. (2011). Model-based clustering and segmentation of time series with change in regime. Adv. Data Analysis and Classification. 5. 301-321. 10.1007/s11634-011-0096-5.
</p>
<p>J. Jacques, C. Biernacki. (2014). Model-based clustering for multivariate partial ranking data. Journal of Statistical Planning and Inference. 149. 10.1016/j.jspi.2014.02.011.
</p>


<h3>See Also</h3>

<p><code>mixtCompLearn</code> <code>availableModels</code> <code>RMixtCompUtilities-package</code>,
<code>RMixtCompIO-package</code>. Other clustering packages: <code>Rmixmod</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(simData)

# define the algorithm's parameters: you can use createAlgo function
algo &lt;- list(
    nbBurnInIter = 50,
    nbIter = 50,
    nbGibbsBurnInIter = 50,
    nbGibbsIter = 50,
    nInitPerClass = 20,
    nSemTry = 20,
    confidenceLevel = 0.95
)

# run RMixtComp for learning using only 3 variables
resLearn &lt;- mixtCompLearn(simData$dataLearn$matrix, simData$model$unsupervised[1:3], algo,
    nClass = 1:2, nRun = 2, nCore = 1
)

summary(resLearn)
plot(resLearn)

# run RMixtComp for predicting
resPred &lt;- mixtCompPredict(
    simData$dataPredict$matrix, simData$model$unsupervised[1:3], algo,
    resLearn, nCore = 1
)

partitionPred &lt;- getPartition(resPred)
print(resPred)

</code></pre>


</div>