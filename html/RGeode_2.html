<div class="container">

<table style="width: 100%;"><tr>
<td>randSVD</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Randomized Singular Value Decomposition.</h2>

<h3>Description</h3>

<p>Compute the near-optimal low-rank singular value decomposition (SVD) of
a rectangular matrix. The algorithm follows a randomized approach.
</p>


<h3>Usage</h3>

<pre><code class="language-R">randSVD(A, k = NULL, l = NULL, its = 2, sdist = "unif")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>A</code></td>
<td>
<p>array_like <br>
a real/complex input matrix (or data frame), with dimensions
<code class="reqn">(m, n)</code>. It is the real/complex matrix being approximated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>int, optional <br>
determines the target rank of the low-rank decomposition and should
satisfy <code class="reqn">k &lt;&lt; min(m,n)</code>. Set by default to 6.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>l</code></td>
<td>
<p>int, optional <br>
block size of the block Lanczos iterations; <code class="reqn">l</code> must be a
positive integer greater than <code class="reqn">k</code>, and defaults <code class="reqn">l=k+2</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>its</code></td>
<td>
<p>int, optional <br>
number of full iterations of a block Lanczos method to conduct;
<code class="reqn">its</code> must be a nonnegative integer, and defaults to 2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sdist</code></td>
<td>
<p>str <code class="reqn">c('normal', 'unif')</code>, optional <br>
Specifies the sampling distribution. <br><code class="reqn">'unif'</code> : (default) Uniform '[-1,1]'. <br><code class="reqn">'normal</code>' : Normal '~N(0,1)'. <br></p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Randomized SVD (randSVD) is a fast algorithm to compute the approximate low-rank SVD of
a rectangular <code class="reqn">(m,n)</code> matrix <code class="reqn">A</code> using a probabilistic algorithm.
Given the decided rank <code class="reqn">k &lt;&lt; n</code>, <code>rSVD</code> factors the input matrix <code class="reqn">A</code> as
<code class="reqn">A = U * diag(S) * V'</code>, which is the typical SVD form. Precisely, the columns of
U are orthonormal, as are the columns of V, the entries of S are all nonnegative,
and the only nonzero entries of S appear in non-increasing order on its diagonal. The
dimensions are:  U is <code class="reqn">(m,k)</code>, V is <code class="reqn">(n,k)</code>, and S is <code class="reqn">(k,k)</code>, when A
is <code class="reqn">(m,n)</code>.
</p>
<p>Increasing <code class="reqn">its</code> or <code class="reqn">l</code> improves the accuracy of the approximation USV' to A.
</p>
<p>The parameter <code class="reqn">its</code> specifies the number of normalized power iterations
(subspace iterations) to reduce the approximation error. This is recommended
if the the singular values decay slowly. In practice 1 or 2 iterations
achieve good results, however, computing power iterations increases the
computational time. The number of power iterations is set to <code class="reqn">its=2</code> by default.
</p>


<h3>Value</h3>

<p><code>randSVD</code> returns a list containing the following three components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>d</code></td>
<td>

<p>array_like <br><code class="reqn">(k,k)</code> matrix in the rank-k approximation USV' to A, where A is
<code class="reqn">(m,n)</code>; the entries of <code class="reqn">S</code> are all nonnegative, and its only
nonzero entries appear in nonincreasing order on the diagonal.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>u</code></td>
<td>

<p>matrix <br><code class="reqn">(m, k)</code> matrix in the rank-<code class="reqn">k</code> approximation <code class="reqn">A = U * diag(S) * V'</code>
to A; the columns of U are orthonormal and are called Left singular vect.
We want to remark that this is the transpose matrix, hence
the vectors are on the rows of our matrix.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>v</code></td>
<td>

<p>matrix <br><code class="reqn">(n, k)</code> matrix in the rank-<code class="reqn">k</code> approximation <code class="reqn">A = U * diag(S) * V'</code>
to A; the columns of V are orthonormal and are called Right singular vect.
</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>The singular vectors are not unique and only defined up to sign
(a constant of modulus one in the complex case). If a left singular vector
has its sign changed, changing the sign of the corresponding right vector
gives an equivalent decomposition.
</p>


<h3>Author(s)</h3>

<p>L. Rimella, <a href="mailto:lorenzo.rimella@hotmail.it">lorenzo.rimella@hotmail.it</a>
</p>


<h3>References</h3>


<ul>
<li>
<p>  [1] N. Halko, P. Martinsson, and J. Tropp.<br>
"Finding structure with randomness: probabilistic
algorithms for constructing approximate matrix
decompositions" (2009). <br>
(available at arXiv <a href="http://arxiv.org/abs/0909.4061">http://arxiv.org/abs/0909.4061</a>).
</p>
</li>
<li>
<p>  [2] S. Voronin and P.Martinsson.<br>
"RSVDPACK: Subroutines for computing partial singular value
decompositions via randomized sampling on single core, multi core,
and GPU architectures" (2015).<br>
(available at 'arXiv <a href="http://arxiv.org/abs/1502.05366">http://arxiv.org/abs/1502.05366</a>).
</p>
</li>
<li>
<p>   [3] N. Benjamin Erichson.<br>
"Randomized Singular Value Decomposition (rsvd): R package" (2016).<br>
(available in the CRAN).
</p>
</li>
<li>
<p>   [4] Nathan Halko, Per-Gunnar Martinsson, and Joel Tropp.<br>
"Finding structure with randomness: Stochastic algorithms for
constructing approximate matrix decompositions" (2009).<br>
(available at <a href="http://arxiv.org">http://arxiv.org</a>).
</p>
</li>
<li>
<p>   [5] V. Rokhlin, A. Szlam, M. Tygert.<br>
"A randomized algorithm for principal component analysis" (2009).<br>
(available at <a href="https://arxiv.org/abs/0809.2274">https://arxiv.org/abs/0809.2274</a>).<br>
The implementation of rand SVD is inspired by the MatLab implementation
of RandPCA by M. Tygert.
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">#Simulate a general matrix with 1000 rows and 1000 columns
vy= rnorm(1000*1000,0,1)
y= matrix(vy,1000,1000,byrow=TRUE)

#Compute the randSVD for the first hundred components of the matrix y and measure the time
start.time &lt;- Sys.time()
prova1= randSVD(y,k=100)
Sys.time()- start.time

#Compare with a classical SVD
start.time &lt;- Sys.time()
prova2= svd(y)
Sys.time()- start.time


</code></pre>


</div>