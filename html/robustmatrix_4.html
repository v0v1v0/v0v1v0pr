<div class="container">

<table style="width: 100%;"><tr>
<td>matrixShapley</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Outlier explanation based on Shapley values for matrix-variate data</h2>

<h3>Description</h3>

<p><code>matrixShapley</code> decomposes the squared matrix Mahalanobis distance (<code>mmd</code>) into additive outlyingness contributions of
the rows, columns, or cell of a matrix (Mayrhofer and Filzmoser 2023; double-blind 2024).
</p>


<h3>Usage</h3>

<pre><code class="language-R">matrixShapley(X, mu = NULL, cov_row, cov_col, inverted = FALSE, type = "cell")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>a 3d array of dimension <code class="reqn">(p,q,n)</code>, containing <code class="reqn">n</code> matrix-variate samples of <code class="reqn">p</code> rows and <code class="reqn">q</code> columns in each slice.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>a <code class="reqn">p \times q</code> matrix containing the means.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov_row</code></td>
<td>
<p>a <code class="reqn">p \times p</code> positive-definite symmetric matrix specifying the rowwise covariance matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov_col</code></td>
<td>
<p>a <code class="reqn">q \times q</code> positive-definite symmetric matrix specifying the columnwise covariance matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>inverted</code></td>
<td>
<p>Logical. FALSE by default.
If TRUE <code>cov_row</code> and <code>cov_col</code> are supposed to contain the inverted rowwise and columnwise covariance matrices, respectively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>Character. Either "row", "col", or "cell" (default) to compute rowwise, columnwise, or cellwise Shapley values.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Rowwise, columnwise, or cellwise Shapley value(s).
</p>


<h3>References</h3>

<p>Mayrhofer M, Filzmoser P (2023).
“Multivariate outlier explanations using Shapley values and Mahalanobis distances.”
<em>Econometrics and Statistics</em>.<br><br> double-blind (2024).
“Robust covariance estimation and explainable outlier detection for matrix-valued data.”
<em>[Manuscript submitted for publication]</em>.
</p>


<h3>See Also</h3>

<p><code>mmd</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">n = 1000; p = 2; q = 3
mu = matrix(rep(0, p*q), nrow = p, ncol = q)
cov_row = matrix(c(5,2,2,4), nrow = p, ncol = p)
cov_col = matrix(c(3,2,1,2,3,2,1,2,3), nrow = q, ncol = q)
X &lt;- rmatnorm(n = 1000, mu, cov_row, cov_col)
distances &lt;- mmd(X, mu, cov_row, cov_col)
</code></pre>


</div>