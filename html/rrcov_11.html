<div class="container">

<table style="width: 100%;"><tr>
<td>Cars</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Consumer reports car data: dimensions
</h2>

<h3>Description</h3>

<p>A data frame containing 11 variables with different dimensions of 111 cars
</p>


<h3>Usage</h3>

<pre><code class="language-R">data(Cars)</code></pre>


<h3>Format</h3>

<p>A data frame with 111 observations on the following 11 variables.
</p>

<dl>
<dt><code>length</code></dt>
<dd>
<p>a numeric vector</p>
</dd>
<dt><code>wheelbase</code></dt>
<dd>
<p>a numeric vector</p>
</dd>
<dt><code>width</code></dt>
<dd>
<p>a numeric vector</p>
</dd>
<dt><code>height</code></dt>
<dd>
<p>a numeric vector</p>
</dd>
<dt><code>front.hd</code></dt>
<dd>
<p>a numeric vector</p>
</dd>
<dt><code>rear.hd</code></dt>
<dd>
<p>a numeric vector</p>
</dd>
<dt><code>front.leg</code></dt>
<dd>
<p>a numeric vector</p>
</dd>
<dt><code>rear.seating</code></dt>
<dd>
<p>a numeric vector</p>
</dd>
<dt><code>front.shoulder</code></dt>
<dd>
<p>a numeric vector</p>
</dd>
<dt><code>rear.shoulder</code></dt>
<dd>
<p>a numeric vector</p>
</dd>
<dt><code>luggage</code></dt>
<dd>
<p>a numeric vector</p>
</dd>
</dl>
<h3>Source</h3>

<p>Consumer reports. (April 1990). http://backissues.com/issue/Consumer-Reports-April-1990, pp. 235–288.
</p>


<h3>References</h3>

<p>Chambers, J. M. and Hastie, T. J. (1992). Statistical models in S. Cole, Pacific Grove, CA:
Wadsworth and Brooks, pp. 46–47.
</p>
<p>M. Hubert, P. J. Rousseeuw, K. Vanden Branden (2005), ROBPCA: A new approach to robust 
principal components analysis, <em>Technometrics</em>, 
<b>47</b>, 64–79.    
</p>


<h3>Examples</h3>

<pre><code class="language-R">    data(Cars)

## Plot a pairwise scaterplot matrix
    pairs(Cars[,1:6])

    mcd &lt;- CovMcd(Cars[,1:6])    
    plot(mcd, which="pairs")
    
## Start with robust PCA
    pca &lt;- PcaHubert(Cars, k=ncol(Cars), kmax=ncol(Cars))
    pca

## Compare with the classical PCA
    prcomp(Cars)

## or  
    PcaClassic(Cars, k=ncol(Cars), kmax=ncol(Cars))
    
## If you want to print the scores too, use
    print(pca, print.x=TRUE)

## Using the formula interface
    PcaHubert(~., data=Cars, k=ncol(Cars), kmax=ncol(Cars))

## To plot the results:

    plot(pca)                    # distance plot
    pca2 &lt;- PcaHubert(Cars, k=4)  
    plot(pca2)                   # PCA diagnostic plot (or outlier map)
    
## Use the standard plots available for prcomp and princomp
    screeplot(pca)    # it is interesting with all variables    
    biplot(pca)       # for biplot we need more than one PCs
    
## Restore the covraiance matrix     
    py &lt;- PcaHubert(Cars, k=ncol(Cars), kmax=ncol(Cars))
    cov.1 &lt;- py@loadings %*% diag(py@eigenvalues) %*% t(py@loadings)
    cov.1      

</code></pre>


</div>