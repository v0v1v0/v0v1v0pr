<div class="container">

<table style="width: 100%;"><tr>
<td>titles_scrap</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Website title scraping</h2>

<h3>Description</h3>

<p>This function is used to scrape titles (h1, h2 &amp; h3 html tags) from a website. Useful for scraping daily electronic newspapers' titles.
</p>


<h3>Usage</h3>

<pre><code class="language-R">titles_scrap(link, contain = NULL, case_sensitive = FALSE, askRobot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>link</code></td>
<td>
<p>the link of the web page to scrape</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>contain</code></td>
<td>
<p>filter the titles according to a character string provided.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>case_sensitive</code></td>
<td>
<p>logical. Should the contain argument be case sensitive ? defaults to FALSE</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>askRobot</code></td>
<td>
<p>logical. Should the function ask the robots.txt if we're allowed or not to scrape the web page ? Default is FALSE</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a character vector
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# Extracting the current titles of the New York Times

link     &lt;- "https://www.nytimes.com/"

titles_scrap(link)

</code></pre>


</div>