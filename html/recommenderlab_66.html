<div class="container">

<table style="width: 100%;"><tr>
<td>evaluationScheme</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Creator Function for evaluationScheme</h2>

<h3>Description</h3>

<p>Creates an evaluationScheme object from a data set. The scheme can be a
simple split into training and test data, k-fold cross-evaluation or using k
independent bootstrap samples.
</p>


<h3>Usage</h3>

<pre><code class="language-R">evaluationScheme(data, ...)

## S4 method for signature 'ratingMatrix'
evaluationScheme(data, method="split",
    train=0.9, k=NULL, given, goodRating = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>data set as a ratingMatrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>a character string defining the evaluation
method to use (see details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>train</code></td>
<td>
<p>fraction of the data set used for training.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>number of folds/times to run the evaluation (defaults to 10
for cross-validation and bootstrap and 1 for split).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>given</code></td>
<td>
<p>single number of items given for evaluation or
a vector of length of data giving the number of items given for each
observation. Negative values implement all-but schemes. For example,
<code>given = -1</code> means all-but-1 evaluation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>goodRating</code></td>
<td>
<p>numeric; threshold at which ratings are considered
good for evaluation. E.g., with <code>goodRating=3</code> all items
with actual user rating of greater or equal 3 are
considered positives in the evaluation process.
Note that this argument is only used if
the ratingMatrix is
a of subclass realRatingMatrix!</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>further arguments. </p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>evaluationScheme</code> creates an evaluation scheme (training and test data)
with <code>k</code> runs and one of the following methods:
</p>
<p><code>"split"</code> randomly assigns
the proportion of objects specified by <code>train</code> to the training set and
the rest is used for the test set.
</p>
<p><code>"cross-validation"</code> creates a k-fold cross-validation scheme. The data
is randomly split into k parts and in each run k-1 parts are used for
training and the remaining part is used for testing. After all k runs each
part was used as the test set exactly once.
</p>
<p><code>"bootstrap"</code> creates the training set by taking a bootstrap sample
(sampling with replacement) of size <code>train</code> times number of users in
the data set.
All objects not in the training set are used for testing.
</p>
<p>For evaluation, Breese et al. (1998) introduced the
four experimental protocols called Given 2, Given 5, Given 10 and All-but-1.
During testing, the Given x protocol presents the algorithm with
only x randomly chosen items for the test user, and the algorithm
is evaluated by how well it is able to predict the withheld items.
For All-but-x,
the algorithm sees all but
x withheld ratings for the test user.
<code>given</code> controls x in the evaluations scheme.
Positive integers result in a Given x protocol, while negative values
produce a All-but-x protocol.
</p>
<p>If a user does not have enough ratings to satisfy <code>given</code>, then the user is dropped from the
evaluation with a warning.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>"evaluationScheme"</code>.
</p>


<h3>References</h3>

<p>Kohavi, Ron (1995). "A study of cross-validation and bootstrap for accuracy
estimation and model selection". Proceedings of  the Fourteenth International
Joint Conference on Artificial Intelligence, pp. 1137-1143.
</p>
<p>Breese JS, Heckerman D, Kadie C (1998). "Empirical Analysis of Predictive
Algorithms for Collaborative Filtering." In Uncertainty in Artificial
Intelligence. Proceedings of the Fourteenth Conference, pp. 43-52.
</p>


<h3>See Also</h3>

<p><code>getData</code>,
<code>evaluationScheme</code>,
<code>ratingMatrix</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">data("MSWeb")

MSWeb10 &lt;- sample(MSWeb[rowCounts(MSWeb) &gt;10,], 50)
MSWeb10

## simple split with 3 items given
esSplit &lt;- evaluationScheme(MSWeb10, method="split",
        train = 0.9, k=1, given=3)
esSplit

## 4-fold cross-validation with all-but-1 items for learning.
esCross &lt;- evaluationScheme(MSWeb10, method="cross-validation",
        k=4, given=-1)
esCross
</code></pre>


</div>