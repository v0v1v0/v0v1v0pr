<div class="container">

<table style="width: 100%;"><tr>
<td>fmaxlo</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
ML estimation of a 'maxlo' distribution
</h2>

<h3>Description</h3>

<p>Fast Maximum Likelihood estimation of a 'maxlo' distribution.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fmaxlo(x,
       shapeMin = 1.25,
       info.observed = TRUE,
       plot = FALSE,
       scaleData = TRUE,
       cov = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>Sample vector to be fitted. Should contain only positive non-NA
values.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>shapeMin</code></td>
<td>

<p>Lower bound on the shape parameter. This must be <code>&gt;= 1.0</code>
since otherwise the ML estimate is obtained with the <code>scale</code>
parameter equal to <code>max(x)</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>info.observed</code></td>
<td>

<p>Should the observed information matrix be used or the expected one
be used?
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot</code></td>
<td>

<p>Logical. If <code>TRUE</code>, a plot will be produced showing the
derivative of the concentrated log-likelihood, function of the shape
parameter. The derivative function shown is that of the log-likelihood for
the unconstrained maximisation; it is not used in the estimation.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleData</code></td>
<td>

<p>Logical. If <code>TRUE</code> observations in <code>x</code> (which are
positive) are divided by their mean value.  The results are in
theory not affected by this transformation, but scaling the data
could improve the estimation in some cases.  The log-likelihood
plots are shown using the scaled values so the returned estimate of
the scale parameter is not the the abscissa of the maximum shown on
the plot.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov</code></td>
<td>

<p>Logical. If <code>FALSE</code>, a minimal estimation is performed with
no covariance matrix or derivative returned. This can be useful
when a large number of ML estimations are required, e.g. to sample
from a likelihood ratio.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The 'maxlo' likelihood is concentrated with respect to the shape
parameter, thus the function to be maximised has only one one scalar
argument: the scale parameter <code class="reqn">\beta</code>. For large scale
<code class="reqn">\beta</code>, the derivative of the concentrated log-likelihood tends
to zero, and its sign is that of <code class="reqn">(\textrm{CV}^2-1)</code>
where <code class="reqn">\textrm{CV}</code> is the coefficient of variation, computed
using <code class="reqn">n</code> as denominator in the formula for the standard
deviation.
</p>
<p>The ML estimate does not exist when the sample has a coefficient of
variation <code>CV</code> greater than <code>1.0</code> and it may fail to be
found when <code>CV</code> is smaller than yet close to <code>1.0</code>.
</p>
<p>The expected information matrix can be obtained by noticing that when
the r.v. <code class="reqn">Y</code> follows the 'maxlo' distribution with shape
<code class="reqn">\alpha</code> and scale <code class="reqn">\beta</code> the r.v <code class="reqn">V:= 1/(1-Y/\beta)</code>
follows a Pareto distribution with minimum 1 and and shape parameter
<code class="reqn">\alpha</code>. The information matrix involves the second order
moment of <code class="reqn">V</code>.
</p>
<p>The default value of <code>info.observed</code> was set to <code>TRUE</code> from
version <code>3.0-1</code> because standard deviations obtained with this
choice are usually better.
</p>


<h3>Value</h3>

<p>A list with the following elements
</p>
<table>
<tr style="vertical-align: top;">
<td><code>estimate</code></td>
<td>

<p>Parameter ML estimates.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sd</code></td>
<td>

<p>Vector of (asymptotic) standard deviations for the estimates.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loglik</code></td>
<td>

<p>The maximised log-likelihood.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dloglik</code></td>
<td>

<p>Gradient of the log-likelihood at the optimum. Its two elements
should normally be close to zero.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov</code></td>
<td>

<p>The (asymptotic) covariance matrix computed from theoretical or
observed information matrix.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>info</code></td>
<td>

<p>The information matrix.
</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>The name of the distribution hence also that of the fitting function
are still experimental and might be changed.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code>Maxlo</code> for the description of the distribution.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## generate sample
set.seed(1234)
n &lt;- 200
alpha &lt;- 2 + rexp(1)
beta &lt;- 1 + rexp(1)
x &lt;- rmaxlo(n, scale = beta, shape = alpha)
res &lt;- fmaxlo(x, plot = TRUE)

## compare with a GPD with shape 'xi' and scale 'sigma'
xi &lt;- -1 / alpha; sigma &lt;- -beta * xi
res.evd &lt;- evd::fpot(x, threshold = 0, model = "gpd")
xi.evd &lt;- res.evd$estimate["shape"]
sigma.evd &lt;- res.evd$estimate["scale"]
beta.evd &lt;- -sigma.evd / xi.evd 
alpha.evd &lt;- -1 / xi.evd
cbind(Renext = res$estimate, evd = c(alpha = alpha.evd, beta = beta.evd))
  

</code></pre>


</div>