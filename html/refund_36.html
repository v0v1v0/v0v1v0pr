<div class="container">

<table style="width: 100%;"><tr>
<td>fpca2s</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Functional principal component analysis by a two-stage method</h2>

<h3>Description</h3>

<p>This function performs functional PCA by performing an ordinary singular
value decomposition on the functional data matrix, then smoothing the right
singular vectors by smoothing splines.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fpca2s(
  Y = NULL,
  ydata = NULL,
  argvals = NULL,
  npc = NA,
  center = TRUE,
  smooth = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>data matrix (rows: observations; columns: grid of eval. points)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ydata</code></td>
<td>
<p>a data frame <code>ydata</code> representing
irregularly observed functions. NOT IMPLEMENTED for this method.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>argvals</code></td>
<td>
<p>the argument values of the function evaluations in <code>Y</code>,
defaults to a equidistant grid from 0 to 1. See Details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>npc</code></td>
<td>
<p>how many smooth SVs to try to extract, if <code>NA</code> (the default)
the hard thresholding rule of Donoho, Gavish (2013) is used (see Details,
References).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center</code></td>
<td>
<p>center <code>Y</code> so that its column-means are 0? Defaults to
<code>TRUE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>smooth</code></td>
<td>
<p>logical; defaults to TRUE, if NULL, no smoothing of
eigenvectors.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Note that <code>fpca2s</code> computes smoothed orthonormal eigenvectors
of the supplied function evaluations (and associated scores), not (!)
evaluations of the smoothed orthonormal eigenfunctions. The smoothed
orthonormal eigenvectors are then rescaled by the length of the domain
defined by <code>argvals</code> to have a quadratic integral approximately equal
to one (instead of crossproduct equal to one), so they approximate the behavior
of smooth eigenfunctions. If <code>argvals</code> is not equidistant,
<code>fpca2s</code> will simply return the smoothed eigenvectors without rescaling,
with a warning.
</p>


<h3>Value</h3>

<p>an <code>fpca</code> object like that returned from <code>fpca.sc</code>,
with entries <code>Yhat</code>, the smoothed trajectories, <code>Y</code>, the observed
data, <code>scores</code>, the estimated FPC loadings, <code>mu</code>, the column means
of <code>Y</code> (or a vector of zeroes if <code>!center</code>),  <code>efunctions</code>,
the estimated smooth FPCs (note that these are orthonormal vectors, not
evaluations of orthonormal functions if <code>argvals</code> is not equidistant),
<code>evalues</code>, their associated eigenvalues, and <code>npc</code>, the number of
smooth components that were extracted.
</p>


<h3>Author(s)</h3>

<p>Luo Xiao <a href="mailto:lxiao@jhsph.edu">lxiao@jhsph.edu</a>, Fabian Scheipl
</p>


<h3>References</h3>

<p>Xiao, L., Ruppert, D., Zipunnikov, V., and Crainiceanu, C., (2013), Fast
covariance estimation for high-dimensional functional data. (submitted)
<a href="https://arxiv.org/abs/1306.5718">https://arxiv.org/abs/1306.5718</a>.
</p>
<p>Gavish, M., and Donoho, D. L.  (2014). The optimal hard threshold for
singular values is 4/sqrt(3).  <em>IEEE Transactions on Information Theory</em>, 60(8), 5040â€“5053.
</p>


<h3>See Also</h3>

<p><code>fpca.sc</code> and <code>fpca.face</code> for FPCA based
on smoothing a covariance estimate; <code>fpca.ssvd</code> for another
SVD-based approach.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
  #### settings
  I &lt;- 50 # number of subjects
  J &lt;- 3000 # dimension of the data
  t &lt;- (1:J)/J # a regular grid on [0,1]
  N &lt;- 4 #number of eigenfunctions
  sigma &lt;- 2 ##standard deviation of random noises
  lambdaTrue &lt;- c(1,0.5,0.5^2,0.5^3) # True eigenvalues

  case = 1
  ### True Eigenfunctions

  if(case==1) phi &lt;- sqrt(2)*cbind(sin(2*pi*t),cos(2*pi*t),
                                   sin(4*pi*t),cos(4*pi*t))
  if(case==2) phi &lt;- cbind(rep(1,J),sqrt(3)*(2*t-1),
                           sqrt(5)*(6*t^2-6*t+1),
                           sqrt(7)*(20*t^3-30*t^2+12*t-1))

  ###################################################
  ########     Generate Data            #############
  ###################################################
  xi &lt;- matrix(rnorm(I*N),I,N);
  xi &lt;- xi%*%diag(sqrt(lambdaTrue))
  X &lt;- xi%*%t(phi); # of size I by J
  Y &lt;- X + sigma*matrix(rnorm(I*J),I,J)

  results &lt;- fpca2s(Y,npc=4,argvals=t)
  ###################################################
  ####               SVDS               ########
  ###################################################
  Phi &lt;- results$efunctions
  eigenvalues &lt;- results$evalues

  for(k in 1:N){
    if(Phi[,k]%*%phi[,k]&lt; 0)
      Phi[,k] &lt;- - Phi[,k]
  }

 ### plot eigenfunctions
 par(mfrow=c(N/2,2))
 seq &lt;- (1:(J/10))*10
 for(k in 1:N){
      plot(t[seq],Phi[seq,k]*sqrt(J),type='l',lwd = 3,
           ylim = c(-2,2),col = 'red',
           ylab = paste('Eigenfunction ',k,sep=''),
           xlab='t',main='SVDS')

      lines(t[seq],phi[seq,k],lwd = 2, col = 'black')
      }
</code></pre>


</div>