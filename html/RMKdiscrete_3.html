<div class="container">

<table style="width: 100%;"><tr>
<td>biLGP</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>The bivariate Lagrangian Poisson (LGP) distribution</h2>

<h3>Description</h3>

<p>Density, random-number generation, and moments of the log-transformed distribution.
</p>


<h3>Usage</h3>

<pre><code class="language-R">dbiLGP(y, theta, lambda, nc=NULL, log=FALSE, add.carefully=FALSE)
biLGP.logMV(theta,lambda,nc=NULL,const.add=1,tol=1e-14,add.carefully=FALSE)
rbiLGP(n, theta, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Numeric vector or two-column matrix of bivariate data.  If matrix, each row corresponds to an observation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta</code></td>
<td>
<p>Numeric vector or three-column matrix of non-negative values for index parameters <code class="reqn">\theta _0</code>, <code class="reqn">\theta _1</code>, and <code class="reqn">\theta _2</code>, in that order.  If matrix, is read by row.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>Numeric vector or three-column matrix of values for multiplicative parameters <code class="reqn">\lambda _0</code>, <code class="reqn">\lambda _1</code>, and <code class="reqn">\lambda _2</code>, in that order.  If matrix, is read by row.  Values must be on the interval [-1,1].</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nc</code></td>
<td>
<p>Numeric vector or three-column matrix of (reciprocals of) the normalizing constants.  These constants differ from 1 only if the corresponding <code>lambda</code> parameter is negative; see <code>dLGP()</code> for details. If matrix, is read by row. Defaults to <code>NULL</code>, in which case the normalizing constants are computed automatically.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>log</code></td>
<td>
<p>Logical; should the natural log of the probability be returned?  Defaults to <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>add.carefully</code></td>
<td>
<p>Logical.  If <code>TRUE</code>, the program takes extra steps to try to prevent round-off error during the addition of probabilities.  Defaults to <code>FALSE</code>, which is recommended, since using <code>TRUE</code> is slower and rarely makes a noticeable difference in practice.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>const.add</code></td>
<td>
<p>Numeric vector of positive constants to add to the non-negative integers before taking their natural logarithm.  Defaults to 1, for the typical <code class="reqn">\log (y+1)</code> transformation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>Numeric; must be positive.  When <code>biLGP.logMV()</code> is calculating the second moment of the log-transformed distribution, it stops when the next term in the series is smaller than <code>tol</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>Integer; number of observations to be randomly generated.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The bivariate LGP is constructed from three independent latent random variables, <code class="reqn">X_0</code>, <code class="reqn">X_1</code>, and <code class="reqn">X_2</code>, where
</p>
<p style="text-align: center;"><code class="reqn">X_0 \sim LGP(\theta _0, \lambda _0)</code>
</p>

<p style="text-align: center;"><code class="reqn">X_1 \sim LGP(\theta _1, \lambda _1)</code>
</p>

<p style="text-align: center;"><code class="reqn">X_2 \sim LGP(\theta _2, \lambda _2)</code>
</p>

<p>The observable variables, <code class="reqn">Y_1</code> and <code class="reqn">Y_2</code>, are defined as <code class="reqn">Y_1 = X_0 + X_1</code> and <code class="reqn">Y_2 = X_0 + X_2</code>, and thus the dependence between <code class="reqn">Y_1</code> and <code class="reqn">Y_2</code> arises because of the common term <code class="reqn">X_0</code>.  The joint PMF of <code class="reqn">Y_1</code> and <code class="reqn">Y_2</code> is derived from the joint PMF of the three independent latent variables, with <code class="reqn">X_1</code> and <code class="reqn">X_2</code> re-expressed as <code class="reqn">Y_1 - X_0</code> and <code class="reqn">Y_2 - X_0</code>, and after <code class="reqn">X_0</code> is marginalized out.
</p>
<p>Function <code>dbiLGP()</code> is the bivariate LGP density (PMF).  Function <code>rbiLGP()</code> generates random draws from the bivariate LGP distribution, via calls to <code>rLGP()</code>.  Function <code>biLGP.logMV()</code> numerically computes the means, variances, and covariance of a bivariate LGP distribution, after it has been log transformed following addition of a positive constant.
</p>
<p>Vectors of numeric arguments other than <code>tol</code> are cycled, whereas only the first element of logical and integer arguments is used.
</p>


<h3>Value</h3>

<p><code>dbiLGP()</code> returns a numeric vector of probabilities.  <code>rbiLGP()</code> returns a matrix of random draws, which is of type 'numeric' (rather than 'integer', even though the bivariate LGP only has support on the non-negative integers).  <code>biLGP.logMV()</code> returns a numeric matrix with the following five named columns:
</p>

<ol>
<li> <p><code>EY1</code>: Post-tranformation expectation of <code class="reqn">Y_1</code>.
</p>
</li>
<li> <p><code>EY2</code>: Post-tranformation expectation of <code class="reqn">Y_2</code>.
</p>
</li>
<li> <p><code>VY1</code>: Post-tranformation variance of <code class="reqn">Y_1</code>.
</p>
</li>
<li> <p><code>VY2</code>: Post-tranformation variance of <code class="reqn">Y_2</code>.
</p>
</li>
<li> <p><code>COV</code>: Post-tranformation covariance of <code class="reqn">Y_1</code> and <code class="reqn">Y_2</code>.
</p>
</li>
</ol>
<h3>Author(s)</h3>

<p>Robert M. Kirkpatrick <a href="mailto:rkirkpatrick2@vcu.edu">rkirkpatrick2@vcu.edu</a>
</p>


<h3>References</h3>

<p>Famoye, F., &amp; Consul, P. C.  (1995).  Bivariate generalized Poisson distribution with some applications.  <em>Metrika</em>, 42, 127-138.
</p>
<p>Consul, P. C., &amp; Famoye, F.  (2006).  <em>Lagrangian Probability Distributions</em>.  Boston: Birkhauser.
</p>


<h3>See Also</h3>

<p><code>LGP</code>, <code>dpois()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## The following two lines do the same thing:
dbiLGP(y=1,theta=1,lambda=0.1)
dbiLGP(y=c(1,1),theta=c(1,1,1),lambda=c(0.1,0.1,0.1))

dbiLGP(y=c(1,1,2,2,3,5),theta=c(1,1,1,2,2,2),lambda=0.1)
## Due to argument cycling, the above line is doing the following three steps:
dbiLGP(y=c(1,1),theta=c(1,1,1),lambda=c(0.1,0.1,0.1))
dbiLGP(y=c(2,2),theta=c(2,2,2),lambda=c(0.1,0.1,0.1))
dbiLGP(y=c(3,5),theta=c(1,1,1),lambda=c(0.1,0.1,0.1))

## Inputs to dbiLGP() can be matrices, too:
dbiLGP(y=matrix(c(1,1,2,2,3,5),ncol=2,byrow=TRUE),
  theta=matrix(c(1,1,1,2,2,2,1,1,1),ncol=3,byrow=TRUE),
  lambda=0.1)

## theta0 = 0 implies independence:
a &lt;- dbiLGP(y=c(1,3),theta=c(0,1,2),lambda=c(0.1,-0.1,0.5))
b &lt;- dLGP(x=1,theta=1,lambda=-0.1) * dLGP(x=3,theta=2,lambda=0.5)
a-b #&lt;--near zero.
## lambdas of zero yield the ordinary Poisson:
a &lt;- dbiLGP(y=c(1,3), theta=c(0,1,2),lambda=0)
b &lt;- dpois(x=1,lambda=1) * dpois(x=3,lambda=2) #&lt;--LGP theta is pois lambda
a-b #&lt;--near zero

( y &lt;- rbiLGP(10,theta=c(1.1,0.87,5.5),lambda=c(0.87,0.89,0.90)) )
dbiLGP(y=y,theta=c(1.1,0.87,5.5),lambda=c(0.87,0.89,0.90))

biLGP.logMV(theta=c(0.65,0.35,0.35),lambda=0.7,tol=1e-8)
</code></pre>


</div>