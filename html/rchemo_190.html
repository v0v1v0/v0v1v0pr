<div class="container">

<table style="width: 100%;"><tr>
<td>kpca</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>KPCA</h2>

<h3>Description</h3>

<p>Kernel PCA (Scholkopf et al. 1997, Scholkopf &amp; Smola 2002, Tipping 2001) by SVD factorization of the weighted Gram matrix <code class="reqn">D^(1/2) * Phi(X) * Phi(X)' * D^(1/2)</code>. <code class="reqn">D</code> is a (<code class="reqn">n, n</code>) diagonal matrix of weights for the observations (rows of <code class="reqn">X</code>).
</p>


<h3>Usage</h3>

<pre><code class="language-R">
kpca(X, weights = NULL, nlv, kern = "krbf", ...)

## S3 method for class 'Kpca'
transform(object, X, ..., nlv = NULL)  

## S3 method for class 'Kpca'
summary(object, ...)  

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>For the main function: Training X-data (<code class="reqn">n, p</code>). — For the auxiliary functions: New X-data (<code class="reqn">m, p</code>) to consider.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>Weights (<code class="reqn">n, 1</code>) to apply to the training observations. Internally, weights are "normalized" to sum to 1. Default to <code>NULL</code> (weights are set to <code class="reqn">1 / n</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlv</code></td>
<td>
<p>The number of PCs to calculate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kern</code></td>
<td>
<p>Name of the function defining the considered kernel for building the Gram matrix. See <code>krbf</code> for syntax, and other available kernel functions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Optional arguments to pass in the kernel function defined in <code>kern</code> (e.g. <code>gamma</code> for <code>krbf</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>— For the auxiliary functions: A fitted model, output of a call to the main functions.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>For <code>kpca</code>:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Training X-data (<code class="reqn">n, p</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Kt</code></td>
<td>
<p>Gram matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>T</code></td>
<td>
<p>X-scores matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>P</code></td>
<td>
<p>X-loadings matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sv</code></td>
<td>
<p>vector of singular values</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eig</code></td>
<td>
<p>vector of eigenvalues.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>vector of observation weights.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kern</code></td>
<td>
<p>kern function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dots</code></td>
<td>
<p>Optional arguments.</p>
</td>
</tr>
</table>
<p>For <code>transform.Kpca</code>: X-scores matrix for new X-data.
</p>
<p>For <code>summary.Kpca</code>: 
</p>
<table><tr style="vertical-align: top;">
<td><code>explvar</code></td>
<td>
<p>explained variance matrix.</p>
</td>
</tr></table>
<h3>References</h3>

<p>Scholkopf, B., Smola, A., Muller, K.-R., 1997. Kernel principal component analysis, in: Gerstner, W., Germond, A., Hasler, M., Nicoud, J.-D. (Eds.), Artificial Neural Networks - ICANN 97, Lecture Notes in Computer Science. Springer, Berlin, Heidelberg, pp. 583-588. https://doi.org/10.1007/BFb0020217
</p>
<p>Scholkopf, B., Smola, A.J., 2002. Learning with kernels: support vector machines, regularization, optimization, and beyond, Adaptive computation and machine learning. MIT Press, Cambridge, Mass.
</p>
<p>Tipping, M.E., 2001. Sparse kernel principal component analysis. Advances in neural information processing systems, MIT Press. http://papers.nips.cc/paper/1791-sparse-kernel-principal-component-analysis.pdf
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## EXAMPLE 1

n &lt;- 5 ; p &lt;- 4
X &lt;- matrix(rnorm(n * p), ncol = p)

nlv &lt;- 3
kpca(X, nlv = nlv, kern = "krbf")

fm &lt;- kpca(X, nlv = nlv, kern = "krbf", gamma = .6)
fm$T
transform(fm, X[1:2, ])
transform(fm, X[1:2, ], nlv = 1)
summary(fm)

## EXAMPLE 2

n &lt;- 5 ; p &lt;- 4
X &lt;- matrix(rnorm(n * p), ncol = p)
nlv &lt;- 3
pcasvd(X, nlv = nlv)$T
kpca(X, nlv = nlv, kern = "kpol")$T

</code></pre>


</div>