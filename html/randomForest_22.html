<div class="container">

<table style="width: 100%;"><tr>
<td>partialPlot</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Partial dependence plot</h2>

<h3>Description</h3>

<p>Partial dependence plot gives a graphical depiction of the marginal
effect of a variable on the class probability (classification) or
response (regression).
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'randomForest'
partialPlot(x, pred.data, x.var, which.class,
      w, plot = TRUE, add = FALSE,
      n.pt = min(length(unique(pred.data[, xname])), 51),
      rug = TRUE, xlab=deparse(substitute(x.var)), ylab="",
      main=paste("Partial Dependence on", deparse(substitute(x.var))),
      ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>an object of class <code>randomForest</code>, which contains a
<code>forest</code> component.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred.data</code></td>
<td>
<p>a data frame used for contructing the plot, usually
the training data used to contruct the random forest.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x.var</code></td>
<td>
<p>name of the variable for which partial
dependence is to be examined.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>which.class</code></td>
<td>
<p>For classification data, the class to focus on
(default the first class).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w</code></td>
<td>
<p>weights to be used in averaging; if not supplied, mean is not
weighted</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot</code></td>
<td>
<p>whether the plot should be shown on the graphic device.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>add</code></td>
<td>
<p>whether to add to existing plot (<code>TRUE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.pt</code></td>
<td>
<p>if <code>x.var</code> is continuous, the number of points on the
grid for evaluating partial dependence.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rug</code></td>
<td>
<p>whether to draw hash marks at the bottom of the plot
indicating the deciles of <code>x.var</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xlab</code></td>
<td>
<p>label for the x-axis.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ylab</code></td>
<td>
<p>label for the y-axis.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>main</code></td>
<td>
<p>main title for the plot.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>other graphical parameters to be passed on to <code>plot</code>
or <code>lines</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function being plotted is defined as:
</p>
<p style="text-align: center;"><code class="reqn">
    \tilde{f}(x) = \frac{1}{n} \sum_{i=1}^n f(x, x_{iC}),
  </code>
</p>

<p>where <code class="reqn">x</code> is the variable for which partial dependence is sought,
and <code class="reqn">x_{iC}</code> is the other variables in the data.  The summand is
the predicted regression function for regression, and logits
(i.e., log of fraction of votes) for <code>which.class</code> for
classification:
</p>
<p style="text-align: center;"><code class="reqn"> f(x) = \log p_k(x) - \frac{1}{K} \sum_{j=1}^K \log p_j(x),</code>
</p>

<p>where <code class="reqn">K</code> is the number of classes, <code class="reqn">k</code> is <code>which.class</code>,
and <code class="reqn">p_j</code> is the proportion of votes for class <code class="reqn">j</code>.
</p>


<h3>Value</h3>

<p>A list with two components: <code>x</code> and <code>y</code>, which are the values
used in the plot.
</p>


<h3>Note</h3>

<p>The <code>randomForest</code> object must contain the <code>forest</code>
component; i.e., created with <code>randomForest(...,
    keep.forest=TRUE)</code>.
</p>
<p>This function runs quite slow for large data sets.
</p>


<h3>Author(s)</h3>

<p>Andy Liaw <a href="mailto:andy_liaw@merck.com">andy_liaw@merck.com</a></p>


<h3>References</h3>

<p>Friedman, J. (2001). Greedy function approximation: the gradient
boosting machine, <em>Ann. of Stat.</em></p>


<h3>See Also</h3>

<p><code>randomForest</code></p>


<h3>Examples</h3>

<pre><code class="language-R">data(iris)
set.seed(543)
iris.rf &lt;- randomForest(Species~., iris)
partialPlot(iris.rf, iris, Petal.Width, "versicolor")

## Looping over variables ranked by importance:
data(airquality)
airquality &lt;- na.omit(airquality)
set.seed(131)
ozone.rf &lt;- randomForest(Ozone ~ ., airquality, importance=TRUE)
imp &lt;- importance(ozone.rf)
impvar &lt;- rownames(imp)[order(imp[, 1], decreasing=TRUE)]
op &lt;- par(mfrow=c(2, 3))
for (i in seq_along(impvar)) {
    partialPlot(ozone.rf, airquality, impvar[i], xlab=impvar[i],
                main=paste("Partial Dependence on", impvar[i]),
                ylim=c(30, 70))
}
par(op)
</code></pre>


</div>