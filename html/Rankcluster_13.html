<div class="container">

<table style="width: 100%;"><tr>
<td>kullback</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Kullback-Leibler divergence</h2>

<h3>Description</h3>

<p>It computes the Kullback-Leibler divergence between two mixtures of multidimensional ISR distributions.
</p>


<h3>Usage</h3>

<pre><code class="language-R">kullback(proportion1, pi1, mu1, proportion2, pi2, mu2, m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>proportion1, proportion2</code></td>
<td>
<p>vectors (which sums to 1) containing the K mixture proportions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pi1, pi2</code></td>
<td>
<p>matrices of size K*p, where K is the number of clusters and p the number of dimension,
containing the probabilities of a good comparison of the model (dispersion parameters).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu1, mu2</code></td>
<td>
<p>matrices of size K*sum(m), containing the modal ranks. Each row contains the modal rank for a cluster.
In the case of multivariate ranks, the reference rank for each dimension are set successively on the same row.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m</code></td>
<td>
<p>a vector containing the size of ranks for each dimension.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>the Kullback-Leibler divergence.
</p>


<h3>Author(s)</h3>

<p>Quentin Grimonprez
</p>


<h3>References</h3>

<p>http://en.wikipedia.org/wiki/Kullback
</p>


<h3>Examples</h3>

<pre><code class="language-R">proportion1 &lt;- c(0.4, 0.6)
pi1 &lt;- matrix(c(0.8, 0.75), nrow = 2)
mu1 &lt;- matrix(c(1, 2, 3, 4, 4, 2, 1, 3), nrow = 2, byrow = TRUE)

proportion2 &lt;- c(0.43, 0.57)
pi2 &lt;- matrix(c(0.82, 0.7), nrow = 2)
mu2 &lt;- matrix(c(1, 2, 3, 4, 4, 2, 1, 3), nrow = 2, byrow = TRUE)

dK &lt;- kullback(proportion1, pi1, mu1, proportion2, pi2, mu2, 4)

</code></pre>


</div>