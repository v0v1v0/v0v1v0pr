<div class="container">

<table style="width: 100%;"><tr>
<td>comp_acc</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compute overall accuracy (acc) from probabilities.</h2>

<h3>Description</h3>

<p><code>comp_acc</code> computes overall accuracy <code>acc</code>
from 3 essential probabilities
<code>prev</code>, <code>sens</code>, and <code>spec</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">comp_acc(prev, sens, spec)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>prev</code></td>
<td>
<p>The condition's prevalence <code>prev</code>
(i.e., the probability of condition being <code>TRUE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sens</code></td>
<td>
<p>The decision's sensitivity <code>sens</code>
(i.e., the conditional probability of a positive decision
provided that the condition is <code>TRUE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>spec</code></td>
<td>
<p>The decision's specificity value <code>spec</code>
(i.e., the conditional probability
of a negative decision provided that the condition is <code>FALSE</code>).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>comp_acc</code> uses probabilities (not frequencies) as
inputs and returns an exact probability (proportion)
without rounding.
</p>
<p>Understanding the probability <code>acc</code>:
</p>

<ul>
<li>
<p> Definition:
<code>acc</code> is the (non-conditional) probability:
</p>
<p><code>acc = p(dec_cor) = dec_cor/N</code>
</p>
<p>or the base rate (or baseline probability)
of a decision being correct, but not necessarily positive.
</p>
<p><code>acc</code> values range
from 0 (no correct decision/prediction)
to 1 (perfect decision/prediction).
</p>
</li>
<li>
<p> Computation: <code>acc</code> can be computed in 2 ways:
</p>
<p>(a) from <code>prob</code>: <code>acc = (prev x sens) + [(1 - prev) x spec]</code>
</p>
<p>(b) from <code>freq</code>: <code>acc = dec_cor/N = (hi + cr)/(hi + mi + fa + cr)</code>
</p>
<p>When frequencies in <code>freq</code> are not rounded, (b) coincides with (a).
</p>
</li>
<li>
<p> Perspective:
<code>acc</code> classifies a population of <code>N</code> individuals
by accuracy/correspondence (<code>acc = dec_cor/N</code>).
</p>
<p><code>acc</code> is the "by accuracy" or "by correspondence" counterpart
to <code>prev</code> (which adopts a "by condition" perspective) and
to <code>ppod</code> (which adopts a "by decision" perspective).
</p>
</li>
<li>
<p> Alternative names of <code>acc</code>:
base rate of correct decisions,
non-erroneous cases
</p>
</li>
<li>
<p> In terms of frequencies,
<code>acc</code> is the ratio of
<code>dec_cor</code> (i.e., <code>hi + cr</code>)
divided by <code>N</code> (i.e.,
<code>hi + mi</code> + <code>fa + cr</code>):
</p>
<p><code>acc = dec_cor/N = (hi + cr)/(hi + mi + fa + cr)</code>
</p>
</li>
<li>
<p> Dependencies:
<code>acc</code> is a feature of both the environment (true condition) and
of the decision process or diagnostic procedure. It reflects the
correspondence of decisions to conditions.
</p>
</li>
</ul>
<p>See <code>accu</code> for other accuracy metrics
and several possible interpretations of accuracy.
</p>


<h3>Value</h3>

<p>Overall accuracy <code>acc</code> as a probability (proportion).
A warning is provided for NaN values.
</p>
<p>See <code>acc</code> for definition
and <code>accu</code> for other accuracy metrics.
<code>comp_accu_freq</code> and <code>comp_accu_prob</code>
compute accuracy metrics from frequencies and probabilities.
</p>


<h3>See Also</h3>

<p><code>acc</code> defines accuracy as a probability;
<code>accu</code> lists all accuracy metrics;
<code>comp_accu_prob</code> computes exact accuracy metrics from probabilities;
<code>comp_accu_freq</code> computes accuracy metrics from frequencies;
<code>comp_sens</code> and <code>comp_PPV</code> compute related probabilities;
<code>is_extreme_prob_set</code> verifies extreme cases;
<code>comp_complement</code> computes a probability's complement;
<code>is_complement</code> verifies probability complements;
<code>comp_prob</code> computes current probability information;
<code>prob</code> contains current probability information;
<code>is_prob</code> verifies probabilities.
</p>
<p>Other functions computing probabilities: 
<code>comp_FDR()</code>,
<code>comp_FOR()</code>,
<code>comp_NPV()</code>,
<code>comp_PPV()</code>,
<code>comp_accu_freq()</code>,
<code>comp_accu_prob()</code>,
<code>comp_comp_pair()</code>,
<code>comp_complement()</code>,
<code>comp_complete_prob_set()</code>,
<code>comp_err()</code>,
<code>comp_fart()</code>,
<code>comp_mirt()</code>,
<code>comp_ppod()</code>,
<code>comp_prob_freq()</code>,
<code>comp_prob()</code>,
<code>comp_sens()</code>,
<code>comp_spec()</code>
</p>
<p>Other metrics: 
<code>accu</code>,
<code>acc</code>,
<code>comp_accu_freq()</code>,
<code>comp_accu_prob()</code>,
<code>comp_err()</code>,
<code>err</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># ways to work:
comp_acc(.10, .200, .300)  # =&gt; acc = 0.29
comp_acc(.50, .333, .666)  # =&gt; acc = 0.4995

# watch out for vectors:
prev.range &lt;- seq(0, 1, by = .1)
comp_acc(prev.range, .5, .5)  # =&gt; 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5

# watch out for extreme values:
comp_acc(1, 1, 1)  #  =&gt; 1
comp_acc(1, 1, 0)  #  =&gt; 1

comp_acc(1, 0, 1)  #  =&gt; 0
comp_acc(1, 0, 0)  #  =&gt; 0

comp_acc(0, 1, 1)  #  =&gt; 1
comp_acc(0, 1, 0)  #  =&gt; 0

comp_acc(0, 0, 1)  #  =&gt; 1
comp_acc(0, 0, 0)  #  =&gt; 0

</code></pre>


</div>