<div class="container">

<table style="width: 100%;"><tr>
<td>ReinforcementLearning</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Performs reinforcement learning</h2>

<h3>Description</h3>

<p>Performs model-free reinforcement learning. Requires input data in the form of sample sequences
consisting of states, actions and rewards. The result of the learning process is a state-action table and an
optimal policy that defines the best possible action in each state.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ReinforcementLearning(data, s = "s", a = "a", r = "r",
  s_new = "s_new", learningRule = "experienceReplay", iter = 1,
  control = list(alpha = 0.1, gamma = 0.1, epsilon = 0.1), verbose = F,
  model = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A dataframe containing the input sequences for reinforcement learning.
Each row represents a state transition tuple <code>(s,a,r,s_new)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s</code></td>
<td>
<p>A string defining the column name of the current state in <code>data</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a</code></td>
<td>
<p>A string defining the column name of the selected action for the current state in <code>data</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r</code></td>
<td>
<p>A string defining the column name of the reward in the current state in <code>data</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s_new</code></td>
<td>
<p>A string defining the column name of the next state in <code>data</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learningRule</code></td>
<td>
<p>A string defining the selected reinforcement learning agent. The default value and
only option in the current package version is <code>experienceReplay</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter</code></td>
<td>
<p>(optional) Iterations to be done. iter is an integer greater than 0. By default, <code>iter</code> is set to 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>(optional) Control parameters defining the behavior of the agent.
Default: <code>alpha = 0.1</code>; <code>gamma = 0.1</code>; <code>epsilon = 0.1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>If true, progress report is shown. Default: <code>false</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>(optional) Existing model of class <code>rl</code>. Default: <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional parameters passed to function.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>An object of class <code>rl</code> with the following components:
</p>

<dl>
<dt><code>Q</code></dt>
<dd>
<p>Resulting state-action table.</p>
</dd>
<dt><code>Q_hash</code></dt>
<dd>
<p>Resulting state-action table in <code>hash</code> format.</p>
</dd>
<dt><code>Actions</code></dt>
<dd>
<p>Set of actions.</p>
</dd>
<dt><code>States</code></dt>
<dd>
<p>Set of states.</p>
</dd>
<dt><code>Policy</code></dt>
<dd>
<p>Resulting policy defining the best possible action in each state.</p>
</dd>
<dt><code>RewardSequence</code></dt>
<dd>
<p>Rewards collected during each learning episode in <code>iter</code>.</p>
</dd>
<dt><code>Reward</code></dt>
<dd>
<p>Total reward collected during the last learning iteration in <code>iter</code>.</p>
</dd>
</dl>
<h3>References</h3>

<p>Sutton and Barto (1998). Reinforcement Learning: An Introduction, Adaptive
Computation and Machine Learning, MIT Press, Cambridge, MA.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Sampling data (1000 grid sequences)
data &lt;- sampleGridSequence(1000)

# Setting reinforcement learning parameters
control &lt;- list(alpha = 0.1, gamma = 0.1, epsilon = 0.1)

# Performing reinforcement learning
model &lt;- ReinforcementLearning(data, s = "State", a = "Action", r = "Reward",
s_new = "NextState", control = control)

# Printing model
print(model)

# Plotting learning curve
plot(model)
</code></pre>


</div>