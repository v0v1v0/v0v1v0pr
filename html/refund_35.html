<div class="container">

<table style="width: 100%;"><tr>
<td>fpca.ssvd</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Smoothed FPCA via iterative penalized rank one SVDs.</h2>

<h3>Description</h3>

<p>Implements the algorithm of Huang, Shen, Buja (2008) for finding smooth right
singular vectors of a matrix <code>X</code> containing (contaminated) evaluations of
functional random variables on a regular, equidistant grid. If the number of
smooth SVs to extract is not specified, the function hazards a guess for the
appropriate number based on the asymptotically optimal truncation threshold
under the assumption of a low rank matrix contaminated with i.i.d. Gaussian
noise with unknown variance derived in Donoho, Gavish (2013). Please note that
Donoho, Gavish (2013) should be regarded as experimental for functional PCA,
and will typically not work well if you have more observations than grid
points.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fpca.ssvd(
  Y = NULL,
  ydata = NULL,
  argvals = NULL,
  npc = NA,
  center = TRUE,
  maxiter = 15,
  tol = 1e-04,
  diffpen = 3,
  gridsearch = TRUE,
  alphagrid = 1.5^(-20:40),
  lower.alpha = 1e-05,
  upper.alpha = 1e+07,
  verbose = FALSE,
  integration = "trapezoidal"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>data matrix (rows: observations; columns: grid of eval. points)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ydata</code></td>
<td>
<p>a data frame <code>ydata</code> representing
irregularly observed functions. NOT IMPLEMENTED for this method.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>argvals</code></td>
<td>
<p>the argument values of the function evaluations in <code>Y</code>,
defaults to a equidistant grid from 0 to 1. See Details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>npc</code></td>
<td>
<p>how many smooth SVs to try to extract, if <code>NA</code> (the default)
the hard thresholding rule of Donoho, Gavish (2013) is used (see Details,
References).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center</code></td>
<td>
<p>center <code>Y</code> so that its column-means are 0? Defaults to
<code>TRUE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiter</code></td>
<td>
<p>how many iterations of the power algorithm to perform at most
(defaults to 15)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>convergence tolerance for power algorithm (defaults to 1e-4)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>diffpen</code></td>
<td>
<p>difference penalty order controlling the desired smoothness of
the right singular vectors, defaults to 3 (i.e., deviations from local
quadratic polynomials).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gridsearch</code></td>
<td>
<p>use <code>optimize</code> or a grid search to find
GCV-optimal smoothing parameters? defaults to <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alphagrid</code></td>
<td>
<p>grid of smoothing parameter values for grid search</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lower.alpha</code></td>
<td>
<p>lower limit for for smoothing parameter if
<code>!gridsearch</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>upper.alpha</code></td>
<td>
<p>upper limit for smoothing parameter if <code>!gridsearch</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>generate graphical summary of progress and diagnostic messages?
defaults to <code>FALSE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>integration</code></td>
<td>
<p>ignored, see Details.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Note that <code>fpca.ssvd</code> computes smoothed orthonormal eigenvectors
of the supplied function evaluations (and associated scores), not (!)
evaluations of the smoothed orthonormal eigenfunctions. The smoothed
orthonormal eigenvectors are then rescaled by the length of the domain
defined by <code>argvals</code> to have a quadratic integral approximately equal
to one (instead of crossproduct equal to one), so they approximate the behavior
of smooth eigenfunctions. If <code>argvals</code> is not equidistant,
<code>fpca.ssvd</code> will simply return the smoothed eigenvectors without rescaling,
with a warning.
</p>


<h3>Value</h3>

<p>an <code>fpca</code> object like that returned from <code>fpca.sc</code>,
with entries <code>Yhat</code>, the smoothed trajectories, <code>Y</code>, the observed
data, <code>scores</code>, the estimated FPC loadings, <code>mu</code>, the column means
of <code>Y</code> (or a vector of zeroes if <code>!center</code>),  <code>efunctions</code>,
the estimated smooth FPCs (note that these are orthonormal vectors, not
evaluations of orthonormal functions if <code>argvals</code> is not equidistant),
<code>evalues</code>, their associated eigenvalues, and <code>npc</code>, the number of
smooth components that were extracted.
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl
</p>


<h3>References</h3>

<p>Huang, J. Z., Shen, H., and Buja, A. (2008). Functional principal
components analysis via penalized rank one approximation. <em>Electronic
Journal of Statistics</em>, 2, 678-695
</p>
<p>Donoho, D.L., and Gavish, M. (2013). The Optimal Hard Threshold for Singular
Values is 4/sqrt(3). eprint arXiv:1305.5870. Available from
<a href="https://arxiv.org/abs/1305.5870">https://arxiv.org/abs/1305.5870</a>.
</p>


<h3>See Also</h3>

<p><code>fpca.sc</code> and <code>fpca.face</code> for FPCA based on
smoothing a covariance estimate; <code>fpca2s</code> for a faster SVD-based
approach.
</p>


<h3>Examples</h3>

<pre><code class="language-R"> ## as in Sec. 6.2 of Huang, Shen, Buja (2008):
 set.seed(2678695)
 n &lt;- 101
 m &lt;- 101
 s1 &lt;- 20
 s2 &lt;- 10
 s &lt;- 4
 t &lt;- seq(-1, 1, l=m)
 v1 &lt;- t + sin(pi*t)
 v2 &lt;- cos(3*pi*t)
 V &lt;- cbind(v1/sqrt(sum(v1^2)), v2/sqrt(sum(v2^2)))
 U &lt;- matrix(rnorm(n*2), n, 2)
 D &lt;- diag(c(s1^2, s2^2))
 eps &lt;- matrix(rnorm(m*n, sd=s), n, m)
 Y &lt;- U%*%D%*%t(V) + eps

smoothSV &lt;- fpca.ssvd(Y, verbose=TRUE)

 layout(t(matrix(1:4, nr=2)))
 clrs &lt;- sapply(rainbow(n), function(c)
           do.call(rgb, as.list(c(col2rgb(c)/255, .1))))
 matplot(V, type="l", lty=1, col=1:2, xlab="",
         main="FPCs: true", bty="n")
 matplot(smoothSV$efunctions, type="l", lty=1, col=1:5, xlab="",
         main="FPCs: estimate", bty="n")
 matplot(1:m, t(U%*%D%*%t(V)), type="l", lty=1, col=clrs, xlab="", ylab="",
         main="true smooth Y", bty="n")
 matplot(1:m, t(smoothSV$Yhat), xlab="", ylab="",
         type="l", lty=1,col=clrs, main="estimated smooth Y", bty="n")
</code></pre>


</div>