<div class="container">

<table style="width: 100%;"><tr>
<td>embed_text</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Generate Embeddings</h2>

<h3>Description</h3>

<p>Generate Embeddings
</p>


<h3>Usage</h3>

<pre><code class="language-R">embed_text(
  text,
  model = NULL,
  server = NULL,
  model_params = NULL,
  verbose = getOption("rollama_verbose", default = interactive())
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>text</code></td>
<td>
<p>text vector to generate embeddings for.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>which model to use. See <a href="https://ollama.com/library">https://ollama.com/library</a> for options.
Default is "llama3". Set option(rollama_model = "modelname") to change
default for the current session. See pull_model for more details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>server</code></td>
<td>
<p>URL to an Ollama server (not the API). Defaults to
"http://localhost:11434".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model_params</code></td>
<td>
<p>a named list of additional model parameters listed in the
<a href="https://github.com/ollama/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values">documentation for the Modelfile</a>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Whether to print status messages to the Console
(<code>TRUE</code>/<code>FALSE</code>). The default is to have status messages in
interactive sessions. Can be changed with <code>options(rollama_verbose =
  FALSE)</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a tibble with embeddings.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
embed_text(c("Here is an article about llamas...",
             "R is a language and environment for statistical computing and graphics."))

## End(Not run)
</code></pre>


</div>