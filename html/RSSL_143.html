<div class="container">

<table style="width: 100%;"><tr>
<td>svmlin</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>svmlin implementation by Sindhwani &amp; Keerthi (2006)</h2>

<h3>Description</h3>

<p>R interface to the svmlin code by Vikas Sindhwani and S. Sathiya Keerthi for fast linear transductive SVMs.
</p>


<h3>Usage</h3>

<pre><code class="language-R">svmlin(X, y, X_u = NULL, algorithm = 1, lambda = 1, lambda_u = 1,
  max_switch = 10000, pos_frac = 0.5, Cp = 1, Cn = 1,
  verbose = FALSE, intercept = TRUE, scale = FALSE, x_center = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Matrix or sparseMatrix containing the labeled feature vectors, without intercept</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>factor containing class assignments</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X_u</code></td>
<td>
<p>Matrix or sparseMatrix containing the unlabeled feature vectors, without intercept</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>algorithm</code></td>
<td>
<p>integer; Algorithm choice, see details (default:1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>double; Regularization parameter lambda (default 1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda_u</code></td>
<td>
<p>double; Regularization parameter lambda_u (default 1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_switch</code></td>
<td>
<p>integer; Maximum number of switches in TSVM (default 10000)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pos_frac</code></td>
<td>
<p>double; Positive class fraction of unlabeled data  (default 0.5)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Cp</code></td>
<td>
<p>double; Relative cost for positive examples (only available with algorithm 1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Cn</code></td>
<td>
<p>double; Relative cost for positive examples (only available with algorithm 1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>logical; Controls the verbosity of the output</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>logical; Whether an intercept should be included</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>logical; Should the features be normalized? (default: FALSE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x_center</code></td>
<td>
<p>logical;  Should the features be centered?</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The codes to select the algorithm are the following: 0. Regularized Least Squares Classification 1. SVM (L2-SVM-MFN) 2. Multi-switch Transductive SVM (using L2-SVM-MFN) 3. Deterministic Annealing Semi-supervised SVM (using L2-SVM-MFN).
</p>


<h3>References</h3>

<p>Vikas Sindhwani and S. Sathiya Keerthi. Large Scale Semi-supervised Linear SVMs. Proceedings of ACM SIGIR, 2006
@references V. Sindhwani and S. Sathiya Keerthi. Newton Methods for Fast Solution of Semi-supervised Linear SVMs. Book Chapter in Large Scale Kernel Machines, MIT Press, 2006
</p>


<h3>See Also</h3>

<p>Other RSSL classifiers: 
<code>EMLeastSquaresClassifier</code>,
<code>EMLinearDiscriminantClassifier</code>,
<code>GRFClassifier</code>,
<code>ICLeastSquaresClassifier</code>,
<code>ICLinearDiscriminantClassifier</code>,
<code>KernelLeastSquaresClassifier</code>,
<code>LaplacianKernelLeastSquaresClassifier()</code>,
<code>LaplacianSVM</code>,
<code>LeastSquaresClassifier</code>,
<code>LinearDiscriminantClassifier</code>,
<code>LinearSVM</code>,
<code>LinearTSVM()</code>,
<code>LogisticLossClassifier</code>,
<code>LogisticRegression</code>,
<code>MCLinearDiscriminantClassifier</code>,
<code>MCNearestMeanClassifier</code>,
<code>MCPLDA</code>,
<code>MajorityClassClassifier</code>,
<code>NearestMeanClassifier</code>,
<code>QuadraticDiscriminantClassifier</code>,
<code>S4VM</code>,
<code>SVM</code>,
<code>SelfLearning</code>,
<code>TSVM</code>,
<code>USMLeastSquaresClassifier</code>,
<code>WellSVM</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(svmlin_example)
t_svmlin_1 &lt;- svmlin(svmlin_example$X_train[1:50,],
                 svmlin_example$y_train,X_u=NULL, lambda = 0.001)
t_svmlin_2 &lt;- svmlin(svmlin_example$X_train[1:50,],
                       svmlin_example$y_train,
                       X_u=svmlin_example$X_train[-c(1:50),], 
                       lambda = 10,lambda_u=100,algorithm = 2)
                       
# Calculate Accuracy
mean(predict(t_svmlin_1,svmlin_example$X_test)==svmlin_example$y_test)
mean(predict(t_svmlin_2,svmlin_example$X_test)==svmlin_example$y_test)

data(testdata)

g_svm &lt;- SVM(testdata$X,testdata$y)
g_sup &lt;- svmlin(testdata$X,testdata$y,testdata$X_u,algorithm = 3)
g_semi &lt;- svmlin(testdata$X,testdata$y,testdata$X_u,algorithm = 2)

mean(predict(g_svm,testdata$X_test)==testdata$y_test)
mean(predict(g_sup,testdata$X_test)==testdata$y_test)
mean(predict(g_semi,testdata$X_test)==testdata$y_test)
</code></pre>


</div>