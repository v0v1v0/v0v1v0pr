<div class="container">

<table style="width: 100%;"><tr>
<td>mbplsrda</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>multi-block PLSDA models</h2>

<h3>Description</h3>

<p>Multi-block discrimination (DA) based on PLS.
</p>
<p>The training variable <code class="reqn">y</code> (univariate class membership) is firstly transformed to a dummy table containing <code class="reqn">nclas</code> columns, where <code class="reqn">nclas</code> is the number of classes present in <code class="reqn">y</code>. Each column is a dummy variable (0/1). Then, a PLS2 is implemented on the <code class="reqn">X-</code>data and the dummy table, returning latent variables (LVs) that are used as dependent variables in a DA model.
</p>
<p>- <code>mbplsrda</code>: Usual "PLSDA". A linear regression model predicts the Y-dummy table from the PLS2 LVs. This corresponds to the PLSR2 of the X-data and the Y-dummy table. For a given observation, the final prediction is the class corresponding to the dummy variable for which the prediction is the highest.
</p>
<p>- <code>mbplslda</code> and <code>mbplsqda</code>: Probabilistic LDA and QDA are run over the PLS2 LVs, respectively.
</p>


<h3>Usage</h3>

<pre><code class="language-R">
mbplsrda(Xlist, y, blockscaling = TRUE, weights = NULL, nlv, 
Xscaling = c("none", "pareto", "sd")[1], Yscaling = c("none", "pareto", "sd")[1])

mbplslda(Xlist, y, blockscaling = TRUE, weights = NULL, nlv, prior = c("unif", "prop"),
Xscaling = c("none", "pareto", "sd")[1], Yscaling = c("none", "pareto", "sd")[1])

mbplsqda(Xlist, y, blockscaling = TRUE, weights = NULL, nlv, prior = c("unif", "prop"),
Xscaling = c("none", "pareto", "sd")[1], Yscaling = c("none", "pareto", "sd")[1])

## S3 method for class 'Mbplsrda'
predict(object, X, ..., nlv = NULL) 

## S3 method for class 'Mbplsprobda'
predict(object, X, ..., nlv = NULL) 

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Xlist</code></td>
<td>
<p>For the main functions: list of training X-data (<code class="reqn">n</code>rows).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>For the auxiliary functions: list of new X-data (<code class="reqn">n</code> rows), with the same variables than the training X-data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Training class membership (<code class="reqn">n</code>). <b>Note:</b> If <code>y</code> is a factor, it is replaced by a character vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>blockscaling</code></td>
<td>
<p>logical. If TRUE, the scaling factor (computed on the training) is the "norm" of the block, i.e. the square root of the sum of the variances of each column of the block.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>Weights (<code class="reqn">n</code>) to apply to the training observations for the PLS2. Internally, weights are "normalized" to sum to 1. Default to <code>NULL</code> (weights are set to <code class="reqn">1 / n</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlv</code></td>
<td>
<p>The number(s) of LVs to calculate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>
<p>The prior probabilities of the classes. Possible values are "unif" (default; probabilities are set equal for all the classes) or "prop" (probabilities are set equal to the observed proportions of the classes in <code>y</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xscaling</code></td>
<td>
<p>vector (of length Xlist) of variable scaling for each datablock, among "none" (mean-centering only), "pareto" (mean-centering and pareto scaling), "sd" (mean-centering and unit variance scaling). If "pareto" or "sd", uncorrected standard deviation is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Yscaling</code></td>
<td>
<p>character. variable scaling for the Y-block after binary transformation, among "none" (mean-centering only), "pareto" (mean-centering and pareto scaling), "sd" (mean-centering and unit variance scaling). If "pareto" or "sd", uncorrected standard deviation is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>For the auxiliary functions: A fitted model, output of a call to the main functions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>For the auxiliary functions: Optional arguments. Not used.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>For <code>mbplsrda</code>:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>fm</code></td>
<td>
<p>list with the MB-PLS model: (<code>T</code>): X-scores matrix; (<code>P</code>): X-loading matrix;(<code>R</code>): The PLS projection matrix (p,nlv); (<code>W</code>): X-loading weights matrix ;(<code>C</code>): The Y-loading weights matrix; (<code>TT</code>): the X-score normalization factor; (<code>xmeans</code>): the centering vector of X (p,1);  (<code>ymeans</code>): the centering vector of Y (q,1); (<code>weights</code>): vector of observation weights; (<code>blockscaling</code>): block scaling; (<code>Xnorms</code>): "norm" of each block; (<code>U</code>): intermediate output.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lev</code></td>
<td>
<p>classes</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ni</code></td>
<td>
<p>number of observations in each class</p>
</td>
</tr>
</table>
<p>For <code>mbplslda</code>, <code>mbplsqda</code>:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>fm</code></td>
<td>
<p>list with 
[[1]] the MB-PLS model: (<code>T</code>): X-scores matrix; (<code>P</code>): X-loading matrix;(<code>R</code>): The PLS projection matrix (p,nlv); (<code>W</code>): X-loading weights matrix ;(<code>C</code>): The Y-loading weights matrix; (<code>TT</code>): the X-score normalization factor; (<code>xmeans</code>): the centering vectors of X;  (<code>ymeans</code>): the centering vector of Y (q,1); (<code>xscales</code>): the scaling vector of X (p,1);  (<code>yscales</code>): the scaling vector of Y (q,1); (<code>weights</code>): vector of observation weights; (<code>blockscaling</code>): block scaling; (<code>Xnorms</code>): "norm" of each block; (<code>U</code>): intermediate output.
[[2]] lda or qda models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lev</code></td>
<td>
<p>classes</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ni</code></td>
<td>
<p>number of observations in each class</p>
</td>
</tr>
</table>
<p>For <code>predict.Mbplsrda</code>, <code>predict.Mbplsprobda</code>: 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>predicted class for each observation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>posterior</code></td>
<td>
<p>calculated probability of belonging to a class for each observation</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>The first example concerns MB-PLSDA, and the second one concerns MB-PLS LDA.
<code>fm</code> are PLS1 models, and <code>zfm</code> are PLS2 models.
</p>


<h3>See Also</h3>

<p><code>mbplsr_mbplsda_allsteps</code> function to help determine the optimal number of latent variables, perform a permutation test, calculate model parameters and predict new observations.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## EXAMPLE OF MB-PLSDA

n &lt;- 50 ; p &lt;- 8
Xtrain &lt;- matrix(rnorm(n * p), ncol = p)
Xtrainlist &lt;- list(Xtrain[,1:3], Xtrain[,4:8])

ytrain &lt;- sample(c(1, 4, 10), size = n, replace = TRUE)

Xtest &lt;- Xtrain[1:5, ] ; ytest &lt;- ytrain[1:5]
Xtestlist &lt;- list(Xtest[,1:3], Xtest[,4:8])

nlv &lt;- 5
fm &lt;- mbplsrda(Xtrainlist, ytrain, Xscaling = "sd", nlv = nlv)
names(fm)

predict(fm, Xtestlist)
predict(fm, Xtestlist, nlv = 0:2)$pred

pred &lt;- predict(fm, Xtestlist)$pred
err(pred, ytest)

zfm &lt;- fm$fm
transform(zfm, Xtestlist)
transform(zfm, Xtestlist, nlv = 1)
summary(zfm, Xtrainlist)
coef(zfm)
coef(zfm, nlv = 0)
coef(zfm, nlv = 2)

## EXAMPLE OF MB-PLS LDA

n &lt;- 50 ; p &lt;- 8
Xtrain &lt;- matrix(rnorm(n * p), ncol = p)
Xtrainlist &lt;- list(Xtrain[,1:3], Xtrain[,4:8])

ytrain &lt;- sample(c(1, 4, 10), size = n, replace = TRUE)

Xtest &lt;- Xtrain[1:5, ] ; ytest &lt;- ytrain[1:5]
Xtestlist &lt;- list(Xtest[,1:3], Xtest[,4:8])

nlv &lt;- 5
fm &lt;- mbplslda(Xtrainlist, ytrain, Xscaling = "none", nlv = nlv)
predict(fm, Xtestlist)
predict(fm, Xtestlist, nlv = 1:2)$pred

zfm &lt;- fm[[1]][[1]]
class(zfm)
names(zfm)
summary(zfm, Xtrainlist)
transform(zfm, Xtestlist)
coef(zfm)

## EXAMPLE OF MB-PLS QDA

n &lt;- 50 ; p &lt;- 8
Xtrain &lt;- matrix(rnorm(n * p), ncol = p)
Xtrainlist &lt;- list(Xtrain[,1:3], Xtrain[,4:8])

ytrain &lt;- sample(c(1, 4, 10), size = n, replace = TRUE)

Xtest &lt;- Xtrain[1:5, ] ; ytest &lt;- ytrain[1:5]
Xtestlist &lt;- list(Xtest[,1:3], Xtest[,4:8])

nlv &lt;- 5
fm &lt;- mbplsqda(Xtrainlist, ytrain, Xscaling = "none", nlv = nlv)
predict(fm, Xtestlist)
predict(fm, Xtestlist, nlv = 1:2)$pred

zfm &lt;- fm[[1]][[1]]
class(zfm)
names(zfm)
summary(zfm, Xtrainlist)
transform(zfm, Xtestlist)
coef(zfm)

</code></pre>


</div>