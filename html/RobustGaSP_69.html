<div class="container">

<table style="width: 100%;"><tr>
<td>predict.rgasp</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>

Prediction for Robust GaSP model
</h2>

<h3>Description</h3>


<p>Function to make prediction on the robust GaSP model after the robust GaSP model has been constructed.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S4 method for signature 'rgasp'
predict(object,testing_input,testing_trend= matrix(1,dim(testing_input)[1],1),
r0=NA,interval_data=T,
outasS3 = T,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p> an object of  class <code>rgasp</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>testing_input</code></td>
<td>
<p>a matrix containing the inputs where the <code>rgasp</code> is to perform prediction.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>testing_trend</code></td>
<td>
<p>a matrix of mean/trend for prediction.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r0</code></td>
<td>

<p>the distance between input and testing input. If the value is <code>NA</code>, it will be calculated later. It can also be specified by the user. If specified by user, it is either a <code>matrix</code> or <code>list</code>. The default value is <code>NA</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>interval_data</code></td>
<td>

<p>a boolean value. If <code>T</code>, the interval of the data will be calculated. Otherwise, the interval of the mean of the data will be calculted.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>outasS3</code></td>
<td>
<p>a boolean parameter indicating whether the output of the function should be as an <code>S3 object</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Extra arguments to be passed to the function (not implemented yet).</p>
</td>
</tr>
</table>
<h3>Value</h3>






<p>If the parameter <code>outasS3=F</code>, then the returned value is a <code>S4 object</code> of class <code>predrgasp-class</code> with 

</p>

<dl>
<dt>
<code>call</code>:</dt>
<dd> <p><code>call</code> to <code>predict.rgasp</code> function where the returned object has been created.</p>
</dd>
<dt>
<code>mean</code>:</dt>
<dd>
<p> predictive mean for the testing inputs.</p>
</dd>
<dt>
<code>lower95</code>:</dt>
<dd>
<p>lower bound of the 95% posterior credible interval.</p>
</dd>
<dt>
<code>upper95</code>:</dt>
<dd>
<p>upper bound of the 95% posterior credible interval.</p>
</dd>
<dt>
<code>sd</code>:</dt>
<dd>
<p>standard deviation of each <code>testing_input</code>.</p>
</dd>
</dl>
<p>If the parameter <code>outasS3=T</code>, then the returned value is a <code>list</code> with 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>mean </code></td>
<td>
<p> predictive mean for the testing inputs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lower95 </code></td>
<td>
<p>lower bound of the 95% posterior credible interval.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>upper95 </code></td>
<td>
<p>upper bound of the 95% posterior credible interval.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sd </code></td>
<td>
<p>standard deviation of each <code>testing_input</code>.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>


<p>Mengyang Gu [aut, cre],
  Jesus Palomo [aut],
  James Berger [aut]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>M. Gu. (2016). Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output. Ph.D. thesis. Duke University.
</p>
<p>M. Gu. and J.O. Berger (2016). Parallel partial Gaussian process emulation for computer models with massive output. <em>Annals of Applied Statistics</em>, 10(3), 1317-1347.
</p>
<p>M. Gu, X. Wang and J.O. Berger (2018), <em>Robust Gaussian Stochastic Process Emulation</em>, <em>Annals of Statistics</em>, 46(6A), 3038-3066.
</p>
<p>M. Gu (2018), <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection</em>, arXiv:1804.09329.
</p>


<h3>Examples</h3>

<pre><code class="language-R">  #------------------------
  # a 3 dimensional example
  #------------------------
  # dimensional of the inputs
  dim_inputs &lt;- 3    
  # number of the inputs
  num_obs &lt;- 30       
  # uniform samples of design
  input &lt;- matrix(runif(num_obs*dim_inputs), num_obs,dim_inputs) 
  
  # Following codes use maximin Latin Hypercube Design, which is typically better than uniform
  # library(lhs)
  # input &lt;- maximinLHS(n=num_obs, k=dim_inputs)  ##maximin lhd sample
  
  # outputs from the 3 dim dettepepel.3.data function
  
  output = matrix(0,num_obs,1)
  for(i in 1:num_obs){
    output[i]&lt;-dettepepel.3.data (input[i,])
  }
  
  # use constant mean basis, with no constraint on optimization
  m1&lt;- rgasp(design = input, response = output, lower_bound=FALSE)
  
  # the following use constraints on optimization
  # m1&lt;- rgasp(design = input, response = output, lower_bound=TRUE)
  
  # the following use a single start on optimization
  # m1&lt;- rgasp(design = input, response = output, lower_bound=FALS)
  
  # number of points to be predicted 
  num_testing_input &lt;- 5000    
  # generate points to be predicted
  testing_input &lt;- matrix(runif(num_testing_input*dim_inputs),num_testing_input,dim_inputs)
  # Perform prediction
  m1.predict&lt;-predict(m1, testing_input)
  # Predictive mean
  # m1.predict$mean  
  
  # The following tests how good the prediction is 
  testing_output &lt;- matrix(0,num_testing_input,1)
  for(i in 1:num_testing_input){
    testing_output[i]&lt;-dettepepel.3.data(testing_input[i,])
  }
  
  # compute the MSE, average coverage and average length
  # out of sample MSE
  MSE_emulator &lt;- sum((m1.predict$mean-testing_output)^2)/(num_testing_input)  
  
  # proportion covered by 95% posterior predictive credible interval
  prop_emulator &lt;- length(which((m1.predict$lower95&lt;=testing_output)
                   &amp;(m1.predict$upper95&gt;=testing_output)))/num_testing_input
  
  # average length of  posterior predictive credible interval
  length_emulator &lt;- sum(m1.predict$upper95-m1.predict$lower95)/num_testing_input
  
  # output of prediction
  MSE_emulator
  prop_emulator
  length_emulator  
  # normalized RMSE
  sqrt(MSE_emulator/mean((testing_output-mean(output))^2 ))


  #-----------------------------------
  # a 2 dimensional example with trend
  #-----------------------------------
  # dimensional of the inputs
  dim_inputs &lt;- 2    
  # number of the inputs
  num_obs &lt;- 20       
  
  # uniform samples of design
  input &lt;-matrix(runif(num_obs*dim_inputs), num_obs,dim_inputs) 
  # Following codes use maximin Latin Hypercube Design, which is typically better than uniform
  # library(lhs)
  # input &lt;- maximinLHS(n=num_obs, k=dim_inputs)  ##maximin lhd sample
  
  # outputs from the 2 dim Brainin function
  
  output &lt;- matrix(0,num_obs,1)
  for(i in 1:num_obs){
    output[i]&lt;-limetal.2.data (input[i,])
  }
  
  #mean basis (trend)
  X&lt;-cbind(rep(1,num_obs), input )
  
  
  # use constant mean basis with trend, with no constraint on optimization
  m2&lt;- rgasp(design = input, response = output,trend =X,  lower_bound=FALSE)
  
  
  # number of points to be predicted 
  num_testing_input &lt;- 5000    
  # generate points to be predicted
  testing_input &lt;- matrix(runif(num_testing_input*dim_inputs),num_testing_input,dim_inputs)
  
  # trend of testing
  testing_X&lt;-cbind(rep(1,num_testing_input), testing_input )
  
  
  # Perform prediction
  m2.predict&lt;-predict(m2, testing_input,testing_trend=testing_X)
  # Predictive mean
  #m2.predict$mean  
  
  # The following tests how good the prediction is 
  testing_output &lt;- matrix(0,num_testing_input,1)
  for(i in 1:num_testing_input){
    testing_output[i]&lt;-limetal.2.data(testing_input[i,])
  }
  
  # compute the MSE, average coverage and average length
  # out of sample MSE
  MSE_emulator &lt;- sum((m2.predict$mean-testing_output)^2)/(num_testing_input)  
  
  # proportion covered by 95% posterior predictive credible interval
  prop_emulator &lt;- length(which((m2.predict$lower95&lt;=testing_output)
                   &amp;(m2.predict$upper95&gt;=testing_output)))/num_testing_input
  
  # average length of  posterior predictive credible interval
  length_emulator &lt;- sum(m2.predict$upper95-m2.predict$lower95)/num_testing_input
  
  # output of prediction
  MSE_emulator
  prop_emulator
  length_emulator  
  # normalized RMSE
  sqrt(MSE_emulator/mean((testing_output-mean(output))^2 ))


    ###here try the isotropic kernel (a function of Euclidean distance)
  m2_isotropic&lt;- rgasp(design = input, response = output,trend =X,  
             lower_bound=FALSE,isotropic=TRUE)
  
  m2_isotropic.predict&lt;-predict(m2_isotropic, testing_input,testing_trend=testing_X)
  
  # compute the MSE, average coverage and average length
  # out of sample MSE
  MSE_emulator_isotropic &lt;- sum((m2_isotropic.predict$mean-testing_output)^2)/(num_testing_input)
  
  # proportion covered by 95% posterior predictive credible interval
  prop_emulator_isotropic &lt;- length(which((m2_isotropic.predict$lower95&lt;=testing_output)
                                &amp;(m2_isotropic.predict$upper95&gt;=testing_output)))/num_testing_input
  
  # average length of  posterior predictive credible interval
  length_emulator_isotropic &lt;- sum(m2_isotropic.predict$upper95-
  m2_isotropic.predict$lower95)/num_testing_input
  
  MSE_emulator_isotropic
  prop_emulator_isotropic
  length_emulator_isotropic
  ##the result of isotropic kernel is not as good as the product kernel for this example


  #--------------------------------------------------------------------------------------
  # an 8 dimensional example using only a subset inputs and a noise with unknown variance
  #--------------------------------------------------------------------------------------
  set.seed(1)
  # dimensional of the inputs
  dim_inputs &lt;- 8    
  # number of the inputs
  num_obs &lt;- 50       
  
  # uniform samples of design
  input &lt;-matrix(runif(num_obs*dim_inputs), num_obs,dim_inputs) 
  # Following codes use maximin Latin Hypercube Design, which is typically better than uniform
  # library(lhs)
  # input &lt;- maximinLHS(n=num_obs, k=dim_inputs)  # maximin lhd sample
  
  # rescale the design to the domain
  input[,1]&lt;-0.05+(0.15-0.05)*input[,1];
  input[,2]&lt;-100+(50000-100)*input[,2];
  input[,3]&lt;-63070+(115600-63070)*input[,3];
  input[,4]&lt;-990+(1110-990)*input[,4];
  input[,5]&lt;-63.1+(116-63.1)*input[,5];
  input[,6]&lt;-700+(820-700)*input[,6];
  input[,7]&lt;-1120+(1680-1120)*input[,7];
  input[,8]&lt;-9855+(12045-9855)*input[,8];
  
  # outputs from the 8 dim Borehole function
  
  output=matrix(0,num_obs,1)
  for(i in 1:num_obs){
    output[i]=borehole(input[i,])
  }
  
  
    
    
  
  # use constant mean basis with trend, with no constraint on optimization
  m3&lt;- rgasp(design = input[,c(1,4,6,7,8)], response = output,
             nugget.est=TRUE, lower_bound=FALSE)
  
  
  # number of points to be predicted 
  num_testing_input &lt;- 5000    
  # generate points to be predicted
  testing_input &lt;- matrix(runif(num_testing_input*dim_inputs),num_testing_input,dim_inputs)
  
  # resale the points to the region to be predict
  testing_input[,1]&lt;-0.05+(0.15-0.05)*testing_input[,1];
  testing_input[,2]&lt;-100+(50000-100)*testing_input[,2];
  testing_input[,3]&lt;-63070+(115600-63070)*testing_input[,3];
  testing_input[,4]&lt;-990+(1110-990)*testing_input[,4];
  testing_input[,5]&lt;-63.1+(116-63.1)*testing_input[,5];
  testing_input[,6]&lt;-700+(820-700)*testing_input[,6];
  testing_input[,7]&lt;-1120+(1680-1120)*testing_input[,7];
  testing_input[,8]&lt;-9855+(12045-9855)*testing_input[,8];
  
  
  # Perform prediction
  m3.predict&lt;-predict(m3, testing_input[,c(1,4,6,7,8)])
  # Predictive mean
  #m3.predict$mean  
  
  # The following tests how good the prediction is 
  testing_output &lt;- matrix(0,num_testing_input,1)
  for(i in 1:num_testing_input){
    testing_output[i]&lt;-borehole(testing_input[i,])
  }
  
  # compute the MSE, average coverage and average length
  # out of sample MSE
  MSE_emulator &lt;- sum((m3.predict$mean-testing_output)^2)/(num_testing_input)  
  
  # proportion covered by 95% posterior predictive credible interval
  prop_emulator &lt;- length(which((m3.predict$lower95&lt;=testing_output)
                   &amp;(m3.predict$upper95&gt;=testing_output)))/num_testing_input
  
  # average length of  posterior predictive credible interval
  length_emulator &lt;- sum(m3.predict$upper95-m3.predict$lower95)/num_testing_input
  
  # output of sample prediction
  MSE_emulator
  prop_emulator
  length_emulator  
  # normalized RMSE
  sqrt(MSE_emulator/mean((testing_output-mean(output))^2 ))

</code></pre>


</div>