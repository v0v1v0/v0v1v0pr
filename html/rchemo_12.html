<div class="container">

<table style="width: 100%;"><tr>
<td>dkrr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Direct KRR Models</h2>

<h3>Description</h3>

<p>Direct kernel ridge regression (DKRR), following the same approcah as for DKPLSR (Bennett &amp; Embrechts 2003). The method builds kernel Gram matrices and then runs a RR algorithm on them. This is not equivalent to the "true" KRR (= LS-SVM) algorithm. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">
dkrr(X, Y, weights = NULL, lb = 1e-2, kern = "krbf", ...)

## S3 method for class 'Dkrr'
coef(object, ..., lb = NULL)  

## S3 method for class 'Dkrr'
predict(object, X, ..., lb = NULL)  

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>For the main function: Training X-data (<code class="reqn">n, p</code>). â€” For the auxiliary functions: New X-data (<code class="reqn">m, p</code>) to consider.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>Training Y-data (<code class="reqn">n, q</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>Weights (<code class="reqn">n, 1</code>) to apply to the training observations. Internally, weights are "normalized" to sum to 1. Default to <code>NULL</code> (weights are set to <code class="reqn">1 / n</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lb</code></td>
<td>
<p>A value of regularization parameter <code class="reqn">lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kern</code></td>
<td>
<p>Name of the function defining the considered kernel for building the Gram matrix. See <code>krbf</code> for syntax, and other available kernel functions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Optional arguments to pass in the kernel function defined in <code>kern</code> (e.g. <code>gamma</code> for <code>krbf</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>For the auxiliary functions: A fitted model, output of a call to the main function.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>For <code>dkrr</code>: 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Matrix with the training X-data (<code class="reqn">n, p</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fm</code></td>
<td>
<p>List with the outputs of the RR ((<code>V</code>): eigenvector matrix of the correlation matrix (n,n); (<code>TtDY</code>): intermediate output; (<code>sv</code>): singular values of the matrix (1,n); (<code>lb</code>): value of regularization parameter <code class="reqn">lambda</code>; (<code>xmeans</code>): the centering vector of X (p,1); (<code>ymeans</code>): the centering vector of Y (q,1); (<code>weights</code>): the weights vector of X-variables (p,1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>kernel Gram matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kern</code></td>
<td>
<p>kernel function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dots</code></td>
<td>
<p>Optional arguments passed in the kernel function</p>
</td>
</tr>
</table>
<p>For <code>predict.Dkrr</code>: 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>A list of matrices (<code class="reqn">m, q</code>) with the Y predicted values for the new X-data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>kernel Gram matrix (<code class="reqn">m, nlv</code>), with values for the new X-data</p>
</td>
</tr>
</table>
<p>For <code>coef.Dkrr</code>: 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>int</code></td>
<td>
<p>matrix (1,nlv) with the intercepts</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>
<p>matrix (n,nlv) with the coefficients</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>model complexity (number of degrees of freedom)</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>The second example concerns the fitting of the function sinc(x) described in Rosipal &amp; Trejo 2001 p. 105-106
</p>


<h3>References</h3>

<p>Bennett, K.P., Embrechts, M.J., 2003. An optimization perspective on kernel partial least squares regression, in: Advances in Learning Theory: Methods, Models and Applications, NATO Science Series III: Computer &amp; Systems Sciences. IOS Press Amsterdam, pp. 227-250.
</p>
<p>Rosipal, R., Trejo, L.J., 2001. Kernel Partial Least Squares Regression in Reproducing Kernel Hilbert Space. Journal of Machine Learning Research 2, 97-123.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## EXAMPLE 1

n &lt;- 6 ; p &lt;- 4
Xtrain &lt;- matrix(rnorm(n * p), ncol = p)
ytrain &lt;- rnorm(n)
Ytrain &lt;- cbind(y1 = ytrain, y2 = 100 * ytrain)
m &lt;- 3
Xtest &lt;- Xtrain[1:m, , drop = FALSE] 
Ytest &lt;- Ytrain[1:m, , drop = FALSE] ; ytest &lt;- Ytest[1:m, 1]

lb &lt;- 2
fm &lt;- dkrr(Xtrain, Ytrain, lb = lb, kern = "krbf", gamma = .8)
coef(fm)
coef(fm, lb = .6)
predict(fm, Xtest)
predict(fm, Xtest, lb = c(0.1, .8))

pred &lt;- predict(fm, Xtest)$pred
msep(pred, Ytest)

lb &lt;- 2
fm &lt;- dkrr(Xtrain, Ytrain, lb = lb, kern = "kpol", degree = 2, coef0 = 10)
predict(fm, Xtest)

## EXAMPLE 1

x &lt;- seq(-10, 10, by = .2)
x[x == 0] &lt;- 1e-5
n &lt;- length(x)
zy &lt;- sin(abs(x)) / abs(x)
y &lt;- zy + rnorm(n, 0, .2)
plot(x, y, type = "p")
lines(x, zy, lty = 2)
X &lt;- matrix(x, ncol = 1)

fm &lt;- dkrr(X, y, lb = .01, gamma = .5)
pred &lt;- predict(fm, X)$pred
plot(X, y, type = "p")
lines(X, zy, lty = 2)
lines(X, pred, col = "red")

</code></pre>


</div>