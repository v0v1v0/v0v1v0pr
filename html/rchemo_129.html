<div class="container">

<table style="width: 100%;"><tr>
<td>lwplsr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>KNN-LWPLSR</h2>

<h3>Description</h3>

<p>Function <code>lwplsr</code> fits KNN-LWPLSR models described in Lesnoff et al. (2020). The function uses functions <code>getknn</code>, <code>locw</code> and PLSR functions. See the code for details. Many variants of such pipelines can be build using <code>locw</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">
lwplsr(X, Y,
    nlvdis, diss = c("eucl", "mahal"),
    h, k,
    nlv,
    cri = 4,
    verb = FALSE)

## S3 method for class 'Lwplsr'
predict(object, X, ..., nlv = NULL)  

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>— For the main function: Training X-data (<code class="reqn">n, p</code>). — For the auxiliary function: New X-data (<code class="reqn">m, p</code>) to consider.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>Training Y-data (<code class="reqn">n, q</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlvdis</code></td>
<td>
<p>The number of LVs to consider in the global PLS used for the dimension reduction before calculating the dissimilarities (see details). If <code>nlvdis = 0</code>, there is no dimension reduction.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>diss</code></td>
<td>
<p>The type of dissimilarity used for defining the neighbors. Possible values are "eucl" (default; Euclidean distance), "mahal" (Mahalanobis distance), or "correlation". Correlation dissimilarities are calculated by sqrt(.5 * (1 - rho)).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>h</code></td>
<td>
<p>A scale scalar defining the shape of the weight function. Lower is <code class="reqn">h</code>, sharper is the function. See <code>wdist</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>The number of nearest neighbors to select for each observation to predict.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlv</code></td>
<td>
<p>The number(s) of LVs to calculate in the local PLSR models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cri</code></td>
<td>
<p>Argument <code>cri</code> in function <code>wdist</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verb</code></td>
<td>
<p>Logical. If <code>TRUE</code>, fitting information are printed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>— For the auxiliary function: A fitted model, output of a call to the main function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>— For the auxiliary function: Optional arguments.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>- LWPLSR: This is a particular case of "weighted PLSR" (WPLSR) (e.g. Schaal et al. 2002). In WPLSR, a priori weights, different from the usual <code class="reqn">1/n</code> (standard PLSR), are given to the <code class="reqn">n</code> training observations. These weights are used for calculating (i) the PLS scores and loadings and (ii) the regression model of the response(s) over the scores (by weighted least squares). LWPLSR is a particular case of WPLSR. "L" comes from "localized": the weights are defined from dissimilarities (e.g. distances) between the new observation to predict and the training observations. By definition of LWPLSR, the weights, and therefore the fitted WPLSR model, change for each new observation to predict.
</p>
<p>- KNN-LWPLSR: Basic versions of LWPLSR (e.g. Sicard &amp; Sabatier 2006, Kim et al 2011) use, for each observation to predict, all the <code class="reqn">n</code> training observation. This can be very time consuming, in particular for large <code class="reqn">n</code>. A faster and often more efficient strategy is to preliminary select, in the training set, a number of <code class="reqn">k</code> nearest neighbors to the observation to predict (this is referred to as <code class="reqn">"weighting 1"</code> in function <code>locw</code>) and then to apply LWPLSR only to this pre-selected neighborhood (this is referred to as<code class="reqn">weighting "2"</code> in <code>locw</code>). This strategy corresponds to KNN-LWPLSR. 
</p>
<p>In function <code>lwplsr</code>, the dissimilarities used for computing the weights can be calculated from the original X-data or after a dimension reduction (argument <code>nlvdis</code>). In the last case, global PLS scores are computed from <code class="reqn">(X, Y)</code> and the dissimilarities are calculated on these scores. For high dimension X-data, the dimension reduction is in general required for using the Mahalanobis distance.   
</p>


<h3>Value</h3>

<p>For <code>lwplsr</code>: object of class <code>Lwplsr</code>
</p>
<p>For <code>predict.Lwplsr</code>: 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>prediction calculated for each observation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>listnn</code></td>
<td>
<p>list with the neighbors used for each observation to be predicted</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>listd</code></td>
<td>
<p>list with the distances to the neighbors used for each observation to be predicted</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>listw</code></td>
<td>
<p>list with the weights attributed to the neighbors used for each observation to be predicted</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Kim, S., Kano, M., Nakagawa, H., Hasebe, S., 2011. Estimation of active pharmaceutical ingredients content using locally weighted partial least squares and statistical wavelength selection. Int. J. Pharm., 421, 269-274.
</p>
<p>Lesnoff, M., Metz, M., Roger, J.-M., 2020. Comparison of locally weighted PLS strategies for regression and discrimination on agronomic NIR data. Journal of Chemometrics, e3209. https://doi.org/10.1002/cem.3209
</p>
<p>Schaal, S., Atkeson, C., Vijayamakumar, S. 2002. Scalable techniques from nonparametric statistics for the real time robot learning. Applied Intell., 17, 49-60.
</p>
<p>Sicard, E. Sabatier, R., 2006. Theoretical framework for local PLS1 regression and application to a rainfall data set. Comput. Stat. Data Anal., 51, 1393-1410.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
n &lt;- 30 ; p &lt;- 10
Xtrain &lt;- matrix(rnorm(n * p), ncol = p)
ytrain &lt;- rnorm(n)
Ytrain &lt;- cbind(ytrain, 100 * ytrain)
m &lt;- 4
Xtest &lt;- matrix(rnorm(m * p), ncol = p)
ytest &lt;- rnorm(m)
Ytest &lt;- cbind(ytest, 10 * ytest)

nlvdis &lt;- 5 ; diss &lt;- "mahal"
h &lt;- 2 ; k &lt;- 10
nlv &lt;- 2  
fm &lt;- lwplsr(
    Xtrain, Ytrain, 
    nlvdis = nlvdis, diss = diss,
    h = h, k = k,
    nlv = nlv)
res &lt;- predict(fm, Xtest)
names(res)
res$pred
msep(res$pred, Ytest)

res &lt;- predict(fm, Xtest, nlv = 0:2)
res$pred

</code></pre>


</div>