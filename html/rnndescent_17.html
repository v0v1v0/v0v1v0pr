<div class="container">

<table style="width: 100%;"><tr>
<td>rpf_filter</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Keep the best trees in a random projection forest</h2>

<h3>Description</h3>

<p>Reduce the size of a random projection forest, by scoring each tree against
a k-nearest neighbors graph. Only the top N trees will be retained which
allows for a faster querying.
</p>


<h3>Usage</h3>

<pre><code class="language-R">rpf_filter(nn, forest = NULL, n_trees = 1, n_threads = 0, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>nn</code></td>
<td>
<p>Nearest neighbor data in the dense list format. This should be
derived from the same data that was used to build the <code>forest</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>forest</code></td>
<td>
<p>A random partition forest, e.g. created by <code>rpf_build()</code>,
representing partitions of the same underlying data reflected in <code>nn</code>.
As a convenient, this parameter is ignored if the <code>nn</code> list contains a
<code>forest</code> entry, e.g. from running <code>rpf_knn()</code> or <code>nnd_knn()</code> with
<code>ret_forest = TRUE</code>, and the forest value will be extracted from <code>nn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_trees</code></td>
<td>
<p>The number of trees to retain. By default only the
best-scoring tree is retained.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_threads</code></td>
<td>
<p>Number of threads to use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>If <code>TRUE</code>, log information to the console.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Trees are scored based on how well each leaf reflects the neighbors as
specified in the nearest neighbor data. It's best to use as accurate nearest
neighbor data as you can and it does not need to come directly from
searching the <code>forest</code>: for example, the nearest neighbor data from running
<code>nnd_knn()</code> to optimize the neighbor data output from an RP Forest is a
good choice.
</p>
<p>Rather than rely on an RP Forest solely for approximate nearest neighbor
querying, it is probably more cost-effective to use a small number of trees
to initialize the neighbor list for use in a graph search via
<code>graph_knn_query()</code>.
</p>


<h3>Value</h3>

<p>A forest with the best scoring <code>n_trees</code> trees.
</p>


<h3>See Also</h3>

<p><code>rpf_build()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Build a knn with a forest of 10 trees using the odd rows
iris_odd &lt;- iris[seq_len(nrow(iris)) %% 2 == 1, ]
# also return the forest with the knn
rfknn &lt;- rpf_knn(iris_odd, k = 15, n_trees = 10, ret_forest = TRUE)

# keep the best 2 trees:
iris_odd_filtered_forest &lt;- rpf_filter(rfknn)

# get some new data to search
iris_even &lt;- iris[seq_len(nrow(iris)) %% 2 == 0, ]

# search with the filtered forest
iris_even_nn &lt;- rpf_knn_query(
  query = iris_even, reference = iris_odd,
  forest = iris_odd_filtered_forest, k = 15
)
</code></pre>


</div>