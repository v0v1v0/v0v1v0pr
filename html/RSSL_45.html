<div class="container">

<table style="width: 100%;"><tr>
<td>LearningCurveSSL</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compute Semi-Supervised Learning Curve</h2>

<h3>Description</h3>

<p>Evaluate semi-supervised classifiers for different amounts of unlabeled training examples or different fractions of unlabeled vs. labeled examples.
</p>


<h3>Usage</h3>

<pre><code class="language-R">LearningCurveSSL(X, y, ...)

## S3 method for class 'matrix'
LearningCurveSSL(X, y, classifiers, measures = list(Accuracy
  = measure_accuracy), type = "unlabeled", n_l = NULL,
  with_replacement = FALSE, sizes = 2^(1:8), n_test = 1000,
  repeats = 100, verbose = FALSE, n_min = 1, dataset_name = NULL,
  test_fraction = NULL, fracs = seq(0.1, 0.9, 0.1), time = TRUE,
  pre_scale = FALSE, pre_pca = FALSE, low_level_cores = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>design matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>vector of labels</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>arguments passed to underlying function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classifiers</code></td>
<td>
<p>list; Classifiers to crossvalidate</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>measures</code></td>
<td>
<p>named list of functions giving the measures to be used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>Type of learning curve, either "unlabeled" or "fraction"</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_l</code></td>
<td>
<p>Number of labeled objects to be used in the experiments (see details)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>with_replacement</code></td>
<td>
<p>Indicated whether the subsampling is done with replacement or not (default: FALSE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sizes</code></td>
<td>
<p>vector with number of unlabeled objects for which to evaluate performance</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_test</code></td>
<td>
<p>Number of test points if with_replacement is TRUE</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>repeats</code></td>
<td>
<p>Number of learning curves to draw</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Print progressbar during execution (default: FALSE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_min</code></td>
<td>
<p>Minimum number of labeled objects per class in</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataset_name</code></td>
<td>
<p>character; Name of the dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test_fraction</code></td>
<td>
<p>numeric; If not NULL a fraction of the object will be left out to serve as the test set</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fracs</code></td>
<td>
<p>list; fractions of labeled data to use</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>time</code></td>
<td>
<p>logical; Whether execution time should be saved.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pre_scale</code></td>
<td>
<p>logical; Whether the features should be scaled before the dataset is used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pre_pca</code></td>
<td>
<p>logical; Whether the features should be preprocessed using a PCA step</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>low_level_cores</code></td>
<td>
<p>integer; Number of cores to use compute repeats of the learning curve</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>classifiers</code> is a named list of classifiers, where each classifier should be a function that accepts 4 arguments: a numeric design matrix of the labeled objects, a factor of labels, a numeric design  matrix of unlabeled objects and a factor of labels for the unlabeled objects.
</p>
<p><code>measures</code> is a named list of performance measures. These are functions that accept seven arguments: a trained classifier, a numeric design matrix of the labeled objects, a factor of labels, a numeric design  matrix of unlabeled objects and a factor of labels for the unlabeled objects, a numeric design matrix of the test objects and a factor of labels of the test objects. See <code>measure_accuracy</code> for an example.
</p>
<p>This function allows for two different types of learning curves to be generated. If <code>type="unlabeled"</code>, the number of labeled objects remains fixed at the value of <code>n_l</code>, where <code>sizes</code> controls the number of unlabeled objects. <code>n_test</code> controls the number of objects used for the test set, while all remaining objects are used if <code>with_replacement=FALSE</code> in which case objects are drawn without replacement from the input dataset. We make sure each class is represented by at least <code>n_min</code> labeled objects of each class. For <code>n_l</code>, additional options include: "enough" which takes the max of the number of features and 20, max(ncol(X)+5,20), "d" which takes the number of features or "2d" which takes 2 times the number of features.
</p>
<p>If <code>type="fraction"</code> the total number of objects remains fixed, while the fraction of labeled objects is changed. <code>frac</code> sets the fractions of labeled objects that should be considered, while <code>test_fraction</code> determines the fraction of the total number of objects left out to serve as the test set.
</p>


<h3>Value</h3>

<p>LearningCurve object
</p>


<h3>See Also</h3>

<p>Other RSSL utilities: 
<code>SSLDataFrameToMatrices()</code>,
<code>add_missinglabels_mar()</code>,
<code>df_to_matrices()</code>,
<code>measure_accuracy()</code>,
<code>missing_labels()</code>,
<code>split_dataset_ssl()</code>,
<code>split_random()</code>,
<code>true_labels()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(1)
df &lt;- generate2ClassGaussian(2000,d=2,var=0.6)

classifiers &lt;- list("LS"=function(X,y,X_u,y_u) {
 LeastSquaresClassifier(X,y,lambda=0)}, 
  "Self"=function(X,y,X_u,y_u) {
    SelfLearning(X,y,X_u,LeastSquaresClassifier)}
)

measures &lt;- list("Accuracy" =  measure_accuracy,
                 "Loss Test" = measure_losstest,
                 "Loss labeled" = measure_losslab,
                 "Loss Lab+Unlab" = measure_losstrain
)

# These take a couple of seconds to run
## Not run: 
# Increase the number of unlabeled objects
lc1 &lt;- LearningCurveSSL(as.matrix(df[,1:2]),df$Class,
                        classifiers=classifiers,
                        measures=measures, n_test=1800,
                        n_l=10,repeats=3)

plot(lc1)

# Increase the fraction of labeled objects, example with 2 datasets
lc2 &lt;- LearningCurveSSL(X=list("Dataset 1"=as.matrix(df[,1:2]),
                               "Dataset 2"=as.matrix(df[,1:2])),
                        y=list("Dataset 1"=df$Class,
                               "Dataset 2"=df$Class),
                        classifiers=classifiers,
                        measures=measures,
                        type = "fraction",repeats=3,
                        test_fraction=0.9)

plot(lc2)

## End(Not run)
</code></pre>


</div>