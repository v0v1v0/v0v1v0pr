<div class="container">

<table style="width: 100%;"><tr>
<td>Universal.Kriging</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Universal Kriging</h2>

<h3>Description</h3>

<p>This functions fits the universal kriging model to the data.
</p>


<h3>Usage</h3>

<pre><code class="language-R">Universal.Kriging(
  X,
  y,
  basis.function,
  interpolation = TRUE,
  fit = TRUE,
  kernel = NULL,
  kernel.parameters = list(),
  nlopt.parameters = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>a matrix for input (feature)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a vector for output (target), only one-dimensional output is supported</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>basis.function</code></td>
<td>
<p>the basis functions for specifying the prior mean</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>interpolation</code></td>
<td>
<p>interpolation whether to interpolate, for noisy data please set <code>interpolate=FALSE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fit</code></td>
<td>
<p>whether to fit the length scale parameters from data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel</code></td>
<td>
<p>a kernel class object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel.parameters</code></td>
<td>
<p>a list of parameters required for the kernel, if no kernel class object is provided</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlopt.parameters</code></td>
<td>
<p>a list of parameters required for NLopt, including choice of optimization algorithm and maximum number of evaluation</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Universal kriging permits a more general function of mean, which can be specified using <code>basis.function</code>. 
Please see Santner et al. (2003) for details.
</p>
<p>For data from deterministic computer experiments, use <code>interpolation=TRUE</code> and will give an interpolator. 
For noisy data, use <code>interpolation=FALSE</code>, which will give an approximator of the underlying function.
</p>
<p>The kernel choices are required and can be specified by 
(i) providing the kernel class object to <code>kernel</code>
or (ii) specifying the kernel type and other parameters in <code>kernel.parameters</code>. 
Please see examples section of Fit.Kriging for detail usages. 
</p>
<p>When the lengthscale / correlation parameters are unknown, 
all parameters including the constant mean can be estimated via Maximum Likelihood method by setting <code>fit=TRUE</code>. 
The initial / lower bound / upper bound of the lengthscale parameters can be provided in <code>kernel.parameters</code>, 
otherwise a good initial and range would be estimated from the data. 
The optimization is performed via <a href="https://nlopt.readthedocs.io/en/latest/">NLopt</a>, 
a open-source library for nonlinear optimization. 
All gradient-free optimization methods in <a href="https://nlopt.readthedocs.io/en/latest/">NLopt</a> 
are supported and can be specified in <code>nlopt.parameters</code>.
See <code>nloptr::nloptr.print.options()</code> for the list of available derivative-free algorithms (prefix with NLOPT_GN or NLOPT_LN).  
The maximum number of optimization steps can also be defined in <code>nlopt.parameters</code>.
Please see examples section of Fit.Kriging for detail usages.
</p>


<h3>Value</h3>

<p>A Universal Kriging Class Object.
</p>


<h3>Author(s)</h3>

<p>Chaofan Huang and V. Roshan Joseph
</p>


<h3>References</h3>

<p>Santner, T. J., Williams, B. J., Notz, W. I., &amp; Williams, B. J. (2003). <em>The design and analysis of computer experiments (Vol. 1)</em>. New York: Springer.
</p>


<h3>See Also</h3>

<p>Fit.Kriging, Predict.Kriging, Get.Kriging.Parameters.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># one dimensional example 
f &lt;- function(x) {
  x &lt;- 0.5 + 2*x
  y &lt;- sin(10*pi*x)/(2*x) + (x-1)^4
  return (y)
}

set.seed(1234)
# train set
n &lt;- 30
p &lt;- 1
X &lt;- matrix(runif(n),ncol=p)
y &lt;- apply(X, 1, f)
newX &lt;- matrix(seq(0,1,length=1001), ncol=p)

basis.function &lt;- function(x) {c(1,x[1],x[1]^2)}

# approach 1
kriging &lt;- Universal.Kriging(X, y, basis.function=basis.function,
                             interpolation=TRUE, fit=TRUE, 
                             kernel.parameters=list(type="Gaussian"))
pred &lt;- Predict.Kriging(kriging, newX)
plot(newX, f(newX), "l")
points(X, y, pch=16, col="blue")
lines(newX, pred$mean, col="red", lty=2)
lines(newX, pred$mean-2*pred$sd, col="red", lty=3)
lines(newX, pred$mean+2*pred$sd, col="red", lty=3)
Get.Kriging.Parameters(kriging)

# approach 2
kriging &lt;- Fit.Kriging(X, y, interpolation=TRUE, fit=TRUE, model="UK",
                       model.parameters=list(basis.function=basis.function),
                       kernel.parameters=list(type="Gaussian"))
pred &lt;- Predict.Kriging(kriging, newX)
plot(newX, f(newX), "l")
points(X, y, pch=16, col="blue")
lines(newX, pred$mean, col="red", lty=2)
lines(newX, pred$mean-2*pred$sd, col="red", lty=3)
lines(newX, pred$mean+2*pred$sd, col="red", lty=3)
Get.Kriging.Parameters(kriging)
</code></pre>


</div>