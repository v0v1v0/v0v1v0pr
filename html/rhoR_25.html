<div class="container">

<table style="width: 100%;"><tr>
<td>rho</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Rho</h2>

<h3>Description</h3>

<p>This function calculates rho for a <code>testSet</code>, <code>contingencyTable</code>, or an observed kappa value with associated set parameters (testSetLength and OcSBaserate).
</p>


<h3>Usage</h3>

<pre><code class="language-R">rho(
  x,
  OcSBaserate = NULL,
  testSetLength = NULL,
  testSetBaserateInflation = 0,
  OcSLength = 10000,
  replicates = 800,
  ScSKappaThreshold = 0.9,
  ScSKappaMin = 0.4,
  ScSPrecisionMin = 0.6,
  ScSPrecisionMax = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>The observed kappa value, <code>testSet</code> or <code>contingencyTable</code> that will be tested with rho</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>OcSBaserate</code></td>
<td>
<p>The <code>baserate</code> of the observed <code>codeSet</code> (defaults to <code>baserate</code> of <code>testSet</code> or <code>contingencyTable</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>testSetLength</code></td>
<td>
<p>The length of the <code>testSet</code> (ignored unless <em>data</em> is an observed kappa value)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>testSetBaserateInflation</code></td>
<td>
<p>The minimum <code>baserate</code> from the sampling procedure</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>OcSLength</code></td>
<td>
<p>The length of the observed <code>codeSet</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>replicates</code></td>
<td>
<p>The number of simulated <code>codeSets</code> to use in the null hypothesis distribution for rho; similar to replicates in a Monte Carlo study</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ScSKappaThreshold</code></td>
<td>
<p>The maximum kappa value used to generate simulated <code>codeSets</code> in the null hypothesis distribution for rho</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ScSKappaMin</code></td>
<td>
<p>The minimum kappa value used to generate simulated <code>codeSets</code> in the null hypothesis distribution for rho</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ScSPrecisionMin</code></td>
<td>
<p>The minimum precision to be used for generation of simulated <code>codeSets</code> in the null hypothesis distribution for rho</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ScSPrecisionMax</code></td>
<td>
<p>The maximum precision to be used for generation of simulated <code>codeSets</code> in the null hypothesis distribution for rho</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Rho is a Monte Carlo rejective method of interrater reliability statistics, implemented here for Cohen's Kappa. Rho constructs a collection of data sets in which kappa is below a specified threshold, and computes the empirical distribution on kappa based on the specified sampling procedure. Rho returns the percent of the empirical distribution greater than or equal to an observed kappa. As a result, Rho quantifies the type 1 error in generalizing from an observed test set to a true value of agreement between two raters.
</p>
<p>Rho starts with an observed kappa value, calculated on a subset of a <code>codeSet</code>, known as an observed <code>testSet</code>, and a <em>kappa threshold</em> which indicates what is considered significant agreement between raters.
</p>
<p>It then generates a collection of fully-coded, simulated 
<code>codeSets</code> (ScS), further described in 
<code>createSimulatedCodeSet</code>, all of which have a kappa value below the kappa 
threshold and similar properties as the original <code>codeSet</code>.
</p>
<p>Then, kappa is calculated on a <code>testSet</code> sampled from each of the ScSs in the
collection to create a null hypothesis distribution. These <code>testSets</code> mirror the observed <code>testSets</code> in their size and sampling method.  How these <code>testSets</code> are sampled is futher described in <code>getTestSet</code>.
</p>
<p>The null hypothesis is that the observed <code>testSet</code>, was sampled from a data set, which, if both raters were to code in its entirety, would result in a level of agreement below the kappa threshold.
</p>
<p>For example, using an alpha level of 0.05, if the observed kappa is greater than 95 percent of the kappas in the null hypothesis distribution, the null hypothesis is rejected. Then one can conclude that the two raters would have acceptable agreement had they coded the entire data set.
</p>


<h3>Value</h3>

<p>rho for the given parameters
</p>
<p>rho and kappa for the given data and parameters (unless kappa is given)
</p>


<h3>See Also</h3>

<p><code>rho</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Given an observed kappa value
rho(x = 0.88, OcSBaserate = 0.2, testSetLength = 80)

# Given a test Set
rho(x = codeSet)

# Given a contingency Table
rho(x = contingencyTable)

</code></pre>


</div>