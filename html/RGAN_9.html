<div class="container">

<table style="width: 100%;"><tr>
<td>gan_update_step</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>gan_update_step</h2>

<h3>Description</h3>

<p>Provides a function to send the output of a DataTransformer to
a torch tensor, so that it can be accessed during GAN training.
</p>


<h3>Usage</h3>

<pre><code class="language-R">gan_update_step(
  data,
  batch_size,
  noise_dim,
  sample_noise,
  device = "cpu",
  g_net,
  d_net,
  g_optim,
  d_optim,
  value_function,
  weight_clipper
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>Input a data set. Needs to be a matrix, array, torch::torch_tensor or torch::dataset.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>batch_size</code></td>
<td>
<p>The number of training samples selected into the mini batch for training. Defaults to 50.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>noise_dim</code></td>
<td>
<p>The dimensions of the GAN noise vector z. Defaults to 2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sample_noise</code></td>
<td>
<p>A function to sample noise to a torch::tensor</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>device</code></td>
<td>
<p>Input on which device (e.g. "cpu" or "cuda") training should be done. Defaults to "cpu".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>g_net</code></td>
<td>
<p>The generator network. Expects a neural network provided as torch::nn_module. Default is NULL which will create a simple fully connected neural network.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>d_net</code></td>
<td>
<p>The discriminator network. Expects a neural network provided as torch::nn_module. Default is NULL which will create a simple fully connected neural network.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>g_optim</code></td>
<td>
<p>The optimizer for the generator network. Expects a torch::optim_xxx function, e.g. torch::optim_adam(). Default is NULL which will setup <code>torch::optim_adam(g_net$parameters, lr = base_lr)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>d_optim</code></td>
<td>
<p>The optimizer for the generator network. Expects a torch::optim_xxx function, e.g. torch::optim_adam(). Default is NULL which will setup <code>torch::optim_adam(g_net$parameters, lr = base_lr * ttur_factor)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>value_function</code></td>
<td>
<p>The value function for GAN training. Expects a function that takes discriminator scores of real and fake data as input and returns a list with the discriminator loss and generator loss. For reference see: . For convenience three loss functions "original", "wasserstein" and "f-wgan" are already implemented. Defaults to "original".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weight_clipper</code></td>
<td>
<p>The wasserstein GAN puts some constraints on the weights of the discriminator, therefore weights are clipped during training.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A function
</p>


</div>