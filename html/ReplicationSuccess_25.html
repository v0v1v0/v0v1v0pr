<div class="container">

<table style="width: 100%;"><tr>
<td>sampleSizeReplicationSuccess</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Computes the required relative sample size to achieve replication success
with the sceptical p-value</h2>

<h3>Description</h3>

<p>The relative sample size to achieve replication success is computed based on
the z-value of the original study,  the type of
recalibration, the power and the design prior.
</p>


<h3>Usage</h3>

<pre><code class="language-R">sampleSizeReplicationSuccess(
  zo,
  power = NA,
  level = 0.025,
  alternative = c("one.sided", "two.sided"),
  type = c("golden", "nominal", "controlled"),
  designPrior = c("conditional", "predictive", "EB"),
  shrinkage = 0,
  h = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>zo</code></td>
<td>
<p>Numeric vector of z-values from original studies.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>power</code></td>
<td>
<p>The power to achieve replication success.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>level</code></td>
<td>
<p>Threshold for the calibrated sceptical p-value.
Default is 0.025.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>
<p>Specifies if <code>level</code> is "one.sided" (default) or
"two.sided". If "one.sided" then sample size calculations are based
on a one-sided assessment of replication success in the direction of the
original effect estimates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>Type of recalibration. Can be either "golden" (default),
"nominal" (no recalibration), or "controlled". "golden" ensures that for
an original study just significant at the specified <code>level</code>,
replication success is only possible for replication effect estimates
larger than the original one. "controlled" ensures exact overall Type-I
error control at level <code>level</code>^2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>designPrior</code></td>
<td>
<p>Is only taken into account when <code>power</code> is specified.
Either "conditional" (default), "predictive", or "EB". If "EB", the power
is computed under a predictive distribution where the contribution of the
original study is shrunken towards zero based on the evidence in the
original study (with an empirical Bayes shrinkage estimator).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>shrinkage</code></td>
<td>
<p>Is only taken into account when <code>power</code> is specified. A
number in [0,1) with default 0. Specifies the shrinkage of the original
effect estimate towards zero (e.g., the effect is shrunken by a factor of
25% for <code>shrinkage = 0.25</code>). Is only taken into account when the
<code>designPrior</code> is "conditional" or "predictive".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>h</code></td>
<td>
<p>Is only taken into account when <code>power</code> is specified and
<code>designPrior</code> is "predictive" or "EB". The relative between-study
heterogeneity, i.e., the ratio of the heterogeneity variance to the
variance of the original effect estimate. Default is 0 (no
heterogeneity).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>sampleSizeReplicationSuccess</code> is the vectorized version of
the internal function <code>.sampleSizeReplicationSuccess_</code>.
<code>Vectorize</code> is used to vectorize the function.
</p>


<h3>Value</h3>

<p>The relative sample size for replication success. If impossible to
achieve the desired power for specified inputs <code>NaN</code> is returned.
</p>


<h3>Author(s)</h3>

<p>Leonhard Held, Charlotte Micheloud, Samuel Pawel, Florian Gerber
</p>


<h3>References</h3>

<p>Held, L. (2020). A new standard for the analysis and design of replication
studies (with discussion). <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <b>183</b>, 431-448.
<a href="https://doi.org/10.1111/rssa.12493">doi:10.1111/rssa.12493</a>
</p>
<p>Held, L., Micheloud, C., Pawel, S. (2022). The assessment of replication
success based on relative effect size. <em>The Annals of Applied
Statistics</em>. 16:706-720. <a href="https://doi.org/10.1214/21-AOAS1502">doi:10.1214/21-AOAS1502</a>
</p>
<p>Micheloud, C., Balabdaoui, F., Held, L. (2023). Assessing replicability
with the sceptical p-value: Type-I error control and
sample size planning. <em>Statistica Neerlandica</em>. <a href="https://doi.org/10.1111/stan.12312">doi:10.1111/stan.12312</a>
</p>


<h3>See Also</h3>

<p><code>pSceptical</code>, <code>powerReplicationSuccess</code>,
<code>levelSceptical</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## based on power
sampleSizeReplicationSuccess(zo = p2z(0.0025), power = 0.8, level = 0.025,
                             type = "golden")
sampleSizeReplicationSuccess(zo = p2z(0.0025), power = 0.8, level = 0.025,
                             type = "golden", designPrior = "predictive")
</code></pre>


</div>