<div class="container">

<table style="width: 100%;"><tr>
<td>indeptest</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Robust independence test for two continuous variables of Kolmogorov-Smirnov's type</h2>

<h3>Description</h3>

<p>Test the independence between two continuous variables based on the maximum distance
between the joint empirical cumulative distribution function and the product of the marginal
empirical cumulative distribution functions.
</p>


<h3>Usage</h3>

<pre><code class="language-R">indeptest(
  x,
  y,
  N = 50000,
  simu = FALSE,
  ties.break = "none",
  nb_tiebreak = 100
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x, y</code></td>
<td>
<p>the two continuous variables. Must be of same length.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>N</code></td>
<td>
<p>the number of Monte-Carlo replications if simu=TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>simu</code></td>
<td>
<p>if TRUE a Monte-Carlo simulation with <code>N</code> replications is used to determine the
distribution of the test statistic under the null hypothesis. If FALSE, pre computed tables are used (see Details
for more information).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ties.break</code></td>
<td>
<p>the method used to break ties in case there are ties in the x or y vectors. Can be <code>"none"</code>,
<code>"random"</code> or <code>"rep_random"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nb_tiebreak</code></td>
<td>
<p>the number of repetition for breaking the ties when <code>ties.break="rep_random"</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>For two continuous variables, <code>indeptest</code> tests H0 X and Y are independent
against H1 X and Y are not independent.
</p>
<p>For observations (x1,y1), ..., (x_n,y_n), the bivariate e.c.d.f.
(empirical cumulative distribution function) Fn is defined as:
</p>
<p style="text-align: center;"><code class="reqn">Fn(t1,t2) = sum_{i=1}^n Indicator(xi&lt;=t1,yi&lt;=t2)/n.</code>
</p>

<p>Let Fn(t1) and Fn(t2) be the marginals e.c.d.f. The test statistic is defined as:
</p>
<p style="text-align: center;"><code class="reqn">n^(1/2) sup_{t1,t2} |Fn(t1,t2)-Fn(t1)*Fn(t2)|.</code>
</p>

<p>Under H0 the test statistic is distribution free and is equivalent to
the same test statistic computed for two independent continuous uniform variables in <code class="reqn">[0,1]</code>,
where the supremum is taken for t1,t2 in <code class="reqn">[0,1]</code>. Using this result, the distribution of the test
statistic is obtained using Monte-Carlo simulations. The user can either use the argument simu=TRUE to
perform the Monte-Carlo simulation (with N the number of replications) or simply use the available tables
by choosing simu=FALSE. In the latter case, the exact distribution is estimated for n=1, ...,150. For <code class="reqn">151&lt;=n&lt;=175</code>, the
distribution with n=150 is used. For <code class="reqn">176&lt;=n&lt;=250</code>, the distribution with n=200 is used.
For <code class="reqn">251&lt;=n&lt;=400</code>, the distribution with n=300 is used. For <code class="reqn">401&lt;=n&lt;=750</code>, the distribution with n=500 is used.
For <code class="reqn">n&gt;=751</code>, the distribution with n=1000 is used. Those tables were computed using 2e^5 replications in Monte-Carlo simulations.
</p>


<h3>Value</h3>

<p>Returns the result of the test with its corresponding p-value and the value of the test statistic.
</p>


<h3>Note</h3>

<p>Only a two sided alternative is possible with this test. Missing values are removed such that if a value
of <code>x</code> (resp. <code>y</code>) is missing then the corresponding
values of both <code>x</code> and <code>y</code> are removed. The test is then implemented on the remaining elements. If <code>ties.break="none"</code> the ties are ignored, putting
mass (number of ties)/n at tied observations in the computation of the empirical cumulative distribution functions.
If <code>ties.break="random"</code> they are randomly broken. If <code>ties.break="rep_random"</code> they are randomly broken <code>nb_tiebreak</code>
times where <code>nb_tiebreak</code> is a parameter of the function. In that case, the test statistic and the p values are computed by taking
the average over all replications.
</p>
<p>This function is implemented using the Rcpp package.
</p>


<h3>Author(s)</h3>

<p>See <em>Distribution Free Tests of Independence Based on the Sample Distribution Function</em>.
J. R. Blum, J. Kiefer and M. Rosenblatt, 1961.
</p>


<h3>See Also</h3>

<p><code>cortest</code>, <code>vartest</code>, <code>mediantest</code>, <code>wilcoxtest</code>.
See also the <code>hoeffd</code> function in the <code>Hmisc</code> package for the Hoeffding test.
</p>


<h3>Examples</h3>

<pre><code class="language-R">#Simulated data 1
x&lt;-c(0.2, 0.3, 0.1, 0.4)
y&lt;-c(0.5, 0.4, 0.05, 0.2)
indeptest(x,y)

#Simulated data 2
n&lt;-40 #sample size
x&lt;-rnorm(n)
y&lt;-x^2+0.3*rnorm(n)
plot(x,y)
indeptest(x,y)

#Application on the Evans dataset
#Description of this dataset is available in the lbreg package
data(Evans)
with(Evans,plot(CHL[CDH==1],DBP[CDH==1]))
with(Evans,cor.test(CHL[CDH==1],DBP[CDH==1])) #the standard Pearson test
with(Evans,cortest(CHL[CDH==1],DBP[CDH==1])) #the robust Pearson test
with(Evans,indeptest(CHL[CDH==1],DBP[CDH==1])) #the robust independence test
#The robust tests give very different pvalues than the standard Pearson test!

#Breaking the ties
#The ties are broken once
with(Evans,indeptest(CHL[CDH==1],DBP[CDH==1],ties.break="random"))
#The ties are broken repeatedly and the average of the test statistics and p.values
#are computed
with(Evans,indeptest(CHL[CDH==1],DBP[CDH==1],ties.break="rep_random",nb_tiebreak=100))
</code></pre>


</div>