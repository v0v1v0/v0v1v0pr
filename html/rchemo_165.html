<div class="container">

<table style="width: 100%;"><tr>
<td>selwold</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Heuristic selection of the dimension of a latent variable model with the Wold's criterion</h2>

<h3>Description</h3>

<p>The function helps selecting the dimensionnality of latent variable (LV) models (e.g. PLSR) using the "Wold criterion". 
</p>
<p>The criterion is the "precision gain ratio" <code class="reqn">R = 1 - r(a+1) / r(a)</code> where <code class="reqn">r</code> is an observed error rate quantifying the model performance (msep, classification error rate, etc.) and <code class="reqn">a</code> the model dimensionnality (= nb. LVs). It can also represent other indicators such as the eigenvalues of a PCA.
</p>
<p><code class="reqn">R</code> is the relative gain in efficiency after a new LV is added to the model. The iterations continue until <code class="reqn">R</code> becomes lower than a threshold value <code class="reqn">alpha</code>. By default and only as an indication, the default <code class="reqn">alpha = .05</code> is set in the function, but the user should set any other value depending on his data and parcimony objective.
</p>
<p>In the original article, Wold (1978; see also Bro et al. 2008) used the ratio of <b>cross-validated</b> over <b>training</b> residual sums of squares, i.e. PRESS over SSR. Instead, <code>selwold</code> compares values of consistent nature (the successive values in the input vector <code class="reqn">r</code>), e.g. PRESS only . For instance, <code class="reqn">r</code> was set to PRESS values in Li et al. (2002) and Andries et al. (2011), which is equivalent to the "punish factor" described in Westad &amp; Martens (2000).
</p>
<p>The ratio <code class="reqn">R</code> is often erratic, making difficult the dimensionnaly selection. Function <code>selwold</code> proposes to calculate a smoothing of <code class="reqn">R</code> (argument <code class="reqn">smooth</code>).
</p>


<h3>Usage</h3>

<pre><code class="language-R">selwold(
    r, indx = seq(length(r)), 
    smooth = TRUE, f = 1/3,
    alpha = .05, digits = 3,
    plot = TRUE,
    xlab = "Index", ylab = "Value", main = "r",
    ...
    )
  </code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>r</code></td>
<td>
<p>Vector of a given error rate (<code class="reqn">n</code>) or any other indicator.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>indx</code></td>
<td>
<p>Vector of indexes (<code class="reqn">n</code>), typically the nb. of Lvs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>smooth</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default), the selection is done on the smoothed <code class="reqn">R</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f</code></td>
<td>
<p>Window for smoothing <code class="reqn">R</code> with function <code>lowess</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>Proportion <code class="reqn">alpha</code> used as threshold for <code class="reqn">R</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>
<p>Number of digits for <code class="reqn">R</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default), results are plotted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xlab</code></td>
<td>
<p>x-axis label of the plot of <code class="reqn">r</code> (left-side in the graphic window).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ylab</code></td>
<td>
<p>y-axis label of the plot of <code class="reqn">r</code> (left-side in the graphic window).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>main</code></td>
<td>
<p>Title of the plot of <code class="reqn">r</code> (left-side in the graphic window).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Other arguments to pass in function <code>lowess</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>res</code></td>
<td>
<p>matrix with for each number of Lvs: <code class="reqn">r</code>, the observed error rate quantifying the model performance; <code class="reqn">diff</code>, the difference between <code class="reqn">r(a+1)</code> and <code class="reqn">r(a)</code> ; <code class="reqn">R</code>, the relative gain in efficiency after a new LV is added to the model; <code class="reqn">Rs</code>, smoothing of <code class="reqn">R</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>opt</code></td>
<td>
<p>The index of the minimum for <code class="reqn">r</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sel</code></td>
<td>
<p>The index of the selection from the <code class="reqn">R</code> (or smoothed <code class="reqn">R</code>) threshold.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Andries, J.P.M., Vander Heyden, Y., Buydens, L.M.C., 2011. Improved variable reduction in partial least squares modelling based on Predictive-Property-Ranked Variables and adaptation of partial least squares complexity. Analytica Chimica Acta 705, 292-305. https://doi.org/10.1016/j.aca.2011.06.037
</p>
<p>Bro, R., Kjeldahl, K., Smilde, A.K., Kiers, H.A.L., 2008. Cross-validation of component models: A critical look at current methods. Anal Bioanal Chem 390, 1241-1251. https://doi.org/10.1007/s00216-007-1790-1
</p>
<p>Li, B., Morris, J., Martin, E.B., 2002. Model selection for partial least squares regression. Chemometrics and Intelligent Laboratory Systems 64, 79-89. https://doi.org/10.1016/S0169-7439(02)00051-5
</p>
<p>Westad, F., Martens, H., 2000. Variable Selection in near Infrared Spectroscopy Based on Significance Testing in Partial Least Squares Regression. J. Near Infrared Spectrosc., JNIRS 8, 117-124.
</p>
<p>Wold S. Cross-Validatory Estimation of the Number of Components in Factor and Principal Components Models. Technometrics. 1978;20(4):397-405
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(cassav)

Xtrain &lt;- cassav$Xtrain
ytrain &lt;- cassav$ytrain
X &lt;- cassav$Xtest
y &lt;- cassav$ytest

nlv &lt;- 20
res &lt;- gridscorelv(
    Xtrain, ytrain, X, y, 
    score = msep, fun = plskern, 
    nlv = 0:nlv
    )
selwold(res$y1, res$nlv, f = 2/3)

</code></pre>


</div>