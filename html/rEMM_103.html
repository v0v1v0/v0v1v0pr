<div class="container">

<table style="width: 100%;"><tr>
<td>score</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Score a New Sequence Given an EMM</h2>

<h3>Description</h3>

<p>Calculates a score of how likely it is that a new sequence was generated
by the same process as the sequences used to build the EMM.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S4 method for signature 'EMM,matrix'
score(x, newdata, method = c("product", "log_sum", "sum",
        "log_odds", "supported_transitions", "supported_states",
        "sum_transitions",  "log_loss", "likelihood", "log_likelihood", "AIC"),
        match_cluster = "exact", random = FALSE, prior = TRUE, normalize = TRUE,
        initial_transition = FALSE, threshold = NA)
## S4 method for signature 'EMM,EMM'
score(x, newdata, method = c("product", "log_sum", "sum",
        "supported_transitions"), match_cluster = "exact", random = FALSE, prior = TRUE,
        initial_transition = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p> an <code>EMM</code> object. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newdata</code></td>
<td>
<p> sequence or another <code>EMM</code> object to score. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p> method to calculate the score (see details) </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>match_cluster</code></td>
<td>
<p> do the new observations have to fall within
the threshold of the cluster (<code>"exact"</code>) or is nearest neighbor
(<code>"nn"</code>) or weighted nearest neighbor (<code>weighted</code>) used?
If <code>match_cluster</code> is a number n then observations
need to fall within n times the clustering threshold of the cluster.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>random</code></td>
<td>
<p> logical; should the order of newdata be randomized? Can be used to compare the score with the
actual score. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>
<p> logical; add one to each transition count. This is equal
to start with a count of one  for each transition, i.e. initially all
transitions are equally likely. It prevents the product
of probabilities to be zero if a transition was never observed. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>normalize</code></td>
<td>
<p>logical; normalize the score by the length of the sequence.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initial_transition</code></td>
<td>
<p> logical; include the initial transition
in the computation?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threshold</code></td>
<td>
<p> minimum count threshold used by supported transitions and supported states.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The scores for a new sequence <code class="reqn">x</code> of length <code class="reqn">l</code> can be computed
by the following methods. For <code>match_cluster="exact"</code> or <code>"nn"</code>:
</p>

<dl>
<dt>"product"</dt>
<dd>
<p>Product of transition probabilities along the path of <code class="reqn">x</code> in the
model. A single missing transition (transition probability of zero)
will result in
a score of 0. Use <code>prior</code> to avoid this.
</p>
<p style="text-align: center;"><code class="reqn">S_\mathrm{product} = \sqrt[l-1]{\prod_{i=1}^{l-1}{a_{s(i),s(i+1)}}}</code>
</p>

<p>where <code class="reqn">a_{s(i),s(j)}</code> is the transition probability
between the state representing positions <code class="reqn">i</code> and <code class="reqn">j</code> in the sequence.
</p>
</dd>
<dt>"sum"</dt>
<dd>
<p>Average of transition probabilities along the path of <code class="reqn">x</code> in the
model.
</p>
<p style="text-align: center;"><code class="reqn">S_\mathrm{sum} = \frac{1}{l-1} \sum_{i=1}^{l-1}{a_{s(i),s(i+1)}}</code>
</p>

</dd>
<dt>"log_sum"</dt>
<dd>
<p>Average of the log of the transition probabilities along the path of
<code class="reqn">x</code> in the model. The ranking of the scores is equivalent to
the product of probabilities, however, the calculation is more reliable
since the product of probabilities might become a very small number.
</p>
<p>A single missing transition (transition probability of zero)
will result in a score of neg. infinity.
Use <code>prior</code> to avoid this.
</p>
<p style="text-align: center;"><code class="reqn">S_\mathrm{log\_sum} = \frac{1}{l-1} \sum_{i=1}^{l-1}{\mathrm{log}(a_{s(i),s(i+1)})}</code>
</p>

</dd>
<dt>"supported_transitions"</dt>
<dd>
<p>Fraction of transitions in the new sequence <code class="reqn">x</code> supported (present) in the model after assigning each data point in <code class="reqn">x</code> to a state in
the model.
</p>
<p style="text-align: center;"><code class="reqn">S_\mathrm{supported\_transitions} = \frac{1}{l-1} \sum_{i=1}^{l-1}{\mathrm{I}(a_{s(i),s(i+1)})}</code>
</p>

</dd>
<dt>"supported_states"</dt>
<dd>
<p>Fraction of points in the new sequence <code class="reqn">x</code>
for which a state (cluster) exists in the model. <code>match_cluster</code>
is always <code>"exact"</code> because for <code>"nn"</code> this measure would
always give 1. Note that this measure ignores transition information.
</p>
<p>If threshold is given, then only states with a count greater than the given threshold are counted as supported.
</p>
</dd>
<dt>"sum_transitions"</dt>
<dd>
<p>Sum of the counts on the edges in the model on the path of sequence <code class="reqn">x</code> normalized by the total number of transition counts in the model.
</p>
<p style="text-align: center;"><code class="reqn">S_\mathrm{sum\_transitions} = \frac{1}{l-1} \sum_{i=1}^{l-1}c_{s(i),s(i+1)}</code>
</p>

<p>where <code class="reqn">c_{s(i),s(i+1)}</code> is the transition count  between the state representing positions <code class="reqn">i</code> and <code class="reqn">j</code> in the sequence.
</p>
<p>If threshold is given, then only transitions with a count greater than the given threshold are counted as supported.
</p>
</dd>
<dt>"likelihood", "log_likelihood"</dt>
<dd>
<p> The likelihood of the model given the new data is the
unnormalized product score (product of transition probabilities).</p>
</dd>
<dt>"log_loss"</dt>
<dd>
<p> The average log loss is defined as
</p>
<p style="text-align: center;"><code class="reqn">-sum(log2(a_s(i),s(i+1)))/(l-1)</code>
</p>

<p>It represents the average compression rate of the new sequence
given the model.
</p>
</dd>
<dt>"AIC"</dt>
<dd>
<p> Akaike Information Criterion corrected for finite sample size.
</p>
<p style="text-align: center;"><code class="reqn">2k - 2log(L) 2k(k-1)/(n-k-1)</code>
</p>

<p>where <code class="reqn">n=l-1</code> and <code class="reqn">k</code> is the model complexity measured by the number of
non-zero entries in the transition matrix.
We use the likelihood of the model given by the proportion
of supported transitions. AIC can be used for model selection
where the smallest value indicates the preferred model.
</p>
</dd>
</dl>
<p>where
<code class="reqn">x_i</code> represents the <code class="reqn">i</code>-th data point in the new sequence,
<code class="reqn">a(i,j)</code> is the transition probability from state <code class="reqn">i</code>
to state <code class="reqn">j</code> in the model,
<code class="reqn">s(i)</code> is the state the <code class="reqn">i</code>-th data point (<code class="reqn">x_i</code>) in
the new sequence is assigned to.
<code class="reqn">\mathrm{I(v)}</code> is an indicator function which is 0 for <code class="reqn">v=0</code> and 1 otherwise.
</p>
<p>For <code>match_cluster="weighted"</code>:
</p>

<dl>
<dt>"product"</dt>
<dd>
<p>Weighted version of the product of probabilities. The weight is
the  similarity between a new data point and the state in the model
it is assigned to.
</p>
<p style="text-align: center;"><code class="reqn">S_\mathrm{weighted\_product} = \sqrt[l-1]{\prod_{i=1}^{l-1}{\mathrm{simil}(x_i,s(i))\mathrm{simil}(x_i,s(i+1))  a_{s(i),s(i+1)}}}</code>
</p>

</dd>
<dt>"sum"</dt>
<dd>
<p>Weighted version of the sum of probabilities.
</p>
<p style="text-align: center;"><code class="reqn">S_\mathrm{weighted\_sum} = \frac{1}{l-1} \sum_{i=1}^{l-1}{\mathrm{simil}(x_i,s(i))\mathrm{simil}(x_i,s(i+1))  a_{s(i),s(i+1)}}</code>
</p>

</dd>
<dt>"log_sum"</dt>
<dd>
<p>Weighted version of the sum of the log of probabilities.
</p>
<p style="text-align: center;"><code class="reqn">S_\mathrm{weighted\_log\_sum} = \frac{1}{l-1} \sum_{i=1}^{l-1}{\mathrm{log}(\mathrm{simil}(x_i,s(i))\mathrm{simil}(x_i,s(i+1))  a_{s(i),s(i+1)})}</code>
</p>

</dd>
<dt>"supported_states"</dt>
<dd>
<p>Same as <code>"supported_states"</code> but instead of counting the
supported states, the similarity <code class="reqn">\mathrm{simil}(x_i,s(i))</code>
is used as a weight. Threshold is not implemented.
</p>
</dd>
</dl>
<p>where <code class="reqn">\mathrm{simil}(\cdot)</code> is a modified and normalized
similarity function given by
<code class="reqn">\mathrm{simil}(x,s) =  1- \frac{1}{1+e^{-\frac{\mathrm{d}(x, s)/t -1.5}{.2}}}</code>
where <code class="reqn">d</code> is the distance measure and <code class="reqn">t</code> is the threshold that
was used to create the model.
</p>


<h3>Value</h3>

<p>A scalar score value.
</p>


<h3>See Also</h3>

<p><code>transition</code> to access transition probabilities
and <code>find_clusters</code> for assigning observations to states/clusters. </p>


<h3>Examples</h3>

<pre><code class="language-R">data("EMMsim")

emm &lt;- EMM(threshold = .2)
emm &lt;- build(emm, EMMsim_train)

# default is method "product". The score is much higher compared to a randomized order.
score(emm, EMMsim_test)
score(emm, EMMsim_test, random = TRUE)


### create shuffled data (destroy temporal relationship)
### and create noisy data
test_shuffled &lt;- EMMsim_test[sample(1:nrow(EMMsim_test)), ]
test_noise &lt;- jitter(EMMsim_test, amount = .3)

### helper for plotting
mybars &lt;- function(...) {
  oldpar &lt;- par(mar = c(5, 10, 4, 2))
  ss &lt;- rbind(...)
  barplot(
    ss[, ncol(ss):1],
    xlim = c(-1, 4),
    beside = TRUE,
    horiz = TRUE,
    las = 2,
    legend = rownames(ss)
  )
  par(oldpar)
}


### compare various scores
methods &lt;- c(
  "product",
  "sum",
  "log_sum",
  "supported_states",
  "supported_transitions",
  "sum_transitions",
  "log_loss",
  "likelihood"
)

### default is exact matching
clean &lt;-
  sapply(
    methods,
    FUN = function(m)
      score(emm, EMMsim_test, method = m)
  )

shuffled &lt;-
  sapply(
    methods,
    FUN = function(m)
      score(emm, test_shuffled, method = m)
  )

noise &lt;-
  sapply(
    methods,
    FUN = function(m)
      score(emm, test_noise, method = m)
  )

mybars(shuffled, noise, clean)

### weighted matching is better for noisy data
clean &lt;-
  sapply(
    methods,
    FUN = function(m)
      score(emm, EMMsim_test, method = m,
        match = "weighted")
  )

shuffled &lt;-
  sapply(
    methods,
    FUN = function(m)
      score(emm, test_shuffled, method = m,
        match = "weighted")
  )

noise &lt;-
  sapply(
    methods,
    FUN = function(m)
      score(emm, test_noise, method = m,
        match = "weighted")
  )

mybars(shuffled, noise, clean)
</code></pre>


</div>