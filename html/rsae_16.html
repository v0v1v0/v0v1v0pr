<div class="container">

<table style="width: 100%;"><tr>
<td>fitsaemodel</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fitting SAE Models</h2>

<h3>Description</h3>

<p><code>fitsaemodel</code> fits SAE models that have been specified by
<code>saemodel()</code> (or synthetic data generated by
<code>makedata()</code>) for various (robust) estimation
methods.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fitsaemodel(method, model, ...)
convergence(object)

## S3 method for class 'fit_model_b'
print(x, digits = max(3L, getOption("digits") - 3L),
    ...)
## S3 method for class 'summary_fit_model_b'
print(x, digits = max(3L, getOption("digits")
    - 3L), ...)
## S3 method for class 'fit_model_b'
summary(object, ...)
## S3 method for class 'fit_model_b'
coef(object, type = "both", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p><code>[character]</code> estimation method; <code>method = "ml"</code>
for (non-robust) maximum likelihood or <code>method = "huberm"</code>
for Huber-type M-estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>an object of class <code>"saemodel"</code>, i.e., a SAE model;
see <code>saemodel()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>
<p><code>[integer]</code> number of digits printed by the
<code>print()</code> and <code>summary()</code> methods.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>an object of class <code>"fit_model_b"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>an object of class <code>"fit_model_b"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p><code>[character]</code> name of the effects to be extracted
by the <code>coef</code> method; it can take one of the
following possibilities: <code>"both"</code> (extracts fixed and random
effects; default), <code>"ranef"</code> (only random effects), or
<code>"fixef"</code> (only fixed effects).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments passed on to
<code>fitsaemodel.control()</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Function <code>fitsaemodel()</code> computes the following estimators:
</p>

<ul>
<li>
<p> maximum likelihood (ML): <code>method = "ml"</code>,
</p>
</li>
<li>
<p> Huber-type M-estimation: <code>method = "huberm"</code>; this
method is called RML II by Richardson and Welsh (1995); see
Schoch (2012)
</p>
</li>
</ul>
<h4>Maximum likelihood</h4>

<p>The ML is <b>not</b> robust against outliers.
</p>



<h4>Huber-type M-estimation</h4>

<p>The call for the Huber-type M-estimator (with Huber psi-function) is:
<code>fitsaemodel(method = "huberm", model, k)</code>, where <code>k</code> is
the robustness tuning constant of the Huber psi-function,
<code class="reqn">k \in (0, \infty]</code>.
</p>
<p>By default, the computation of the M-estimator is initialized by a
robust estimate that derives from a fixed-effects model (centered by
the median instead of the mean); see Schoch (2012) for the details.
</p>
<p>If the data are supposed to be heavily contaminated (<b>or</b> if the
<b>default algorithm did not converge</b>), one may try to initialize
the algorithm underlying <code>fitsaemodel()</code> by a high breakdown-point
estimate. The package offers two initialization methods:
<b>NOTE:</b> the <span class="pkg">robustbase</span> package (Maechler et al., 2022)
must be installed to use this functionality.
</p>

<ul>
<li> <p><code>init = "lts"</code>: least trimmed squares (LTS)
regression from <span class="pkg">robustbase</span>; see
ltsReg() and Rousseeuw and Van
Driessen (2006),
</p>
</li>
<li> <p><code>init = "s"</code>: regression S-estimator from
<span class="pkg">robustbase</span>; see lmrob() and
Maronna et al. (2019).
</p>
</li>
</ul>
<p>For small and medium size datasets, both methods are equivalent in
terms of computation time. For large data, the S-estimator is
considerably faster.
</p>



<h4>Implementation</h4>

<p>The methods are computed by (nested) iteratively re-weighted least
squares and a derivative of Richard Brent's <code>zeroin</code> algorithm;
see Brent (2013, Chapter 4). The functions depend on the subroutines in
BLAS (Blackford et al., 2002) and LAPACK (Anderson et al., 2000); see
Schoch (2012).
</p>



<h3>Value</h3>

<p>An instance of the class <code>"fitmodel"</code>
</p>


<h3>References</h3>

<p>Anderson, E., Bai, Z., Bischof, C., Blackford, L. S., Demmel, J., Dongarra,
J., et al. (2000). <em>LAPACK users' guide</em> (3rd ed.). Philadelphia:
Society for Industrial and Applied Mathematics (SIAM).
</p>
<p>Blackford, L.S., Petitet, A., Pozo, R., Remington, K., Whaley, R.C.,
Demmel, J., et al. (2002).
An updated set of basic linear algebra subprograms (BLAS).
<em>ACM Transactions on Mathematical Software</em> <b>28</b>, 135–151.
<a href="https://doi.org/10.1145/567806.567807">doi:10.1145/567806.567807</a>
</p>
<p>Brent, R.P. (2013). <em>Algorithms for minimization without derivatives</em>.
Mineola (NY): Dover Publications Inc. (This publication is an unabridged
republication of the work originally published by Prentice-Hall Inc.,
Englewood Cliffs, NJ, in 1973).
</p>
<p>Maechler, M., Rousseeuw, P., Croux, C., Todorov, V., Ruckstuhl, A.,
Salibian-Barrera, M., Verbeke, T., Koller, M., Conceicao, E.L.T. and
M. Anna di Palma (2022). robustbase: Basic Robust Statistics R package
version 0.95-0. <a href="https://CRAN.R-project.org/package=robustbase">https://CRAN.R-project.org/package=robustbase</a>
</p>
<p>Maronna, R.A., Martin, D., V.J. Yohai and M. Salibian-Barrera (2019):
<em>Robust statistics: Theory and methods</em>. Chichester: John Wiley
and Sons, 2nd ed.
</p>
<p>Richardson, A.M. and A.H. Welsh (1995).
Robust restricted maximum likelihood in mixed linear model.
<em>Biometrics</em> <b>51</b>, 1429–1439.
<a href="https://doi.org/10.2307/2533273">doi:10.2307/2533273</a>
</p>
<p>Rousseeuw, P. J. and K. Van Driessen (2006).
Computing LTS regression for large data sets.
<em>Data Mining and Knowledge Discovery</em> <b>12</b>, 29–45.
<a href="https://doi.org/10.1007/s10618-005-0024-4">doi:10.1007/s10618-005-0024-4</a>
</p>
<p>Schoch, T. (2012). Robust Unit-Level Small Area Estimation: A Fast Algorithm
for Large Datasets. <em>Austrian Journal of Statistics</em> <b>41</b>,
243–265. <a href="https://doi.org/10.17713/ajs.v41i4.1548">doi:10.17713/ajs.v41i4.1548</a>
</p>


<h3>See Also</h3>

<p><code>fitsaemodel.control()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># use the landsat data
head(landsat)

# define the saemodel using the landsat data
model &lt;- saemodel(formula = HACorn ~ PixelsCorn + PixelsSoybeans,
    area = ~CountyName,
    data = subset(landsat, subset = (outlier == FALSE)))

# summary of the model
summary(model)

# maximum likelihood estimates
fitsaemodel("ml", model)

# Huber M-estimate with robustness tuning constant k = 2
m &lt;- fitsaemodel("huberm", model, k = 2)
m

# summary of the fitted model/ estimates
summary(m)

# obtain more information about convergence
convergence(m)

# extract the fixed effects
coef(m, "fixef")

# extract the random effects
coef(m, "ranef")

# extract both
coef(m)
</code></pre>


</div>