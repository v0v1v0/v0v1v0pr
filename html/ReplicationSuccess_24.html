<div class="container">

<table style="width: 100%;"><tr>
<td>RProjects</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Data from four large-scale replication projects</h2>

<h3>Description</h3>

<p>Data from <em>Reproduciblity Project Psychology</em> (RPP),
<em>Experimental Economics Replication Project</em> (EERP), <em>Social
Sciences Replication Project</em> (SSRP), <em>Experimental Philosophy
Replicability Project</em> (EPRP). The variables are as follows:
</p>

<dl>
<dt><code>study</code></dt>
<dd>
<p>Study identifier, usually names of authors
from original study</p>
</dd>
<dt><code>project</code></dt>
<dd>
<p>Name of replication project</p>
</dd>
<dt><code>ro</code></dt>
<dd>
<p>Effect estimate of original study on correlation scale</p>
</dd>
<dt><code>rr</code></dt>
<dd>
<p>Effect estimate of replication study on correlation scale</p>
</dd>
<dt><code>fiso</code></dt>
<dd>
<p>Effect estimate of original study transformed to
Fisher-z scale</p>
</dd>
<dt><code>fisr</code></dt>
<dd>
<p>Effect estimate of replication study transformed
to Fisher-z scale</p>
</dd>
<dt><code>se_fiso</code></dt>
<dd>
<p>Standard error of Fisher-z transformed effect estimate
of original study</p>
</dd>
<dt><code>se_fisr</code></dt>
<dd>
<p>Standard error of Fisher-z transformed effect estimate
of replication study</p>
</dd>
<dt><code>po</code></dt>
<dd>
<p>Two-sided p-value from significance test of effect estimate
from original study</p>
</dd>
<dt><code>pr</code></dt>
<dd>
<p>Two-sided p-value from significance test of effect estimate
from replication study</p>
</dd>
<dt><code>po1</code></dt>
<dd>
<p>One-sided p-value from significance test of effect estimate
from original study (in the direction of the original effect estimate)</p>
</dd>
<dt><code>pr1</code></dt>
<dd>
<p>One-sided p-value from significance test of effect estimate
from replication study (in the direction of the original effect estimate)</p>
</dd>
<dt><code>pm_belief</code></dt>
<dd>
<p>Peer belief about whether replication effect estimate
will achieve statistical significance elicited through prediction market (only
available for EERP and SSRP)</p>
</dd>
<dt><code>no</code></dt>
<dd>
<p>Sample size in original study</p>
</dd>
<dt><code>nr</code></dt>
<dd>
<p>Sample size in replication study</p>
</dd>
</dl>
<h3>Usage</h3>

<pre><code class="language-R">data(RProjects)
</code></pre>


<h3>Format</h3>

<p>A data frame with 143 rows and 15 variables
</p>


<h3>Details</h3>

<p>Two-sided p-values were calculated assuming normality of Fisher-z
transformed effect estimates. From the RPP only the <em>meta-analytic
subset</em> is included, which consists of 73 out of 100 study pairs for
which the standard error of the z-transformed correlation coefficient can
be computed. For the RPP sample sizes were recalculated from the reported
standard errors of Fisher z-transformed correlation coefficients. From
the EPRP only 31 out of 40 study pairs are included where effective
sample size for original and replication study are available
simultaneously. For more details about how the the data was preprocessed
see source below and supplement S1 of Pawel and Held (2020).
</p>


<h3>Source</h3>

<p>RPP: The source files were downloaded from
<a href="https://github.com/CenterForOpenScience/rpp/">https://github.com/CenterForOpenScience/rpp/</a>. The "masterscript.R"
file was executed and the relevant variables were extracted from the
generated "final" object (standard errors of Fisher-z transformed
correlations) and "MASTER" object (everything else). The data set is
licensed under a CC0 1.0 Universal license, see
<a href="https://creativecommons.org/publicdomain/zero/1.0/">https://creativecommons.org/publicdomain/zero/1.0/</a> for the terms of
reuse.
</p>
<p>EERP: The source files were downloaded from <a href="https://osf.io/pnwuz/">https://osf.io/pnwuz/</a>. The
required data were then manually extracted from the code in the files
"effectdata.py" (sample sizes) and "create_studydetails.do" (everything
else). Data regarding the prediction market and survey beliefs were manually
extracted from table S3 of the supplementary materials of the EERP. The
authors of this R package have been granted permission to share this data set
by the coordinators of the EERP.
</p>
<p>SSRP: The relevant variables were extracted from the file
"D3 - ReplicationResults.csv" downloaded from <a href="https://osf.io/abu7k">https://osf.io/abu7k</a>. For
replications which underwent only the first stage, the data from the first
stage were taken as the data for the replication study. For the replications
which reached the second stage, the pooled data from both stages were taken
as the data for the replication study. Data regarding survey and prediction
market beliefs were extracted from the "D6 - MeanPeerBeliefs.csv" file, which
was downloaded from <a href="https://osf.io/vr6p8/">https://osf.io/vr6p8/</a>. The data set is licensed
under a CC0 1.0 Universal license, see
<a href="https://creativecommons.org/publicdomain/zero/1.0/">https://creativecommons.org/publicdomain/zero/1.0/</a> for the terms of
reuse.
</p>
<p>EPRP: Data were taken from the "XPhiReplicability_CompleteData.csv" file,
which was downloaded from <a href="https://osf.io/4ewkh/">https://osf.io/4ewkh/</a>. The authors of this R
package have been granted permission to share this data set by the
coordinators of the EPRP.
</p>


<h3>References</h3>

<p>Camerer, C. F., Dreber, A., Forsell, E., Ho, T.-H., Huber, J.,
Johannesson, M., ... Hang, W. (2016). Evaluating replicability of
laboratory experiments in economics. <em>Science</em>, <b>351</b>, 1433-1436.
<a href="https://doi.org/10.1126/science.aaf0918">doi:10.1126/science.aaf0918</a>
</p>
<p>Camerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J.,
Johannesson, M., ... Wu, H. (2018). Evaluating the replicability of
social science experiments in Nature and Science between 2010 and 2015.
<em>Nature Human Behaviour</em>, <b>2</b>, 637-644.
<a href="https://doi.org/10.1038/s41562-018-0399-z">doi:10.1038/s41562-018-0399-z</a>
</p>
<p>Cova, F., Strickland, B., Abatista, A., Allard, A., Andow, J., Attie, M., ...
Zhou, X. (2018). Estimating the reproducibility of experimental philosophy.
<em>Review of Philosophy and Psychology</em>. <a href="https://doi.org/10.1007/s13164-018-0400-9">doi:10.1007/s13164-018-0400-9</a>
</p>
<p>Open Science Collaboration. (2015). Estimating the reproducibility of
psychological science. <em>Science</em>, <b>349</b>, aac4716.
<a href="https://doi.org/10.1126/science.aac4716">doi:10.1126/science.aac4716</a>
</p>
<p>Pawel, S., Held, L. (2020). Probabilistic forecasting of replication studies.
<em>PLoS ONE</em>. <b>15</b>, e0231416. <a href="https://doi.org/10.1371/journal.pone.0231416">doi:10.1371/journal.pone.0231416</a>
</p>


<h3>See Also</h3>

<p><code>SSRP</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data("RProjects", package = "ReplicationSuccess")

## Computing key quantities
RProjects$zo &lt;- RProjects$fiso/RProjects$se_fiso
RProjects$zr &lt;- RProjects$fisr/RProjects$se_fisr
RProjects$c &lt;- RProjects$se_fiso^2/RProjects$se_fisr^2

## Computing one-sided p-values for alternative = "greater"
RProjects$po1 &lt;- z2p(z = RProjects$zo, alternative = "greater")
RProjects$pr1 &lt;- z2p(z = RProjects$zr, alternative = "greater")

## Plots of effect estimates
parOld &lt;- par(mfrow = c(2, 2))
for (p in unique(RProjects$project)) {
  data_project &lt;- subset(RProjects, project == p)
  plot(rr ~ ro, data = data_project, ylim = c(-0.5, 1),
       xlim = c(-0.5, 1), main = p, xlab = expression(italic(r)[o]),
       ylab = expression(italic(r)[r]))
  abline(h = 0, lty = 2)
  abline(a = 0, b = 1, col = "grey")
}
par(parOld)

## Plots of peer beliefs
RProjects$significant &lt;- factor(RProjects$pr &lt; 0.05,
                                levels = c(FALSE, TRUE),
                                labels = c("no", "yes"))
parOld &lt;- par(mfrow = c(1, 2))
for (p in c("Experimental Economics", "Social Sciences")) {
  data_project &lt;- subset(RProjects, project == p)
  boxplot(pm_belief ~ significant, data = data_project, ylim = c(0, 1),
          main = p, xlab = "Replication effect significant", ylab = "Peer belief")
  stripchart(pm_belief ~ significant, data = data_project, vertical = TRUE,
             add = TRUE, pch = 1, method = "jitter")
}
par(parOld)

## Computing the sceptical p-value
ps &lt;- with(RProjects, pSceptical(zo = fiso/se_fiso,
                                 zr = fisr/se_fisr,
                                 c = se_fiso^2/se_fisr^2))
</code></pre>


</div>