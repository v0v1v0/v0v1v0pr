<div class="container">

<table style="width: 100%;"><tr>
<td>predict.randomUniformForest</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Predict method for random Uniform Forests objects
</h2>

<h3>Description</h3>

<p>Prediction of test data with random Uniform Forests. Many options are allowed, the default one rendering exactly the same type of variable than the one of training labels.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'randomUniformForest'
predict(object, X, 
	type = c("response", "prob", "votes", "confInt", 
	"ranking", "quantile", "truemajority", "all"),
	classcutoff = c(0,0), 
	conf = 0.95,
	whichQuantile = NULL,
	rankingIDs = NULL,
	threads = "auto", 
	parallelpackage = "doParallel",
	...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>

<p>an object of class randomUniformForest, as one created by the randomUniformForest( ) function.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>

<p>a data frame or matrix containing new data (without response values).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>

<p>one of response, prob, votes, prediction intervals, ranking, quantile, true majority or raw outputs, indicating respectively the type of output: 'predicted values', 'matrix of class probabilities', 'matrix of vote counts', 'prediction interval for each response', 'ranked responses' in case of recommendation scheme (note that it is currently experimental and it, first, requires classification modelling), 'quantile regression', 'predicted values based on nodes votes instead of tree votes', or lastly, 'raw outputs' of a random uniform forest. Note that "confInt" and "quantile" use an estimate of the conditional expectation for each tree parameter (the randomness), which contains many duplicates, due to bootstrap and the nature of ensemble learning, to produce estimates. These ones are usually loose since the forest replicates the distribution of Y (knowing X) to take decisions while one does not need all the X values to have one prediction. A more accurate option is to use the dedicated <code>bCI</code> function. Note also that option "quantile" is better handled when using default value of the 'nodesize' option in the <code>randomUniformForest</code> function. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classcutoff</code></td>
<td>

<p>see <code>randomUniformForest</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf</code></td>
<td>

<p>if type == "confInt", value of 'conf' (greater than 0 and lesser than 1) is the desired level of confidence for any prediction interval.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>whichQuantile</code></td>
<td>

<p>if type == "quantile", value of 'whichQuantile' is the desired quantile (greater than 0 and lesser than 1).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rankingIDs</code></td>
<td>

<p>experimental. If 'type = "ranking"', vector of ID if one wants to rank responses instead of classify them. Ranking usually involves many same users (or objects, or items) whose choices have to be ranked, e.g., by a recommendation engine. For example, if 'user1' is present four times in test sample, its ID gives to the model a way to identify him (or it) and to order response values, beginning by the most relevant. Then, for many users, the process is repeated giving, finally, predictions from most to least relevant, taking into account all users. random Uniform Forests approach currently uses class probabilities to order predictions values. Note that optimizing AUC is one of the methods leading to good ranking methods if choices are binary, and NDCG is a way to assess model. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threads</code></td>
<td>

<p>see <code>randomUniformForest</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallelpackage</code></td>
<td>

<p>see <code>randomUniformForest</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>not used currently.
</p>
</td>
</tr>
</table>
<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>response </code></td>
<td>
<p>predicted values. Default option that returns values in the same way than original training responses.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prob </code></td>
<td>
<p>for classification only. Matrix of class probabilities.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>votes </code></td>
<td>
<p>matrix of vote counts. Each row is an observation and each column is tree output.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>confInt </code></td>
<td>
<p>for regression only. Matrix where each row is an observation and each column one of the prediction interval bounds. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>quantile </code></td>
<td>
<p>for regression only. Vector of predicted quantiles for 'conf' (value of the option) level of confidence.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ranking </code></td>
<td>
<p>a matrix or data frame. Description will be updated soon.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>truemajority </code></td>
<td>
<p>predicted values, using raw outputs of trees (not majority vote). This option makes sense if one set 'nodesize' option greater than 1. Hence, aggregation is participative (at the leaf level) and not representative (at the tree level).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>all </code></td>
<td>
<p>raw outputs of the model. Not useful, unless further computation is needed, for example in case of Post-processing.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Saip Ciss  <a href="mailto:saip.ciss@wanadoo.fr">saip.ciss@wanadoo.fr</a>
</p>


<h3>See Also</h3>

<p><code>postProcessingVotes</code>, <code>bCI</code>, <code>model.stats</code>, <code>generic.cv</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## same as randomForest example
#  data(iris)
# set.seed(111)
# ind &lt;- sample(2, nrow(iris), replace = TRUE, prob = c(0.8, 0.2))

# iris.ruf &lt;- randomUniformForest(Species ~ ., data = iris[ind == 1,], OOB = FALSE, 
# importance = FALSE, threads = 1)
# iris.pred &lt;- predict(iris.ruf, iris[ind == 2,])

# table(observed = iris[ind == 2, "Species"], predicted = iris.pred)

## get all votes : note that aliases of classes are used internally and, for intermediate
## results, are not converted to their true values
# iris.all.votes &lt;- predict(iris.ruf, iris[ind == 2,], type = "votes")

## get class probabilities
# iris.class.prob &lt;- predict(iris.ruf, iris[ind == 2,], type = "prob")
# iris.class.prob
</code></pre>


</div>