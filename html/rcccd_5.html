<div class="container">

<table style="width: 100%;"><tr>
<td>rwcccd_classifier</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Random Walk Class Cover Catch Digraph Classifier</h2>

<h3>Description</h3>

<p><code>rwcccd_classifier</code> and <code>rwcccd_classifier_2</code> fits a
Random Walk Class Cover Catch Digraph (RWCCCD) classification model.
<code>rwcccd_classifier</code> uses C++ for speed and <code>rwcccd_classifier_2</code>
uses R language to determine balls.
</p>


<h3>Usage</h3>

<pre><code class="language-R">rwcccd_classifier(x, y, method = "default", m = 1, proportion = 0.99)

rwcccd_classifier_2(
  x,
  y,
  method = "default",
  m = 1,
  proportion = 0.99,
  partial_ordering = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>feature matrix or dataframe.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>class factor variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>"default" or "balanced".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m</code></td>
<td>
<p>penalization parameter. Takes value in <code class="reqn">[0,\infty)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>proportion</code></td>
<td>
<p>proportion of covered samples. A real number between <code class="reqn">(0,1]</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>partial_ordering</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> Default is <code>FALSE</code> <code>TRUE</code> uses partial
ordering in determining dominant points. It orders incompletely but faster.
Only for <code>rwcccd_classifier_2</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Random Walk Class Cover Catch Digraphs (RWCCD) are determined by calculating
<code class="reqn">T_{\text{target}}</code> score for each class as target class as
</p>
<p style="text-align: center;"><code class="reqn">
T_{\text{target}}=R_{\text{target}}(r_{\text{target}})-\frac{r_{\text{target}}n_u}{2d_m(x)}.
</code>
</p>

<p>Here, <code class="reqn">r_{\text{target}}</code> is radius and determined by maximum
<code class="reqn">R_{\text{target}}(r) - P_{\text{target}}(r)</code> calculated for each target sample.
<code class="reqn">R_{\text{target}}(r)</code> is
</p>
<p style="text-align: center;"><code class="reqn">
  R_{\text{target}}(r):=
  w_{target}|{z\in X^{\text{target}}_{n_{\text{target}}}:d(x^{\text{target}},z)\leq r}| -
  w_{non-target}|{z\in X^{\text{non-target}}_{n_{\text{non-target}}}:d(x^{\text{target}},z)\leq r}|
</code>
</p>

<p>and <code class="reqn">P_{\text{target}}(r)</code> is
</p>
<p style="text-align: center;"><code class="reqn">
  P_{\text{target}}(r) = m\times d(x^{\text{target}},z)^p.
</code>
</p>

<p><code class="reqn">m=0</code> removes penalty. <code class="reqn">w_{target}=1</code> for default and
<code class="reqn">w_{target}=n_{\text{target}/n_{\text{non-target}}}</code> for balanced method.
<code class="reqn">n_u</code> is the number of uncovered samples in the current iteration and
<code class="reqn">d_m(x)</code> is <code class="reqn">\max{d(x^{\text{target}},x^{\text{uncovered}})}</code>.
</p>
<p>This method is more robust to noise compared to PCCCD However, balls covers
classes improperly and <code class="reqn">r = 0</code> can be selected.
</p>
<p>For detail, please refer to Priebe et al. (2001), Priebe et al. (2003),
and Manukyan and Ceyhan (2016).
</p>


<h3>Value</h3>

<p>a rwcccd_classifier object
</p>
<table>
<tr style="vertical-align: top;">
<td><code>i_dominant_list</code></td>
<td>
<p>dominant sample indexes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x_dominant_list</code></td>
<td>
<p>dominant samples from feature matrix, x</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>radii_dominant_list</code></td>
<td>
<p>Radiuses of the circle for dominant samples</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>class_names</code></td>
<td>
<p>class names</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k_class</code></td>
<td>
<p>number of classes</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>proportions</code></td>
<td>
<p>proportions each class covered</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Fatih Saglam, saglamf89@gmail.com
</p>


<h3>References</h3>

<p>Priebe, C. E., DeVinney, J., &amp; Marchette, D. J. (2001). On the distribution
of the domination number for random class cover catch digraphs. Statistics &amp;
Probability Letters, 55(3), 239–246. https://doi.org/10.1016/s0167-7152(01)00129-8
</p>
<p>Priebe, C. E., Marchette, D. J., DeVinney, J., &amp; Socolinsky, D. A. (2003).
Classification Using Class Cover Catch Digraphs. Journal of Classification,
20(1), 3–23. https://doi.org/10.1007/s00357-003-0003-7
</p>
<p>Manukyan, A., &amp; Ceyhan, E. (2016). Classification of imbalanced data with a
geometric digraph family. Journal of Machine Learning Research, 17(1),
6504–6543. https://jmlr.org/papers/volume17/15-604/15-604.pdf
</p>


<h3>Examples</h3>

<pre><code class="language-R">
n &lt;- 500
x1 &lt;- runif(n, 1, 10)
x2 &lt;- runif(n, 1, 10)
x &lt;- cbind(x1, x2)
y &lt;- as.factor(ifelse(3 &lt; x1 &amp; x1 &lt; 7 &amp; 3 &lt; x2 &amp; x2 &lt; 7, "A", "B"))

# dataset
m_rwcccd_1 &lt;- rwcccd_classifier(x = x, y = y, method = "default", m = 1)

plot(x, col = y, asp = 1, main = "default")
# dominant samples of second class
x_center &lt;- m_rwcccd_1$x_dominant_list[[2]]
# radii of balls for second class
radii &lt;- m_rwcccd_1$radii_dominant_list[[2]]

# balls
for (i in 1:nrow(x_center)) {
  xx &lt;- x_center[i, 1]
  yy &lt;- x_center[i, 2]
  r &lt;- radii[i]
  theta &lt;- seq(0, 2*pi, length.out = 100)
  xx &lt;- xx + r*cos(theta)
  yy &lt;- yy + r*sin(theta)
  lines(xx, yy, type = "l", col = "green")
}

# dataset
m_rwcccd_2 &lt;- rwcccd_classifier_2(x = x, y = y, method = "default", m = 1, partial_ordering = TRUE)

plot(x, col = y, asp = 1, main = "default, prartial_ordering = TRUE")
# dominant samples of second class
x_center &lt;- m_rwcccd_2$x_dominant_list[[2]]
# radii of balls for second class
radii &lt;- m_rwcccd_2$radii_dominant_list[[2]]

# balls
for (i in 1:nrow(x_center)) {
  xx &lt;- x_center[i, 1]
  yy &lt;- x_center[i, 2]
  r &lt;- radii[i]
  theta &lt;- seq(0, 2*pi, length.out = 100)
  xx &lt;- xx + r*cos(theta)
  yy &lt;- yy + r*sin(theta)
  lines(xx, yy, type = "l", col = "green")
}

# dataset
m_rwcccd_3 &lt;- rwcccd_classifier(x = x, y = y, method = "balanced", m = 1, proportion = 0.5)

plot(x, col = y, asp = 1, main = "balanced, proportion = 0.5")
# dominant samples of second class
x_center &lt;- m_rwcccd_3$x_dominant_list[[2]]
# radii of balls for second class
radii &lt;- m_rwcccd_3$radii_dominant_list[[2]]

# balls
for (i in 1:nrow(x_center)) {
  xx &lt;- x_center[i, 1]
  yy &lt;- x_center[i, 2]
  r &lt;- radii[i]
  theta &lt;- seq(0, 2*pi, length.out = 100)
  xx &lt;- xx + r*cos(theta)
  yy &lt;- yy + r*sin(theta)
  lines(xx, yy, type = "l", col = "green")
}

# testing the performance
i_train &lt;- sample(1:n, round(n*0.8))

x_train &lt;- x[i_train,]
y_train &lt;- y[i_train]

x_test &lt;- x[-i_train,]
y_test &lt;- y[-i_train]

m_rwcccd &lt;- rwcccd_classifier(x = x_train, y = y_train, method = "balanced")
pred &lt;- predict(object = m_rwcccd, newdata = x_test)

# confusion matrix
table(y_test, pred)

# accuracy
sum(y_test == pred)/nrow(x_test)

</code></pre>


</div>