<div class="container">

<table style="width: 100%;"><tr>
<td>robcbi-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Robust Fit for Discrete Generalized Linear Model
</h2>

<h3>Description</h3>

<p>Conditionally unbiased bounded influence estimates as described in Kuensch et al.  
(1989) in three special cases of the Generalized Linear Model: Bernoulli, Binomial,  
and Poisson distributed responses. 
</p>


<h3>Details</h3>


<table>
<tr>
<td style="text-align: left;">
Package: </td>
<td style="text-align: left;"> cubinf</td>
</tr>
<tr>
<td style="text-align: left;">
#Version: </td>
<td style="text-align: left;"> 1.0</td>
</tr>
<tr>
<td style="text-align: left;">
#Date: </td>
<td style="text-align: left;"> 2013-07-04</td>
</tr>
<tr>
<td style="text-align: left;">
License: </td>
<td style="text-align: left;">  GPL (&gt;= 2)</td>
</tr>
<tr>
<td style="text-align: left;">
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>A. Marazzi  &lt;Alfio.Marazzi@chuv.ch&gt;
</p>
<p>Maintainer: A. Randriamiharisoa &lt;Alex.Randriamiharisoa@chuv.ch&gt;
</p>


<h3>References</h3>

<p>Kuensch, H.R., Stefanski L.A., Carroll R.J. (1989).
Conditionally unbiased bounded-influence estimation in general regression models,
with application to generalized linear models. 
Journal of the American Statistical Association, 84, 460-466.
</p>
<p>Marazzi, A. (1993).
Algorithms, Routines, and S-functions for robust Statistics.
Chapman and Hall, New York.
</p>


<h3>Examples</h3>

<pre><code class="language-R"> library(robcbi)
# First example
 data(Finney)
 Vol &lt;- Finney$Vol; Rate &lt;- Finney$Rate; Resp &lt;- Finney$Resp
## Not run: 
 plot(Vol,Rate,type="n")
 points(Vol[Resp==0],Rate[Resp==0],pch=5, cex=1.2)
 points(Vol[Resp==1],Rate[Resp==1],pch=16,cex=1.2)

## End(Not run)
 lVol &lt;-log(Vol); lRate &lt;- log(Rate)
 z.glm &lt;- glm(Resp~lVol+lRate,family=binomial)
 summary(z.glm)
 z.cub &lt;- glm(Resp~lVol+lRate,family=binomial,method="cubinf", ufact=3.2)
 summary(z.cub)
 weights(z.cub)
## Not run: 
 plot(z.cub, smooth=TRUE, ask=TRUE)

## End(Not run)
 comp &lt;- fits.compare(z.glm,z.cub)
 comp
## Not run: 
 plot(comp)

## End(Not run)
# Second example
 data(Breslow)
## Not run:  
 help(Breslow)

## End(Not run)
 y  = Breslow$sumY
 x1 = Breslow$Age10
 x2 = Breslow$Base4
 x3 = rep(0,length(y))
 x3[Breslow$Trt=="progabide"] = 1
 x4 = x2*x3
 CBA = glm(y~x1+x2+x3+x4,family=poisson,method=cubinf,ufact=3.2)
## Not run: 
 plot(CBA,num=5)

## End(Not run)
 weights(CBA)
#
# compute the $R_n^2$ statistic (Section 2.5) to compare CBA 
# with a reduced model with three variables:
#
 CBA.red = update(CBA, .~.-x3-x4)
 np = 5       # number of parameters of the full model
 nq = 3       # number of parameters of the reduced model
 CVR = covar(CBA)
 CFF = coef(CBA)
 K22 = CVR[(nq+1):np,(nq+1):np]
 cff = as.matrix(CFF[(nq+1):np])
 Rn2 = t(cff)%*%solve(K22)%*%cff
 Rn2
</code></pre>


</div>