<div class="container">

<table style="width: 100%;"><tr>
<td>LIM</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Leaky Integration Model</h2>

<h3>Description</h3>

<p>SDDM modified to encode leaky integration in the drift rate. Also known as an
Ornstein-Uhlenbeck model, its drift rate is <code class="reqn">v(x,t) = \mu - L*x</code> where <code class="reqn">L</code> is the
leakage rate. All other parameters are unchanged from the SDDM. Leakage describes
the rate at which old information is lost from the accumulator, occurring on a
time scale of approximately <code class="reqn">1/L</code>. The LIM is used to model decay of excitatory
currents in decision neurons (Usher &amp; McClelland, 2001; Wong &amp; Wang, 2006) and
has been proposed as a mechanism for preference reversals under time pressure
(Busemeyer &amp; Townsend, 1993). Due to its neural plausibility and simple functional
form, recent work has proposed it as an alternative psychometric tool to the SDDM
(Wang &amp; Donkin, 2024).
</p>


<h3>Usage</h3>

<pre><code class="language-R">dLIM(rt, resp, phi, x_res = "default", t_res = "default")

pLIM(rt, resp, phi, x_res = "default", t_res = "default")

rLIM(n, phi, dt = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>rt</code></td>
<td>
<p>vector of response times</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>resp</code></td>
<td>
<p>vector of responses ("upper" and "lower")</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>phi</code></td>
<td>
<p>parameter vector in the following order:
</p>

<ol>
<li>
<p> Non-decision time (<code class="reqn">t_{nd}</code>). Time for non-decision processes such as stimulus
encoding and response execution. Total decision time t is the sum of the decision
and non-decision times.
</p>
</li>
<li>
<p> Relative start (<code class="reqn">w</code>). Sets the start point of accumulation as a ratio of
the two decision thresholds. Related to the absolute start z point via equation
<code class="reqn">z = b_l + w*(b_u - b_l)</code>.
</p>
</li>
<li>
<p> Stimulus strength (<code class="reqn">\mu</code>). Strength of the stimulus.
</p>
</li>
<li>
<p> Log10-leakage (<code class="reqn">log_{10}(L)</code>). Rate of leaky integration.
</p>
</li>
<li>
<p> Noise scale (<code class="reqn">\sigma</code>). Model scaling parameter.
</p>
</li>
<li>
<p> Decision thresholds (<code class="reqn">b</code>). Sets the location of each decision threshold. The
upper threshold <code class="reqn">b_u</code> is above 0 and the lower threshold <code class="reqn">b_l</code> is below 0 such that
<code class="reqn">b_u = -b_l = b</code>. The threshold separation <code class="reqn">a = 2b</code>.
</p>
</li>
<li>
<p> Contamination (<code class="reqn">g</code>). Sets the strength of the contamination process. Contamination
process is a uniform distribution <code class="reqn">f_c(t)</code> where <code class="reqn">f_c(t) = 1/(g_u-g_l)</code>
if <code class="reqn">g_l &lt;= t &lt;= g_u</code> and <code class="reqn">f_c(t) = 0</code> if <code class="reqn">t &lt; g_l</code> or <code class="reqn">t &gt; g_u</code>. It is
combined with PDF <code class="reqn">f_i(t)</code> to give the final combined distribution
<code class="reqn">f_{i,c}(t) = g*f_c(t) + (1-g)*f_i(t)</code>, which is then output by the program.
If <code class="reqn">g = 0</code>, it just outputs <code class="reqn">f_i(t)</code>.
</p>
</li>
<li>
<p> Lower bound of contamination distribution (<code class="reqn">g_l</code>). See parameter <code class="reqn">g</code>.
</p>
</li>
<li>
<p> Upper bound of contamination distribution (<code class="reqn">g_u</code>). See parameter <code class="reqn">g</code>.
</p>
</li>
</ol>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x_res</code></td>
<td>
<p>spatial/evidence resolution</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>t_res</code></td>
<td>
<p>time resolution</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>number of samples</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dt</code></td>
<td>
<p>step size of time. We recommend 0.00001 (1e-5)</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>For the density a list of PDF values, log-PDF values, and the sum of the
log-PDFs, for the distribution function a list of of CDF values, log-CDF values,
and the sum of the log-CDFs, and for the random sampler a list of response
times (rt) and response thresholds (resp).
</p>


<h3>Author(s)</h3>

<p>Raphael Hartmann &amp; Matthew Murrow
</p>


<h3>References</h3>

<p>Busemeyer, J. R., &amp; Townsend, J. T. (1993). Decision field theory: A dynamic-cognitive
approach to decision making in an uncertain environment. <em>Psychological Review, 100</em>(3), 432-459.
</p>
<p>Usher, M., &amp; McClelland, J. L. (2001). The time course of perceptual choice: The leaky,
competing accumulator model. <em>Psychological Review, 108</em>(3), 550-592.
</p>
<p>Wang, J.-S., &amp; Donkin, C. (2024). The neural implausibility of the diffusion decision
model doesnâ€™t matter for cognitive psychometrics, but the Ornstein-Uhlenbeck model
is better. <em>Psychonomic Bulletin &amp; Review</em>.
</p>
<p>Wong, K.-F., &amp; Wang, X.-J. (2006). A Recurrent Network Mechanism of Time Integration
in Perceptual Decisions. <em>The Journal of Neuroscience, 26</em>(4), 1314-1328.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Probability density function
dLIM(rt = c(1.2, 0.6, 0.4), resp = c("upper", "lower", "lower"),
     phi = c(0.3, 0.5, 1.0, 0.5, 1.0, 0.5, 0.0, 0.0, 1.0))

# Cumulative distribution function
pLIM(rt = c(1.2, 0.6, 0.4), resp = c("upper", "lower", "lower"),
     phi = c(0.3, 0.5, 1.0, 0.5, 1.0, 0.5, 0.0, 0.0, 1.0))

# Random sampling
rLIM(n = 100, phi = c(0.3, 0.5, 1.0, 0.5, 1.0, 0.5, 0.0, 0.0, 1.0))
</code></pre>


</div>