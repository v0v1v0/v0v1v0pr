<div class="container">

<table style="width: 100%;"><tr>
<td>StSignificanceTestingCadVsRad</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Significance testing: standalone CAD vs. radiologists</h2>

<h3>Description</h3>

<p>Comparing standalone CAD vs. at least two radiologists interpreting 
the same cases; <strong>standalone CAD</strong> means that <b>all</b> the 
<b>designer-level</b> mark-rating pairs generated by the CAD algorithm 
are available to the analyst, not just the one or two marks per case
displayed to the radiologist (the latter are marks whose ratings exceed a 
pre-selected threshold). At the very minimum, location-level information, 
such as in
the LROC paradigm, should be used. Ideally, the FROC paradigm should be used.
A severe statistical power penalty is paid if one uses the ROC paradigm. 
See Standalone CAD vs Radiologists chapter, available via <em>download</em> 
link at site 
<a href="https://github.com/dpc10ster/RJafrocBook/blob/gh-pages/RJafrocBook.pdf">https://github.com/dpc10ster/RJafrocBook/blob/gh-pages/RJafrocBook.pdf</a>
</p>


<h3>Usage</h3>

<pre><code class="language-R">StSignificanceTestingCadVsRad(
  dataset,
  FOM,
  FPFValue = 0.2,
  method = "1T-RRRC",
  alpha = 0.05,
  plots = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>dataset</code></td>
<td>
<p><strong>The dataset to be analyzed; must be single-treatment
at least three readers, where the first reader is CAD. </strong></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>FOM</code></td>
<td>
<p>The desired FOM; for ROC data it must be <code>"Wilcoxon"</code>, for FROC data 
it can be any valid FOM, e.g., <code>"HrAuc"</code>, <code>"wAFROC"</code>, etc; 
for LROC data it must be <code>"Wilcoxon"</code>, or <code>"PCL"</code> or <code>"ALROC"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>FPFValue</code></td>
<td>
<p>Only needed for <code>LROC</code> data <strong>and</strong> FOM = "PCL" or "ALROC";
where to evaluate a partial curve based figure of merit. The default is 0.2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>The desired analysis: "1T-RRFC","1T-RRRC" (the default) or "2T-RRRC",
see manuscript for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>Significance level of the test, defaults to 0.05.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plots</code></td>
<td>
<p>Flag, default is FALSE, i.e., a plot is not displayed. 
If TRUE, it displays the appropriate operating characteristic for all 
readers and CAD.</p>
</td>
</tr>
</table>
<h3>Details</h3>


<ul>
<li>
<p><strong>PCL</strong> is the probability of a correct localization. 
</p>
</li>
<li>
<p>The LROC is the plot of PCL (ordinate) vs. FPF. 
</p>
</li>
<li>
<p>For LROC data, FOM = "PCL" means the interpolated PCL value 
at the specified <code>FPFValue</code>.
</p>
</li>
<li>
<p>For FOM = "ALROC" the trapezoidal area under the LROC
from FPF = 0 to FPF = <code>FPFValue</code> is used. 
</p>
</li>
<li>
<p>If <code>method = "1T-RRRC"</code> the first <strong>reader</strong> is assumed to be CAD. 
</p>
</li>
<li>
<p>If <code>method = "2T-RRRC"</code> the first <strong>treatment</strong> is assumed to be CAD. 
</p>
</li>
<li>
<p>The NH is that the FOM of CAD equals the average of the readers. 
</p>
</li>
<li>
<p>The <code>method = "1T-RRRC"</code> analysis uses an adaptation of the 
single-treatment multiple-reader Obuchowski Rockette (OR) model described in a 
paper by Hillis (2007), section 5.3. It is characterized by 3 parameters
<code>VarR</code>, <code>Var</code> and <code>Cov2</code>, where the latter two are estimated 
using the jackknife. 
</p>
</li>
<li>
<p>For <code>method = "2T-RRRC"</code> the analysis replicates the CAD data as many times as
necessary so as to form one "treatment" of an MRMC pairing, the other 
"treatment" being the radiologists. Then standard ORH analysis is applied. The 
method is described in Kooi et al. It gives exactly the same final results 
(F-statistic, ddf and p-value) as <code>"1T-RRRC"</code> but the intermediate quantities 
are meaningless.
</p>
</li>
</ul>
<h3>Value</h3>

<p>If <code>method = "1T-RRRC"</code> the return value is a 
list with the following elements:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>fomCAD</code></td>
<td>
<p>The observed FOM for CAD.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fomRAD</code></td>
<td>
<p>The observed FOM array for the readers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>avgRadFom</code></td>
<td>
<p>The average FOM of the readers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>avgDiffFom</code></td>
<td>
<p>The mean of the difference FOM, RAD - CAD.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ciAvgDiffFom</code></td>
<td>
<p>The 95-percent CI of the average difference, RAD - CAD.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>varR</code></td>
<td>
<p>The variance of the radiologists.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>varError</code></td>
<td>
<p>The variance of the error term in the single-treatment 
multiple-reader OR model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov2</code></td>
<td>
<p>The covariance of the error term.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tstat</code></td>
<td>
<p>The observed value of the t-statistic; it's square is 
equivalent to an F-statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>The degrees of freedom of the t-statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pval</code></td>
<td>
<p>The p-value for rejecting the NH.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Plots</code></td>
<td>
<p>If argument plots = TRUE, a <span class="pkg">ggplot</span> object 
containing empirical operating characteristics  
corresponding to specified FOM. For example, if <code>FOM</code> = 
<code>"Wilcoxon"</code> an ROC plot object
is produced where reader 1 is CAD. If an LROC FOM is selected, an LROC
plot is displayed.</p>
</td>
</tr>
</table>
<p>If <code>method = "2T-RRRC"</code> the return value is a list 
with the following elements:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>fomCAD</code></td>
<td>
<p>The observed FOM for CAD.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fomRAD</code></td>
<td>
<p>The observed FOM array for the readers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>avgRadFom</code></td>
<td>
<p>The average FOM of the readers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>avgDiffFom</code></td>
<td>
<p>The mean of the difference FOM, RAD - CAD.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ciDiffFom</code></td>
<td>
<p>A data frame containing the statistics associated 
with the average difference, RAD - CAD.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ciAvgRdrEachTrt</code></td>
<td>
<p>A data frame containing the statistics 
associated with the average FOM in each "treatment".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>varR</code></td>
<td>
<p>The variance of the pure reader term in the OR model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>varTR</code></td>
<td>
<p>The variance of the treatment-reader term error 
term in the OR model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov1</code></td>
<td>
<p>The covariance1 of the error term - same reader, 
different treatments.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov2</code></td>
<td>
<p>The covariance2 of the error term  - 
different readers, same treatment.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov3</code></td>
<td>
<p>The covariance3 of the error term  - different readers, 
different treatments.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>varError</code></td>
<td>
<p>The variance of the pure error term in the OR model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>FStat</code></td>
<td>
<p>The observed value of the F-statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ndf</code></td>
<td>
<p>The numerator degrees of freedom of the F-statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>The denominator degrees of freedom of the F-statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pval</code></td>
<td>
<p>The p-value for rejecting the NH.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Plots</code></td>
<td>
<p>see above.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Hillis SL (2007) A comparison of denominator degrees of freedom methods 
for multiple observer ROC studies, Statistics in Medicine. 26:596-619.
</p>
<p>Chakraborty DP (2017) <em>Observer Performance Methods for Diagnostic Imaging - Foundations, 
Modeling, and Applications with R-Based Examples</em>, CRC Press, Boca Raton, FL. 
<a href="https://www.routledge.com/Observer-Performance-Methods-for-Diagnostic-Imaging-Foundations-Modeling/Chakraborty/p/book/9781482214840">https://www.routledge.com/Observer-Performance-Methods-for-Diagnostic-Imaging-Foundations-Modeling/Chakraborty/p/book/9781482214840</a>
</p>
<p>Hupse R, Samulski M, Lobbes M, et al (2013) Standalone computer-aided detection compared to radiologists 
performance for the detection of mammographic masses, Eur Radiol. 23(1):93-100.
</p>
<p>Kooi T, Gubern-Merida A, et al. (2016) A comparison between a deep convolutional 
neural network and radiologists for classifying regions of interest in mammography. 
Paper presented at: International Workshop on Digital Mammography, Malmo, Sweden.
</p>


<h3>Examples</h3>

<pre><code class="language-R">ret1M &lt;- StSignificanceTestingCadVsRad (dataset09, 
FOM = "Wilcoxon", method = "1T-RRRC")

StSignificanceTestingCadVsRad(datasetCadLroc, 
FOM = "Wilcoxon", method = "1T-RRFC")

retLroc1M &lt;- StSignificanceTestingCadVsRad (datasetCadLroc, 
FOM = "PCL", method = "1T-RRRC", FPFValue = 0.05)

## test with fewer readers
dataset09a &lt;- DfExtractDataset(dataset09, rdrs = seq(1:7))
ret1M7 &lt;- StSignificanceTestingCadVsRad (dataset09a, 
FOM = "Wilcoxon", method = "1T-RRRC")

datasetCadLroc7 &lt;- DfExtractDataset(datasetCadLroc, rdrs = seq(1:7))
ret1MLroc7 &lt;- StSignificanceTestingCadVsRad (datasetCadLroc7, 
FOM = "PCL", method = "1T-RRRC", FPFValue = 0.05)


## takes longer than 5 sec on OSX
## retLroc2M &lt;- StSignificanceTestingCadVsRad (datasetCadLroc, 
## FOM = "PCL", method = "2T-RRRC", FPFValue = 0.05)

## ret2MLroc7 &lt;- StSignificanceTestingCadVsRad (datasetCadLroc7, 
## FOM = "PCL", method = "2T-RRRC", FPFValue = 0.05)


</code></pre>


</div>