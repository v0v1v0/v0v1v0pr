<div class="container">

<table style="width: 100%;"><tr>
<td>RLT</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Reinforcement Learning Trees</h2>

<h3>Description</h3>

<p>Fit models for regression, classification and survival analysis using reinforced splitting rules
</p>


<h3>Usage</h3>

<pre><code class="language-R">RLT(
  x,
  y,
  censor = NULL,
  model = "regression",
  print.summary = 0,
  use.cores = 1,
  ntrees = if (reinforcement) 100 else 500,
  mtry = max(1, as.integer(ncol(x)/3)),
  nmin = max(1, as.integer(log(nrow(x)))),
  alpha = 0.4,
  split.gen = "random",
  nsplit = 1,
  resample.prob = 0.9,
  replacement = TRUE,
  npermute = 1,
  select.method = "var",
  subject.weight = NULL,
  variable.weight = NULL,
  track.obs = FALSE,
  importance = TRUE,
  reinforcement = FALSE,
  muting = -1,
  muting.percent = if (reinforcement) MuteRate(nrow(x), ncol(x), speed = "aggressive",
    info = FALSE) else 0,
  protect = as.integer(log(ncol(x))),
  combsplit = 1,
  combsplit.th = 0.25,
  random.select = 0,
  embed.n.th = 4 * nmin,
  embed.ntrees = max(1, -atan(0.01 * (ncol(x) - 500))/pi * 100 + 50),
  embed.resample.prob = 0.8,
  embed.mtry = 1/2,
  embed.nmin = as.integer(nrow(x)^(1/3)),
  embed.split.gen = "random",
  embed.nsplit = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A matrix or data.frame for features</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Response variable, a numeric/factor vector or a Surv object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>censor</code></td>
<td>
<p>The censoring indicator if survival model is used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>The model type: <code>regression</code>, <code>classification</code> or <code>survival</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>print.summary</code></td>
<td>
<p>Whether summary should be printed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use.cores</code></td>
<td>
<p>Number of cores</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ntrees</code></td>
<td>
<p>Number of trees, <code>ntrees = 100</code> if use reinforcement, <code>ntrees = 1000</code> otherwise</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mtry</code></td>
<td>
<p>Number of variables used at each internal node, only for <code>reinforcement = FALSE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nmin</code></td>
<td>
<p>Minimum number of observations required in an internal node to perform a split. Set this to twice of the desired terminal node size.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>Minimum number of observations required for each child node as a portion of the parent node. Must be within <code>(0, 0.5]</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>split.gen</code></td>
<td>
<p>How the cutting points are generated</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nsplit</code></td>
<td>
<p>Number of random cutting points to compare for each variable at an internal node</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>resample.prob</code></td>
<td>
<p>Proportion of in-bag samples</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>replacement</code></td>
<td>
<p>Whether the in-bag samples are sampled with replacement</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>npermute</code></td>
<td>
<p>Number of imputations (currently not implemented, saved for future use)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>select.method</code></td>
<td>
<p>Method to compare different splits</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subject.weight</code></td>
<td>
<p>Subject weights</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>variable.weight</code></td>
<td>
<p>Variable weights when randomly sample <code>mtry</code> to select the splitting rule</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>track.obs</code></td>
<td>
<p>Track which terminal node the observation belongs to</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>importance</code></td>
<td>
<p>Should importance measures be calculated</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reinforcement</code></td>
<td>
<p>If reinforcement splitting rules should be used. There are default values for all tuning parameters under this feature.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>muting</code></td>
<td>
<p>Muting method, <code>-1</code> for muting by proportion, positive for muting by count</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>muting.percent</code></td>
<td>
<p>Only for <code>muting = -1</code> the proportion of muting</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>protect</code></td>
<td>
<p>Number of protected variables that will not be muted. These variables are adaptively selected for each tree.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>combsplit</code></td>
<td>
<p>Number of variables used in a combination split. <code>combsplit = 1</code> gives regular binary split; <code>combsplit &gt; 1</code> produces linear combination splits.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>combsplit.th</code></td>
<td>
<p>The minimum threshold (as a relative measurement compared to the best variable) for a variable to be used in the combination split.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>random.select</code></td>
<td>
<p>Randomly select a variable from the top variable in the linear combination as the splitting rule.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>embed.n.th</code></td>
<td>
<p>Number of observations to stop the embedded model and choose randomly from the current protected variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>embed.ntrees</code></td>
<td>
<p>Number of embedded trees</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>embed.resample.prob</code></td>
<td>
<p>Proportion of in-bag samples for embedded trees</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>embed.mtry</code></td>
<td>
<p>Number of variables used for embedded trees, as proportion</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>embed.nmin</code></td>
<td>
<p>Terminal node size for embedded trees</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>embed.split.gen</code></td>
<td>
<p>How the cutting points are generated in the embedded trees</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>embed.nsplit</code></td>
<td>
<p>Number of random cutting points for embedded trees</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A <code>RLT</code> object; a list consisting of
</p>
<table>
<tr style="vertical-align: top;">
<td><code>FittedTrees</code></td>
<td>
<p>Fitted tree structure</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>FittedSurv, timepoints</code></td>
<td>
<p>Terminal node survival estimation and all time points, if survival model is used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>AllError</code></td>
<td>
<p>All out-of-bag errors, if <code>importance = TRUE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>VarImp</code></td>
<td>
<p>Variable importance measures, if <code>importance = TRUE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ObsTrack</code></td>
<td>
<p>Registration of each observation in each fitted tree</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>All the tuning parameters are saved in the fitted <code>RLT</code> object</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Zhu, R., Zeng, D., &amp; Kosorok, M. R. (2015) "Reinforcement Learning Trees." Journal of the American Statistical Association. 110(512), 1770-1784.
</p>
<p>Zhu, R., &amp; Kosorok, M. R. (2012). Recursively imputed survival trees. Journal of the American Statistical Association, 107(497), 331-340.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
N = 600
P = 100

X = matrix(runif(N*P), N, P)
Y = rowSums(X[,1:5]) + rnorm(N)

trainx = X[1:200,]
trainy = Y[1:200]
testx = X[-c(1:200),]
testy = Y[-c(1:200)]

# Regular ensemble trees (Extremely Randomized Trees, Geurts, et. al., 2006)

RLT.fit = RLT(trainx, trainy, model = "regression", use.cores = 6)

barplot(RLT.fit$VarImp)
RLT.pred = predict(RLT.fit, testx)
mean((RLT.pred$Prediction - testy)^2)

# Reinforcement Learning Trees, using an embedded model to find the splitting rule

Mark0 = proc.time()
RLT.fit = RLT(trainx, trainy, model = "regression", use.cores = 6, ntrees = 100,
              importance = TRUE, reinforcement = TRUE, combsplit = 3, embed.ntrees = 25)
proc.time() - Mark0

barplot(RLT.fit$VarImp)
RLT.pred = predict(RLT.fit, testx)
mean((RLT.pred$Prediction - testy)^2)

</code></pre>


</div>