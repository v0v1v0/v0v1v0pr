<div class="container">

<table style="width: 100%;"><tr>
<td>reduce_network</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Reduce the weights of a random weight neural network.</h2>

<h3>Description</h3>

<p>Methods for weight and neuron pruning in random weight neural networks.
</p>


<h3>Usage</h3>

<pre><code class="language-R">reduce_network(object, method, retrain = TRUE, ...)

## S3 method for class 'RWNN'
reduce_network(object, method, retrain = TRUE, ...)

## S3 method for class 'ERWNN'
reduce_network(object, method, retrain = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>An RWNN-object or ERWNN-object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>A string, or a function, setting the method used to reduce the network (see details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>retrain</code></td>
<td>
<p>TRUE/FALSE: Should the output weights be retrained after reduction (defaults to <code>TRUE</code>)?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments passed to the reduction method (see details).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The '<code>method</code>' and additional arguments required by the method are:
</p>

<dl>
<dt>
<code>"global"</code> (or <code>"glbl"</code>)</dt>
<dd>
<dl>
<dt>
<code>p</code>: The proportion of weights to remove globally based on magnitude.</dt>
<dd></dd>
</dl>
</dd>
<dt>
<code>"uniform"</code> (or <code>"unif"</code>)</dt>
<dd>
<dl>
<dt>
<code>p</code>: The proportion of weights to remove uniformly layer-by-layer based on magnitude.</dt>
<dd></dd>
</dl>
</dd>
<dt><code>"lamp"</code></dt>
<dd>
<dl>
<dt>
<code>p</code>: The proportion of weights to remove based on LAMP scores.</dt>
<dd></dd>
</dl>
</dd>
<dt><code>"apoz"</code></dt>
<dd>
<dl>
<dt>
<code>p</code>: The proportion of neurons to remove based on proportion of zeroes produced.</dt>
<dd></dd>
<dt>
<code>tolerance</code>: The tolerance used when identifying zeroes.</dt>
<dd></dd>
<dt>
<code>type</code>: A string indicating whether weights should be removed globally (<code>'global'</code>) or uniformly  (<code>'uniform'</code>).</dt>
<dd></dd>
</dl>
</dd>
<dt>
<code>"correlation"</code> (or <code>"cor"</code>)</dt>
<dd>
<dl>
<dt>
<code>type</code>: The type of correlation (argument passed to cor function).</dt>
<dd></dd>
<dt>
<code>rho</code>: The correlation threshold used to remove neurons.</dt>
<dd></dd>
</dl>
</dd>
<dt>
<code>"correlationtest"</code> (or <code>"cortest"</code>)</dt>
<dd>
<dl>
<dt>
<code>type</code>: The type of correlation (argument passed to cor function).</dt>
<dd></dd>
<dt>
<code>rho</code>: The correlation threshold used to remove neurons.</dt>
<dd></dd>
<dt>
<code>alpha</code>: The significance levels used to test whether the observed correlation between two neurons is small than <code>rho</code>.</dt>
<dd></dd>
</dl>
</dd>
<dt><code>"relief"</code></dt>
<dd>
<dl>
<dt>
<code>p</code>: The proportion of neurons or weights to remove based on relief scores.</dt>
<dd></dd>
<dt>
<code>type</code>: A string indicating whether neurons (<code>'neuron'</code>) or weights (<code>'weight'</code>) should be removed.</dt>
<dd></dd>
</dl>
</dd>
<dt><code>"output"</code></dt>
<dd>
<dl>
<dt>
<code>tolerance</code>: The tolerance used when removing zeroes from the output layer.</dt>
<dd></dd>
</dl>
</dd>
</dl>
<p>If the object is an ERWNN-object, the reduction is applied to all RWNN-object's in the ERWNN-object. Furthermore, when
the ERWNN-object is created as a stack and the weights of the stack is trained, then '<code>method</code>' can be set to:
</p>

<dl>
<dt><code>"stack"</code></dt>
<dd>
<dl>
<dt>
<code>tolerance</code>: The tolerance used when removing elements from the stack.</dt>
<dd></dd>
</dl>
</dd>
</dl>
<p>Lastly, '<code>method</code>' can also be passed as a function, with additional arguments passed through the <code>...</code> argument. 
NB: features and target are passed using the names <code>X</code> and <code>y</code>, respectively.
</p>


<h3>Value</h3>

<p>A reduced RWNN-object or ERWNN-object.
</p>


<h3>References</h3>

<p>Han S., Mao H., Dally W.J. (2016) "Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding." arXiv: 1510.00149.
</p>
<p>Hu H., Peng R., Tai Y.W., Tang C.K. (2016) "Network Trimming: A Data-Driven Neuron Pruning Approach towards Efficient Deep Architectures." arXiv: 1607.03250.
</p>
<p>Morcos A.S., Yu H., Paganini M., Tian Y. (2019) "One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers." arXiv: 1906.02773.
</p>
<p>Lee J., Park S., Mo S., Ahn S., Shin J. (2021) "Layer-adaptive sparsity for the Magnitude-based Pruning." arXiv: 2010.07611.
</p>
<p>Dekhovich A., Tax D.M., Sluiter M.H., Bessa M.A. (2024) "Neural network relief: a pruning algorithm based on neural activity." <em>Machine Learning</em>, 113, 2597-2618.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## RWNN-object
n_hidden &lt;- c(10, 15)
lambda &lt;- 2

m &lt;- rwnn(y ~ ., data = example_data, n_hidden = n_hidden, 
          lambda = lambda, control = list(lnorm = "l2"))

m |&gt; 
    reduce_network(method = "relief", p = 0.2, type = "neuron") |&gt; 
    (\(x) x$weights)()

m |&gt; 
    reduce_network(method = "relief", p = 0.2, type = "neuron") |&gt; 
    reduce_network(method = "correlationtest", rho = 0.995, alpha = 0.05) |&gt; 
    (\(x) x$weights)()


m |&gt; 
    reduce_network(method = "relief", p = 0.2, type = "neuron") |&gt; 
    reduce_network(method = "correlationtest", rho = 0.995, alpha = 0.05) |&gt; 
    reduce_network(method = "lamp", p = 0.2) |&gt; 
    (\(x) x$weights)()

m |&gt; 
    reduce_network(method = "relief", p = 0.4, type = "neuron") |&gt; 
    reduce_network(method = "relief", p = 0.4, type = "weight") |&gt; 
    reduce_network(method = "output") |&gt; 
    (\(x) x$weights)()

## ERWNN-object (reduction is performed element-wise on each RWNN)
n_hidden &lt;- c(10, 15)
lambda &lt;- 2
B &lt;- 100


m &lt;- bag_rwnn(y ~ ., data = example_data, n_hidden = n_hidden, 
              lambda = lambda, B = B, control = list(lnorm = "l2"))

m |&gt; 
    reduce_network(method = "relief", p = 0.2, type = "neuron") |&gt; 
    reduce_network(method = "relief", p = 0.2, type = "weight") |&gt; 
    reduce_network(method = "output")



m &lt;- stack_rwnn(y ~ ., data = example_data, n_hidden = n_hidden,
                lambda = lambda, B = B, optimise = TRUE)

# Number of models in stack
length(m$weights)
# Number of models in stack with weights &gt; .Machine$double.eps
length(m$weights[m$weights &gt; .Machine$double.eps]) 

m |&gt; 
    reduce_network(method = "stack", tolerance = 1e-8) |&gt; 
    (\(x) x$weights)()

</code></pre>


</div>