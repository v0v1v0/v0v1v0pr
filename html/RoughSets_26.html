<div class="container">

<table style="width: 100%;"><tr>
<td>FS.greedy.heuristic.reduct.RST</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>The greedy heuristic algorithm for computing decision reducts and approximate decision reducts</h2>

<h3>Description</h3>

<p>This function implements a greedy heuristic algorithm for computing decision reducts
(or approximate decision reducts) based on RST.
</p>


<h3>Usage</h3>

<pre><code class="language-R">FS.greedy.heuristic.reduct.RST(
  decision.table,
  attrDescriptions = attr(decision.table, "desc.attrs"),
  decisionIdx = attr(decision.table, "decision.attr"),
  qualityF = X.gini,
  nAttrs = NULL,
  epsilon = 0,
  inconsistentDecisionTable = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>decision.table</code></td>
<td>
<p>an object of a <code>"DecisionTable"</code> class representing a decision table. See <code>SF.asDecisionTable</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>attrDescriptions</code></td>
<td>
<p>a list containing possible values of attributes (columns) in <code>decision.table</code>. 
It usually corresponds to <code>attr(decision.table, "desc.attrs")</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>decisionIdx</code></td>
<td>
<p>an integer value representing an index of the decision attribute.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>qualityF</code></td>
<td>
<p>a function used for computation of the quality of attribute subsets.
Currently, the following functions are included:
</p>

<ul>
<li> <p><code>X.entropy</code>: See <code>X.entropy</code>.
</p>
</li>
<li> <p><code>X.gini</code>: See <code>X.gini</code>.
</p>
</li>
<li> <p><code>X.nOfConflicts</code>: See <code>X.nOfConflicts</code>.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nAttrs</code></td>
<td>
<p>an integer between 1 and the number of conditional attributes. It indicates
the attribute sample size for the Monte Carlo selection of candidating attributes.
If set to <code>NULL</code> (default) all attributes are used and the algorithm changes
to a standard greedy method for computation of decision reducts.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epsilon</code></td>
<td>
<p>a numeric value between [0, 1) representing an approximate threshold. It
indicates whether to compute approximate reducts or not. If it equals 0 (the default)
a standard decision reduct is computed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>inconsistentDecisionTable</code></td>
<td>
<p>logical indicating whether the decision table is suspected
to be inconsistent or <code>NULL</code> (the default) which indicated that a test should
be made to determine the data consistency.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>In this implementation, we provided some attribute subset quality measures which can be
passed to the algorithm by the parameter <code>qualityF</code>. Those measures
guide the computations in the search for a decision/approximated reduct. They are used to
assess amount of information gained after addition of an attribute. For example,
<code>X.entropy</code> corresponds to the information gain measure.
</p>
<p>Additionally, this function can use the value of <code>epsilon</code> parameter in order to compute
<code class="reqn">\epsilon</code>-approximate reducts. The <code class="reqn">\epsilon</code>-approximate can be defined as an
irreducable subset of attributes <code>B</code>, such that:
</p>
<p><code class="reqn">Quality_{\mathcal{A}}(B) \ge (1 - \epsilon)Quality_{\mathcal{A}}(A)</code>,
</p>
<p>where <code class="reqn">Quality_{\mathcal{A}}(B)</code> is the value of a quality measure (see possible values
of the parameter <code>qualityF</code>) for an attribute subset <code class="reqn">B</code> in decision table <code class="reqn">\mathcal{A}</code>
and <code class="reqn">\epsilon</code> is a numeric value between 0 and 1 expressing the approximation threshold.
A lot of monographs provide comprehensive explanations about this topics, for example
(Janusz and Stawicki, 2011; Slezak, 2002; Wroblewski, 2001) which are used as the references of this function.
</p>
<p>Finally, this implementation allows to restrain the computational complexity of greedy
searching for decision reducts by setting the value of the parameter <code>nAttrs</code>. If this
parameter is set to a positive integer, the Monte Carlo method of selecting candidating
attributes will be used in each iteration of the algorithm.
</p>


<h3>Value</h3>

<p>A class <code>"FeatureSubset"</code> that contains the following components:
</p>

<ul>
<li> <p><code>reduct</code>: a list representing a single reduct. In this case, it could be a superreduct or just a subset of features.
</p>
</li>
<li> <p><code>type.method</code>: a string representing the type of method which is <code>"greedy.heuristic"</code>.
</p>
</li>
<li> <p><code>type.task</code>: a string showing the type of task which is <code>"feature selection"</code>.
</p>
</li>
<li> <p><code>model</code>: a string representing the type of model. In this case, it is <code>"RST"</code> which means rough set theory.
</p>
</li>
<li> <p><code>epsilon</code>: the approximation threshold.
</p>
</li>
</ul>
<h3>Author(s)</h3>

<p>Andrzej Janusz
</p>


<h3>References</h3>

<p>Andrzej Janusz and Dominik Slezak. "Rough Set Methods for Attribute
Clustering and Selection". Applied Artificial Intelligence, 28(3):220–242, 2014.
</p>
<p>A. Janusz and S. Stawicki, "Applications of Approximate Reducts to the Feature Selection Problem",
Proceedings of International Conference on Rough Sets and Knowledge Technology (RSKT), vol. 6954, p. 45 - 50 (2011).
</p>
<p>D. Ślęzak, "Approximate Entropy Reducts", Fundamenta Informaticae, vol. 53, no. 3 - 4, p. 365 - 390 (2002).
</p>
<p>J. Wróblewski, "Ensembles of Classifiers Based on Approximate Reducts", Fundamenta Informaticae, vol. 47, no. 3 - 4, p. 351 - 360 (2001).
</p>


<h3>See Also</h3>

<p><code>FS.DAAR.heuristic.RST</code> and <code>FS.reduct.computation</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">###################################################
## Example 1: Evaluate reduct and generate
##            new decision table
###################################################
data(RoughSetData)
decision.table &lt;- RoughSetData$hiring.dt

## evaluate a single reduct
res.1 &lt;- FS.greedy.heuristic.reduct.RST(decision.table, qualityF = X.entropy,
                                        epsilon = 0.0)

## generate a new decision table corresponding to the reduct
new.decTable &lt;- SF.applyDecTable(decision.table, res.1)
</code></pre>


</div>