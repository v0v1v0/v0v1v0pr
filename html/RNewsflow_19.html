<div class="container">

<table style="width: 100%;"><tr>
<td>term_char_sim</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Find terms with similar spelling</h2>

<h3>Description</h3>

<p>A quick, language agnostic way for finding terms with similar spelling. 
Calculates similarity as percentage of a terms bigram's or trigram's that also occur in the other term. 
The percentage has to be above the given threshold for both terms (unless allow_asym = T)
</p>


<h3>Usage</h3>

<pre><code class="language-R">term_char_sim(
  voc,
  type = c("tri", "bi"),
  min_overlap = 2/3,
  max_diff = 4,
  pad = F,
  as_lower = T,
  same_start = 1,
  drop_non_alpha = T,
  min_length = 5,
  allow_asym = F,
  verbose = T
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>voc</code></td>
<td>
<p>A character vector that gives the vocabulary (e.g., colnames of a dtm)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>Either "bi" (bigrams) or "tri" (trigrams)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_overlap</code></td>
<td>
<p>The minimal overlap percentage. Works together with max_diff to determine required overlap</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_diff</code></td>
<td>
<p>The maximum number of bi/tri-grams that is different</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pad</code></td>
<td>
<p>If True, pad the left size (ls) and right side (rs) of bi/tri-grams. So, trigrams for "pad" would be: "ls_ls_p", "ls_p_a", "p_a_d", "a_d_rs", "d_rs_rs".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>as_lower</code></td>
<td>
<p>If True, ignore case</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>same_start</code></td>
<td>
<p>Should terms start with the same character(s)? Given as a number for the number of same characters. (also greatly speeds up calculation)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>drop_non_alpha</code></td>
<td>
<p>If True, ignore non alpha terms (e.g., numbers, punctuation). They will appear in the output matrix, but only with zeros.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_length</code></td>
<td>
<p>The minimum number of characters in a term. Terms with fewer characters are ignored. They will appear in the output matrix, but only with zeros.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>allow_asym</code></td>
<td>
<p>If True, the match only needs to be true for at least one term. In practice, this means that "America" would match perfectly with "Southern-America".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>If True, report progress</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A similarity matrix in the CsparseMatrix format
</p>


<h3>Examples</h3>

<pre><code class="language-R">dfm = quanteda::tokens(c('That guy Gadaffi','Do you mean Kadaffi?',
                         'Nah more like Gadaffel','What Gargamel?')) |&gt;
  quanteda::dfm()
simmat = term_char_sim(colnames(dfm), same_start=0)
term_union(dfm, simmat, verbose = FALSE)
</code></pre>


</div>