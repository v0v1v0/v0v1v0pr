<div class="container">

<table style="width: 100%;"><tr>
<td>overimpute</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Perform overimputation diagnostic test</h2>

<h3>Description</h3>

<p><code>overimpute()</code> spikes additional missingness into the input data and reports imputation accuracy at training intervals specified by the user.
<code>overimpute()</code> works like <code>train()</code> – users must specify input data, binary and categorical columns (if data is not generated via <code>convert()</code>, model parameters for the neural network, and then overimputation parameters (see below for full details).
</p>


<h3>Usage</h3>

<pre><code class="language-R">overimpute(
  data,
  binary_columns = NULL,
  softmax_columns = NULL,
  spikein = 0.3,
  training_epochs,
  report_ival = 35,
  plot_vars = FALSE,
  skip_plot = FALSE,
  spike_seed = NULL,
  save_path = "",
  layer_structure = c(256, 256, 256),
  learn_rate = 4e-04,
  input_drop = 0.8,
  seed = 123L,
  train_batch = 16L,
  latent_space_size = 4,
  cont_adj = 1,
  binary_adj = 1,
  softmax_adj = 1,
  dropout_level = 0.5,
  vae_layer = FALSE,
  vae_alpha = 1,
  vae_sample_var = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A data.frame (or coercible) object, or an object of class <code>midas_pre</code> created from rMIDAS::convert()</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>binary_columns</code></td>
<td>
<p>A vector of column names, containing binary variables. NOTE: if <code>data</code> is a <code>midas_pre</code> object, this argument will be overwritten.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>softmax_columns</code></td>
<td>
<p>A list of lists, each internal list corresponding to a single categorical variable and containing names of the one-hot encoded variable names. NOTE: if <code>data</code> is a <code>midas_pre</code> object, this argument will be overwritten.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>spikein</code></td>
<td>
<p>A numeric between 0 and 1; the proportion of observed values in the input dataset to be randomly removed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>training_epochs</code></td>
<td>
<p>An integer, specifying the number of overimputation training epochs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>report_ival</code></td>
<td>
<p>An integer, specifying the number of overimputation training epochs between calculations of loss. Shorter intervals provide a more granular view of model performance but slow down the overimputation process.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot_vars</code></td>
<td>
<p>Boolean, specifies whether to plot the distribution of original versus overimputed values. This takes the form of a density plot for continuous variables and a barplot for categorical variables (showing proportions of each class).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>skip_plot</code></td>
<td>
<p>Boolean, specifies whether to suppress the main graphical output. This may be desirable when users are conducting a series of overimputation exercises and are primarily interested in the console output. <strong>Note</strong>, when <code>skip_plot = FALSE</code>, users must manually close the resulting pyplot window before the code will terminate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>spike_seed, seed</code></td>
<td>
<p>An integer, to initialize the pseudo-random number generators. Separate seeds can be provided for the spiked-in missingness and imputation, otherwise <code>spike_seed</code> is set to <code>seed</code> (default = 123L).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>save_path</code></td>
<td>
<p>String, indicating path to directory to save overimputation figures. Users should include a trailing "/" at the end of the path i.e. save_path = "path/to/figures/".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>layer_structure</code></td>
<td>
<p>A vector of integers, The number of nodes in each layer of the network (default = <code>c(256, 256, 256)</code>, denoting a three-layer network with 256 nodes per layer). Larger networks can learn more complex data structures but require longer training and are more prone to overfitting.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learn_rate</code></td>
<td>
<p>A number, the learning rate <code class="reqn">\gamma</code> (default = 0.0001), which controls the size of the weight adjustment in each training epoch. In general, higher values reduce training time at the expense of less accurate results.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>input_drop</code></td>
<td>
<p>A number between 0 and 1. The probability of corruption for input columns in training mini-batches (default = 0.8). Higher values increase training time but reduce the risk of overfitting. In our experience, values between 0.7 and 0.95 deliver the best performance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>train_batch</code></td>
<td>
<p>An integer, the number of observations in training mini-batches (default = 16).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>latent_space_size</code></td>
<td>
<p>An integer, the number of normal dimensions used to parameterize the latent space.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cont_adj</code></td>
<td>
<p>A number, weights the importance of continuous variables in the loss function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>binary_adj</code></td>
<td>
<p>A number, weights the importance of binary variables in the loss function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>softmax_adj</code></td>
<td>
<p>A number, weights the importance of categorical variables in the loss function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dropout_level</code></td>
<td>
<p>A number between 0 and 1, determines the number of nodes dropped to "thin" the network</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vae_layer</code></td>
<td>
<p>Boolean, specifies whether to include a variational autoencoder layer in the network</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vae_alpha</code></td>
<td>
<p>A number, the strength of the prior imposed on the Kullback-Leibler divergence term in the variational autoencoder loss functions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vae_sample_var</code></td>
<td>
<p>A number, the sampling variance of the normal distributions used to parameterize the latent space.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Accuracy is measured as the RMSE of imputed values versus actual values for continuous variables and classification error for categorical variables (i.e., the fraction of correctly predicted classes subtracted from 1).
Both metrics are reported in two forms:
</p>

<ol>
<li>
<p> their summed value over all Monte Carlo samples from the estimated missing-data posterior – "Aggregated RMSE" and "Aggregated softmax error”;
</p>
</li>
<li>
<p> their aggregated value divided by the number of such samples – "Individual RMSE" and "Individual softmax error".
</p>
</li>
</ol>
<p>In the final model, we recommend selecting the number of training epochs that minimizes the average value of these metrics — weighted by the proportion (or substantive importance) of continuous and categorical variables — in the overimputation exercise.  This “early stopping” rule reduces the risk of overtraining and thus, in effect, serves as an extra layer of regularization in the network.
</p>
<p>For more information, see Lall and Robinson (2023): <a href="doi:10.18637/jss.v107.i09">doi:10.18637/jss.v107.i09</a>.
</p>


<h3>Value</h3>

<p>Object of class <code>midas</code>, and outputs both overimputation loss values to the console and generates overimputation graphs.
</p>


<h3>References</h3>

<p>Lall R, Robinson T (2023).
“Efficient Multiple Imputation for Diverse Data in Python and R: MIDASpy and rMIDAS.”
<em>Journal of Statistical Software</em>, <b>107</b>(9), 1–38.
<a href="https://doi.org/10.18637/jss.v107.i09">doi:10.18637/jss.v107.i09</a>.
</p>


<h3>See Also</h3>

<p><code>train</code> for the main imputation function.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
# Run where Python initialised and configured correctly
if (python_configured()) {

raw_data &lt;- data.table(a = sample(c("red","yellow","blue",NA),1000, replace = TRUE),
                         b = 1:1000,
                         c = sample(c("YES","NO",NA),1000,replace=TRUE),
                         d = runif(1000,1,10),
                         e = sample(c("YES","NO"), 1000, replace = TRUE),
                         f = sample(c("male","female","trans","other",NA), 1000, replace = TRUE))

# Names of bin./cat. variables
test_bin &lt;- c("c","e")
test_cat &lt;- c("a","f")

# Pre-process data
test_data &lt;- convert(raw_data,
                       bin_cols = test_bin,
                       cat_cols = test_cat,
                       minmax_scale = TRUE)

# Overimpute - without plots
test_imp &lt;- overimpute(test_data,
                       spikein = 0.3,
                       plot_vars = FALSE,
                       skip_plot = TRUE,
                       training_epochs = 10,
                       report_ival = 5)
}

## End(Not run)
</code></pre>


</div>