<div class="container">

<table style="width: 100%;"><tr>
<td>Many score based zero inflated Poisson regressions</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Many score based zero inflated Poisson regressions
</h2>

<h3>Description</h3>

<p>Many score based zero inflated Poisson regressions.
</p>


<h3>Usage</h3>

<pre><code class="language-R">score.zipregs(y, x, logged = FALSE ) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>A vector with discrete data, counts.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>A matrix with data, the predictor variables. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logged</code></td>
<td>

<p>A boolean variable; it will return the logarithm of the pvalue if set to TRUE.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Instead of maximising the log-likelihood via the Newton-Raphson algorithm in order to perform the hypothesis testing that <code class="reqn">\beta_i=0</code> we use the score test. 
This is dramatcially faster as no model need to be fitted. The first derivative of the log-likelihood is known in closed form and under the null hypothesis the 
fitted values are all equal to the mean of the response variable y. The test is not the same as the likelihood ratio test. It is size correct nonetheless but it is 
a bit less efficient and less powerful. For big sample sizes though (5000 or more) the results are the same. It is also much faster then the classical likelihood ratio test.  
</p>


<h3>Value</h3>

<p>A matrix with two columns, the test statistic and its associated (logged) p-value.  
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris..
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M., Alenazi A. and Fafalios S. (2020). Computationally efficient univariate filtering for massive data. 
Electronic Journal of Applied Statistical Analysis, 13(2):390-412.
</p>
<p>Lambert D. (1992). Zero-inflated Poisson regression, with an application to defects in manufacturing. Technometrics, 34(1):1-14.
</p>
<p>Campbell, M.J. (2001). Statistics at Square Two: Understand Modern Statistical Applications in Medicine, pg. 112.
London, BMJ Books. 
</p>


<h3>See Also</h3>

<p><code> ztp.reg, censpois.mle
</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">x &lt;- matrix( rnorm(1000 * 100), ncol = 100 )
y &lt;- rpois(1000, 10)
y[1:150] &lt;- 0
a &lt;- score.zipregs(y, x)
x &lt;- NULL
mean(a &lt; 0.05) ## estimated type I error 
</code></pre>


</div>