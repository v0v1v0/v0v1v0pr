<div class="container">

<table style="width: 100%;"><tr>
<td>Many multivariate simple linear regressions coefficients</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Many multivariate simple linear regressions coefficients
</h2>

<h3>Description</h3>

<p>Many multivariate simple linear regressions coefficients.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mvbetas(y, x, pvalue = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>A matrix with the data, where rows denotes the observations and the columns contain the dependent variables.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>A numerical vector with one continuous independent variable only. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pvalue</code></td>
<td>

<p>If you want a hypothesis test that each slope (beta coefficient) is equal to zero set this equal to TRUE. It will also produce all the correlations between y and x.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>It is a function somehow opposite to the <code>allbetas</code>. Instead of having one y and many xs we have many ys and one x.
</p>


<h3>Value</h3>

<p>A matrix with the constant (alpha) and the slope (beta) for each simple linear regression. 
If the p-value is set to TRUE, the correlation of each y with the x is calculated along with the relevant p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code>allbetas, correls, univglms
</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">y &lt;- matrnorm(100, 100)
x &lt;- rnorm(100)
a &lt;- mvbetas(y, x, pvalue = FALSE)
b &lt;- matrix(nrow = 100, ncol = 2)
z &lt;- cbind(1, x)

a &lt;- mvbetas(y, x)
b[2, ] &lt;- coef( lm.fit( z, y[, 1] ) )
b[2, ] &lt;- coef( lm.fit( z, y[, 2] ) )
x &lt;- NULL
</code></pre>


</div>