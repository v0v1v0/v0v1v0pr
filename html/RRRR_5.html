<div class="container">

<table style="width: 100%;"><tr>
<td>RRRR</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Robust Reduced-Rank Regression using Majorisation-Minimisation</h2>

<h3>Description</h3>

<p>Majorisation-Minimisation based Estimation for Reduced-Rank Regression with a Cauchy Distribution Assumption.
This method is robust in the sense that it assumes a heavy-tailed Cauchy distribution
for the innovations. This method is an iterative optimization algorithm. See <code>References</code> for a similar setting.
</p>


<h3>Usage</h3>

<pre><code class="language-R">RRRR(
  y,
  x,
  z = NULL,
  mu = TRUE,
  r = 1,
  itr = 100,
  earlystop = 1e-04,
  initial_A = matrix(rnorm(P * r), ncol = r),
  initial_B = matrix(rnorm(Q * r), ncol = r),
  initial_D = matrix(rnorm(P * R), ncol = R),
  initial_mu = matrix(rnorm(P)),
  initial_Sigma = diag(P),
  return_data = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Matrix of dimension N*P. The matrix for the response variables. See <code>Detail</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Matrix of dimension N*Q. The matrix for the explanatory variables to be projected. See <code>Detail</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>z</code></td>
<td>
<p>Matrix of dimension N*R. The matrix for the explanatory variables not to be projected. See <code>Detail</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>Logical. Indicating if a constant term is included.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r</code></td>
<td>
<p>Integer. The rank for the reduced-rank matrix <code class="reqn">AB'</code>. See <code>Detail</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>itr</code></td>
<td>
<p>Integer. The maximum number of iteration.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>earlystop</code></td>
<td>
<p>Scalar. The criteria to stop the algorithm early. The algorithm will stop if the improvement
on objective function is small than <code class="reqn">earlystop * objective_from_last_iteration</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initial_A</code></td>
<td>
<p>Matrix of dimension P*r. The initial value for matrix <code class="reqn">A</code>. See <code>Detail</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initial_B</code></td>
<td>
<p>Matrix of dimension Q*r. The initial value for matrix <code class="reqn">B</code>. See <code>Detail</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initial_D</code></td>
<td>
<p>Matrix of dimension P*R. The initial value for matrix <code class="reqn">D</code>. See <code>Detail</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initial_mu</code></td>
<td>
<p>Matrix of dimension P*1. The initial value for the constant <code class="reqn">mu</code>. See <code>Detail</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initial_Sigma</code></td>
<td>
<p>Matrix of dimension P*P. The initial value for matrix Sigma. See <code>Detail</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_data</code></td>
<td>
<p>Logical. Indicating if the data used is return in the output.
If set to <code>TRUE</code>, <code>update.RRRR</code> can update the model by simply provide new data.
Set to <code>FALSE</code> to save output size.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The formulation of the reduced-rank regression is as follow:
</p>
<p style="text-align: center;"><code class="reqn">y = \mu +AB'  x + D z+innov,</code>
</p>

<p>where for each realization <code class="reqn">y</code> is a vector of dimension <code class="reqn">P</code> for the <code class="reqn">P</code> response variables,
<code class="reqn">x</code> is a vector of dimension <code class="reqn">Q</code> for the <code class="reqn">Q</code> explanatory variables that will be projected to
reduce the rank,
<code class="reqn">z</code> is a vector of dimension <code class="reqn">R</code> for the <code class="reqn">R</code> explanatory variables
that will not be projected,
<code class="reqn">\mu</code> is the constant vector of dimension <code class="reqn">P</code>,
<code class="reqn">innov</code> is the innovation vector of dimension <code class="reqn">P</code>,
<code class="reqn">D</code> is a coefficient matrix for <code class="reqn">z</code> with dimension <code class="reqn">P*R</code>,
<code class="reqn">A</code> is the so called exposure matrix with dimension <code class="reqn">P*r</code>, and
<code class="reqn">B</code> is the so called factor matrix with dimension <code class="reqn">Q*r</code>.
The matrix resulted from <code class="reqn">AB'</code> will be a reduced rank coefficient matrix with rank of <code class="reqn">r</code>.
The function estimates parameters <code class="reqn">\mu</code>, <code class="reqn">A</code>, <code class="reqn">B</code>, <code class="reqn">D</code>, and <code class="reqn">Sigma</code>, the covariance matrix of
the innovation's distribution, assuming the innovation has a Cauchy distribution.
</p>


<h3>Value</h3>

<p>A list of the estimated parameters of class <code>RRRR</code>.
</p>

<dl>
<dt>spec</dt>
<dd>
<p>The input specifications. <code class="reqn">N</code> is the sample size.</p>
</dd>
<dt>history</dt>
<dd>
<p>The path of all the parameters during optimization and the path of the objective value.</p>
</dd>
<dt>mu</dt>
<dd>
<p>The estimated constant vector. Can be <code>NULL</code>.</p>
</dd>
<dt>A</dt>
<dd>
<p>The estimated exposure matrix.</p>
</dd>
<dt>B</dt>
<dd>
<p>The estimated factor matrix.</p>
</dd>
<dt>D</dt>
<dd>
<p>The estimated coefficient matrix of <code>z</code>.</p>
</dd>
<dt>Sigma</dt>
<dd>
<p>The estimated covariance matrix of the innovation distribution.</p>
</dd>
<dt>obj</dt>
<dd>
<p>The final objective value.</p>
</dd>
<dt>data</dt>
<dd>
<p>The data used in estimation if <code>return_data</code> is set to <code>TRUE</code>. <code>NULL</code> otherwise.</p>
</dd>
</dl>
<h3>Author(s)</h3>

<p>Yangzhuoran Yang
</p>


<h3>References</h3>

<p>Z. Zhao and D. P. Palomar, "Robust maximum likelihood estimation of sparse vector error correction model," in2017 IEEE Global Conference on Signal and Information Processing (GlobalSIP),  pp. 913â€“917,IEEE, 2017.
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(2222)
data &lt;- RRR_sim()
res &lt;- RRRR(y=data$y, x=data$x, z = data$z)
res

</code></pre>


</div>