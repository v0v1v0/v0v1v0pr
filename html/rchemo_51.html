<div class="container">

<table style="width: 100%;"><tr>
<td>kplsr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>KPLSR Models</h2>

<h3>Description</h3>

<p>NIPALS Kernel PLSR algorithm described in Rosipal &amp; Trejo (2001). 
</p>
<p>The algorithm is slow for <code class="reqn">n &gt;= 500</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">
kplsr(X, Y, weights = NULL, nlv, kern = "krbf",
     tol = .Machine$double.eps^0.5, maxit = 100, ...)

## S3 method for class 'Kplsr'
transform(object, X, ..., nlv = NULL)  

## S3 method for class 'Kplsr'
coef(object, ..., nlv = NULL)  

## S3 method for class 'Kplsr'
predict(object, X, ..., nlv = NULL)  

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>For the main function: Training X-data (<code class="reqn">n, p</code>). — For the auxiliary functions: New X-data (<code class="reqn">m, p</code>) to consider.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>Training Y-data (<code class="reqn">n, q</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>Weights (<code class="reqn">n, 1</code>) to apply to the training observations. Internally, weights are "normalized" to sum to 1. Default to <code>NULL</code> (weights are set to <code class="reqn">1 / n</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlv</code></td>
<td>
<p>The number(s) of LVs to calculate. — For the auxiliary functions: The number(s) of LVs to consider.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kern</code></td>
<td>
<p>Name of the function defining the considered kernel for building the Gram matrix. See <code>krbf</code> for syntax, and other available kernel functions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>Tolerance level for stopping the NIPALS iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxit</code></td>
<td>
<p>Maximum number of NIPALS iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Optional arguments to pass in the kernel function defined in <code>kern</code> (e.g. <code>gamma</code> for <code>krbf</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>For the auxiliary functions: A fitted model, output of a call to the main function.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>For <code>kplsr</code>:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Training X-data (<code class="reqn">n, p</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Kt</code></td>
<td>
<p>Gram matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>T</code></td>
<td>
<p>X-scores matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>C</code></td>
<td>
<p>The Y-loading weights matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>U</code></td>
<td>
<p>intermediate output.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>R</code></td>
<td>
<p>The PLS projection matrix (p,nlv).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ymeans</code></td>
<td>
<p>the centering vector of Y (q,1).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>vector of observation weights.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kern</code></td>
<td>
<p>kern function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dots</code></td>
<td>
<p>Optional arguments.</p>
</td>
</tr>
</table>
<p>For <code>transform.Kplsr</code>: X-scores matrix for new X-data.
</p>
<p>For <code>coef.Kplsr</code>:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>int</code></td>
<td>
<p>intercept values matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>beta coefficient matrix.</p>
</td>
</tr>
</table>
<p>For <code>predict.Kplsr</code>: 
</p>
<table><tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>predicted values matrix for new X-data.</p>
</td>
</tr></table>
<h3>Note</h3>

<p>The second example concerns the fitting of the function sinc(x) described in Rosipal &amp; Trejo 2001 p. 105-106
</p>


<h3>References</h3>

<p>Rosipal, R., Trejo, L.J., 2001. Kernel Partial Least Squares Regression in Reproducing Kernel Hilbert Space. Journal of Machine Learning Research 2, 97-123.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## EXAMPLE 1

n &lt;- 6 ; p &lt;- 4
Xtrain &lt;- matrix(rnorm(n * p), ncol = p)
ytrain &lt;- rnorm(n)
Ytrain &lt;- cbind(y1 = ytrain, y2 = 100 * ytrain)
m &lt;- 3
Xtest &lt;- Xtrain[1:m, , drop = FALSE] 
Ytest &lt;- Ytrain[1:m, , drop = FALSE] ; ytest &lt;- Ytest[1:m, 1]

nlv &lt;- 2
fm &lt;- kplsr(Xtrain, Ytrain, nlv = nlv, kern = "krbf", gamma = .8)
transform(fm, Xtest)
transform(fm, Xtest, nlv = 1)
coef(fm)
coef(fm, nlv = 1)

predict(fm, Xtest)
predict(fm, Xtest, nlv = 0:nlv)$pred

pred &lt;- predict(fm, Xtest)$pred
msep(pred, Ytest)

nlv &lt;- 2
fm &lt;- kplsr(Xtrain, Ytrain, nlv = nlv, kern = "kpol", degree = 2, coef0 = 10)
predict(fm, Xtest, nlv = nlv)

## EXAMPLE 2

x &lt;- seq(-10, 10, by = .2)
x[x == 0] &lt;- 1e-5
n &lt;- length(x)
zy &lt;- sin(abs(x)) / abs(x)
y &lt;- zy + rnorm(n, 0, .2)
plot(x, y, type = "p")
lines(x, zy, lty = 2)
X &lt;- matrix(x, ncol = 1)

nlv &lt;- 2
fm &lt;- kplsr(X, y, nlv = nlv)
pred &lt;- predict(fm, X)$pred
plot(X, y, type = "p")
lines(X, zy, lty = 2)
lines(X, pred, col = "red")

</code></pre>


</div>